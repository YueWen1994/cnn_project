{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "def show_img(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        img2 = img\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get three channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.preprocess_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try scratched Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "import keras.utils as ku\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n"
     ]
    }
   ],
   "source": [
    "SHAPE = (64, 64)\n",
    "CHANNEL = 3\n",
    "    \n",
    "data = generate_data_set_for_training(shape=SHAPE, channel=CHANNEL)\n",
    "# Extract Train, val from data\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "# Format as the input of VGG\n",
    "y_train = list(data['y_train'].T)\n",
    "y_val = list(data['y_val'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,row, col,channel = X_train.shape\n",
    "digLen = 5 # including category 0\n",
    "numDigits = 11\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "vgg16Model = VGG16(include_top = False,\n",
    "                   weights = None)\n",
    "vgg16Model.summary()\n",
    "ptInput = keras.Input(shape = (row,col,channel), name  = 'vgg16Scratch')\n",
    "vgg16 = vgg16Model(ptInput)\n",
    "\n",
    "# vgg16 = Conv2D(64,(3, 3), activation ='relu', padding='same')(input)\n",
    "# vgg16 = Conv2D(64,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = MaxPooling2D(pool_size=(2, 2))(vgg16)\n",
    "#\n",
    "# vgg16 = Conv2D(128,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(128,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = MaxPooling2D(pool_size=(2, 2))(vgg16)\n",
    "#\n",
    "# vgg16 = Conv2D(256,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(256,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = MaxPooling2D(pool_size=(2, 2))(vgg16)\n",
    "#\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = MaxPooling2D(pool_size=(2, 2))(vgg16)\n",
    "#\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = Conv2D(512,(3, 3), activation ='relu', padding='same')(vgg16)\n",
    "# vgg16 = MaxPooling2D(pool_size=(2, 2))(vgg16)\n",
    "\n",
    "vgg16 = Flatten()(vgg16)\n",
    "vgg16 = Dense(1024, activation='relu')(vgg16)\n",
    "vgg16 = Dense(1024, activation='relu')(vgg16)\n",
    "# vgg16 = Dense(1000, activation='relu')(vgg16)\n",
    "vgg16 = Dropout(0.5)(vgg16)\n",
    "\n",
    "numd_SM = Dense(digLen,    activation='softmax',name = 'num')(vgg16)\n",
    "dig1_SM = Dense(numDigits, activation='softmax',name = 'dig1')(vgg16)\n",
    "dig2_SM = Dense(numDigits, activation='softmax',name = 'dig2')(vgg16)\n",
    "dig3_SM = Dense(numDigits, activation='softmax',name = 'dig3')(vgg16)\n",
    "dig4_SM = Dense(numDigits, activation='softmax',name = 'dig4')(vgg16)\n",
    "numB_SM = Dense(2,         activation='softmax',name = 'nC')(vgg16)\n",
    "out = [numd_SM, dig1_SM ,dig2_SM, dig3_SM, dig4_SM, numB_SM]\n",
    "\n",
    "vgg16 = keras.Model(inputs = ptInput, outputs = out)\n",
    "\n",
    "callback = []\n",
    "optim = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='saved_models/vgg16.classifier.hdf5',\n",
    "                                               monitor='loss',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
    "                                              factor = 0.1,\n",
    "                                              verbose = 1,\n",
    "                                              patience= 3,\n",
    "                                              cooldown= 0,\n",
    "                                              min_lr = 0.000001)\n",
    "# tb = keras.callbacks.TensorBoard(log_dir='logs', write_graph=True, write_images=True)\n",
    "# es = keras.callbacks.EarlyStopping(monitor= 'val_loss',\n",
    "#                                    min_delta=0.00000001,\n",
    "#                                    patience=5,\n",
    "#                                    verbose=1,\n",
    "#                                    mode='auto')\n",
    "#callback.append(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "vgg16Scratch (InputLayer)       (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   multiple             14714688    vgg16Scratch[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "num (Dense)                     (None, 5)            5125        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dig1 (Dense)                    (None, 11)           11275       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dig2 (Dense)                    (None, 11)           11275       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dig3 (Dense)                    (None, 11)           11275       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dig4 (Dense)                    (None, 11)           11275       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "nC (Dense)                      (None, 2)            2050        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,914,739\n",
      "Trainable params: 17,914,739\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callback.append(checkpointer)\n",
    "callback.append(reduce_lr)\n",
    "vgg16.summary()\n",
    "\n",
    "vgg16.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer= optim,\n",
    "              metrics=  ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n",
      "69076/69076 [==============================] - 92s 1ms/step - loss: 5.2512 - num_loss: 1.1180 - dig1_loss: 1.4738 - dig2_loss: 1.2648 - dig3_loss: 0.5829 - dig4_loss: 0.1299 - nC_loss: 0.6819 - num_acc: 0.6104 - dig1_acc: 0.6125 - dig2_acc: 0.7112 - dig3_acc: 0.8972 - dig4_acc: 0.9848 - nC_acc: 0.6088 - val_loss: 5.1057 - val_num_loss: 1.0941 - val_dig1_loss: 1.4415 - val_dig2_loss: 1.2369 - val_dig3_loss: 0.5630 - val_dig4_loss: 0.1020 - val_nC_loss: 0.6681 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.25117, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 2/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1248 - num_loss: 1.0997 - dig1_loss: 1.4483 - dig2_loss: 1.2394 - dig3_loss: 0.5602 - dig4_loss: 0.1084 - nC_loss: 0.6687 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1057 - val_num_loss: 1.0951 - val_dig1_loss: 1.4404 - val_dig2_loss: 1.2377 - val_dig3_loss: 0.5631 - val_dig4_loss: 0.1015 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00002: loss improved from 5.25117 to 5.12476, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 3/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1182 - num_loss: 1.0985 - dig1_loss: 1.4463 - dig2_loss: 1.2378 - dig3_loss: 0.5597 - dig4_loss: 0.1078 - nC_loss: 0.6682 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1032 - val_num_loss: 1.0941 - val_dig1_loss: 1.4403 - val_dig2_loss: 1.2361 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1014 - val_nC_loss: 0.6683 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00003: loss improved from 5.12476 to 5.11821, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 4/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1137 - num_loss: 1.0977 - dig1_loss: 1.4452 - dig2_loss: 1.2369 - dig3_loss: 0.5584 - dig4_loss: 0.1076 - nC_loss: 0.6680 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1062 - val_num_loss: 1.0952 - val_dig1_loss: 1.4412 - val_dig2_loss: 1.2364 - val_dig3_loss: 0.5633 - val_dig4_loss: 0.1011 - val_nC_loss: 0.6691 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00004: loss improved from 5.11821 to 5.11371, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 5/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1123 - num_loss: 1.0977 - dig1_loss: 1.4450 - dig2_loss: 1.2366 - dig3_loss: 0.5575 - dig4_loss: 0.1075 - nC_loss: 0.6680 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1052 - val_num_loss: 1.0947 - val_dig1_loss: 1.4405 - val_dig2_loss: 1.2360 - val_dig3_loss: 0.5648 - val_dig4_loss: 0.1013 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00005: loss improved from 5.11371 to 5.11228, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 6/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1083 - num_loss: 1.0970 - dig1_loss: 1.4444 - dig2_loss: 1.2355 - dig3_loss: 0.5569 - dig4_loss: 0.1069 - nC_loss: 0.6677 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1020 - val_num_loss: 1.0940 - val_dig1_loss: 1.4400 - val_dig2_loss: 1.2359 - val_dig3_loss: 0.5632 - val_dig4_loss: 0.1011 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00006: loss improved from 5.11228 to 5.10830, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 7/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1070 - num_loss: 1.0968 - dig1_loss: 1.4436 - dig2_loss: 1.2349 - dig3_loss: 0.5571 - dig4_loss: 0.1071 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1006 - val_num_loss: 1.0938 - val_dig1_loss: 1.4395 - val_dig2_loss: 1.2358 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1010 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00007: loss improved from 5.10830 to 5.10700, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 8/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1079 - num_loss: 1.0969 - dig1_loss: 1.4438 - dig2_loss: 1.2350 - dig3_loss: 0.5570 - dig4_loss: 0.1073 - nC_loss: 0.6678 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1026 - val_num_loss: 1.0937 - val_dig1_loss: 1.4406 - val_dig2_loss: 1.2358 - val_dig3_loss: 0.5633 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6680 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00008: loss did not improve from 5.10700\n",
      "Epoch 9/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1065 - num_loss: 1.0965 - dig1_loss: 1.4435 - dig2_loss: 1.2344 - dig3_loss: 0.5573 - dig4_loss: 0.1071 - nC_loss: 0.6676 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1010 - val_num_loss: 1.0938 - val_dig1_loss: 1.4395 - val_dig2_loss: 1.2355 - val_dig3_loss: 0.5630 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00009: loss improved from 5.10700 to 5.10653, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 10/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1056 - num_loss: 1.0965 - dig1_loss: 1.4433 - dig2_loss: 1.2348 - dig3_loss: 0.5564 - dig4_loss: 0.1069 - nC_loss: 0.6676 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1055 - val_num_loss: 1.0948 - val_dig1_loss: 1.4415 - val_dig2_loss: 1.2363 - val_dig3_loss: 0.5627 - val_dig4_loss: 0.1017 - val_nC_loss: 0.6686 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00010: loss improved from 5.10653 to 5.10561, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 11/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 5.1063 - num_loss: 1.0965 - dig1_loss: 1.4433 - dig2_loss: 1.2350 - dig3_loss: 0.5567 - dig4_loss: 0.1073 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1015 - val_num_loss: 1.0937 - val_dig1_loss: 1.4395 - val_dig2_loss: 1.2362 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6680 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00011: loss did not improve from 5.10561\n",
      "Epoch 12/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1045 - num_loss: 1.0964 - dig1_loss: 1.4429 - dig2_loss: 1.2342 - dig3_loss: 0.5564 - dig4_loss: 0.1070 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1009 - val_num_loss: 1.0938 - val_dig1_loss: 1.4397 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1013 - val_nC_loss: 0.6681 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: loss improved from 5.10561 to 5.10446, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 13/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1044 - num_loss: 1.0961 - dig1_loss: 1.4428 - dig2_loss: 1.2345 - dig3_loss: 0.5565 - dig4_loss: 0.1070 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1020 - val_num_loss: 1.0942 - val_dig1_loss: 1.4398 - val_dig2_loss: 1.2355 - val_dig3_loss: 0.5631 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6681 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00013: loss improved from 5.10446 to 5.10441, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 14/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1049 - num_loss: 1.0965 - dig1_loss: 1.4430 - dig2_loss: 1.2342 - dig3_loss: 0.5565 - dig4_loss: 0.1071 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1018 - val_num_loss: 1.0940 - val_dig1_loss: 1.4399 - val_dig2_loss: 1.2359 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00014: loss did not improve from 5.10441\n",
      "Epoch 15/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1042 - num_loss: 1.0965 - dig1_loss: 1.4429 - dig2_loss: 1.2342 - dig3_loss: 0.5559 - dig4_loss: 0.1072 - nC_loss: 0.6676 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1016 - val_num_loss: 1.0939 - val_dig1_loss: 1.4402 - val_dig2_loss: 1.2359 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1011 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00015: loss improved from 5.10441 to 5.10421, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 16/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1029 - num_loss: 1.0960 - dig1_loss: 1.4425 - dig2_loss: 1.2339 - dig3_loss: 0.5562 - dig4_loss: 0.1070 - nC_loss: 0.6674 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1017 - val_num_loss: 1.0939 - val_dig1_loss: 1.4399 - val_dig2_loss: 1.2356 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1014 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00016: loss improved from 5.10421 to 5.10290, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 17/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1033 - num_loss: 1.0963 - dig1_loss: 1.4424 - dig2_loss: 1.2338 - dig3_loss: 0.5563 - dig4_loss: 0.1070 - nC_loss: 0.6674 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1024 - val_num_loss: 1.0943 - val_dig1_loss: 1.4401 - val_dig2_loss: 1.2361 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1014 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00017: loss did not improve from 5.10290\n",
      "Epoch 18/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1026 - num_loss: 1.0961 - dig1_loss: 1.4425 - dig2_loss: 1.2340 - dig3_loss: 0.5556 - dig4_loss: 0.1070 - nC_loss: 0.6674 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1049 - val_num_loss: 1.0939 - val_dig1_loss: 1.4398 - val_dig2_loss: 1.2360 - val_dig3_loss: 0.5657 - val_dig4_loss: 0.1016 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00018: loss improved from 5.10290 to 5.10261, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 19/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1027 - num_loss: 1.0961 - dig1_loss: 1.4424 - dig2_loss: 1.2337 - dig3_loss: 0.5562 - dig4_loss: 0.1070 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1012 - val_num_loss: 1.0941 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2356 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6680 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00019: loss did not improve from 5.10261\n",
      "Epoch 20/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1024 - num_loss: 1.0961 - dig1_loss: 1.4422 - dig2_loss: 1.2334 - dig3_loss: 0.5565 - dig4_loss: 0.1070 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1021 - val_num_loss: 1.0939 - val_dig1_loss: 1.4400 - val_dig2_loss: 1.2359 - val_dig3_loss: 0.5630 - val_dig4_loss: 0.1013 - val_nC_loss: 0.6680 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00020: loss improved from 5.10261 to 5.10245, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 21/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.1024 - num_loss: 1.0962 - dig1_loss: 1.4423 - dig2_loss: 1.2338 - dig3_loss: 0.5557 - dig4_loss: 0.1069 - nC_loss: 0.6675 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1023 - val_num_loss: 1.0940 - val_dig1_loss: 1.4405 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5632 - val_dig4_loss: 0.1014 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00021: loss improved from 5.10245 to 5.10238, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 22/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1025 - num_loss: 1.0962 - dig1_loss: 1.4422 - dig2_loss: 1.2333 - dig3_loss: 0.5561 - dig4_loss: 0.1073 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1003 - val_num_loss: 1.0937 - val_dig1_loss: 1.4394 - val_dig2_loss: 1.2356 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00022: loss did not improve from 5.10238\n",
      "Epoch 23/50\n",
      "69076/69076 [==============================] - 82s 1ms/step - loss: 5.1024 - num_loss: 1.0961 - dig1_loss: 1.4423 - dig2_loss: 1.2335 - dig3_loss: 0.5562 - dig4_loss: 0.1069 - nC_loss: 0.6674 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1023 - val_num_loss: 1.0939 - val_dig1_loss: 1.4403 - val_dig2_loss: 1.2357 - val_dig3_loss: 0.5629 - val_dig4_loss: 0.1015 - val_nC_loss: 0.6680 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00023: loss did not improve from 5.10238\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 24/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0997 - num_loss: 1.0955 - dig1_loss: 1.4414 - dig2_loss: 1.2330 - dig3_loss: 0.5558 - dig4_loss: 0.1068 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1001 - val_num_loss: 1.0937 - val_dig1_loss: 1.4394 - val_dig2_loss: 1.2352 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: loss improved from 5.10238 to 5.09966, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 25/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.0986 - num_loss: 1.0954 - dig1_loss: 1.4414 - dig2_loss: 1.2328 - dig3_loss: 0.5548 - dig4_loss: 0.1070 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1001 - val_num_loss: 1.0937 - val_dig1_loss: 1.4394 - val_dig2_loss: 1.2353 - val_dig3_loss: 0.5626 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00025: loss improved from 5.09966 to 5.09858, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 26/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 5.1004 - num_loss: 1.0959 - dig1_loss: 1.4418 - dig2_loss: 1.2330 - dig3_loss: 0.5555 - dig4_loss: 0.1070 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1002 - val_num_loss: 1.0937 - val_dig1_loss: 1.4394 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00026: loss did not improve from 5.09858\n",
      "Epoch 27/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 5.0993 - num_loss: 1.0955 - dig1_loss: 1.4417 - dig2_loss: 1.2330 - dig3_loss: 0.5554 - dig4_loss: 0.1066 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.1000 - val_num_loss: 1.0937 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00027: loss did not improve from 5.09858\n",
      "Epoch 28/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 5.0985 - num_loss: 1.0954 - dig1_loss: 1.4413 - dig2_loss: 1.2331 - dig3_loss: 0.5551 - dig4_loss: 0.1065 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00028: loss improved from 5.09858 to 5.09852, saving model to saved_models/vgg16.classifier.hdf5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 29/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 5.0992 - num_loss: 1.0956 - dig1_loss: 1.4417 - dig2_loss: 1.2326 - dig3_loss: 0.5555 - dig4_loss: 0.1066 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00029: loss did not improve from 5.09852\n",
      "Epoch 30/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1002 - num_loss: 1.0957 - dig1_loss: 1.4417 - dig2_loss: 1.2331 - dig3_loss: 0.5553 - dig4_loss: 0.1070 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00030: loss did not improve from 5.09852\n",
      "Epoch 31/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0996 - num_loss: 1.0957 - dig1_loss: 1.4414 - dig2_loss: 1.2325 - dig3_loss: 0.5556 - dig4_loss: 0.1071 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00031: loss did not improve from 5.09852\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 32/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 5.0979 - num_loss: 1.0953 - dig1_loss: 1.4411 - dig2_loss: 1.2326 - dig3_loss: 0.5551 - dig4_loss: 0.1067 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00032: loss improved from 5.09852 to 5.09794, saving model to saved_models/vgg16.classifier.hdf5\n",
      "Epoch 33/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0991 - num_loss: 1.0955 - dig1_loss: 1.4413 - dig2_loss: 1.2327 - dig3_loss: 0.5554 - dig4_loss: 0.1068 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00033: loss did not improve from 5.09794\n",
      "Epoch 34/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1005 - num_loss: 1.0958 - dig1_loss: 1.4417 - dig2_loss: 1.2332 - dig3_loss: 0.5557 - dig4_loss: 0.1069 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00034: loss did not improve from 5.09794\n",
      "Epoch 35/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0993 - num_loss: 1.0958 - dig1_loss: 1.4414 - dig2_loss: 1.2324 - dig3_loss: 0.5553 - dig4_loss: 0.1071 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00035: loss did not improve from 5.09794\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 36/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0999 - num_loss: 1.0955 - dig1_loss: 1.4415 - dig2_loss: 1.2336 - dig3_loss: 0.5552 - dig4_loss: 0.1068 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: loss did not improve from 5.09794\n",
      "Epoch 37/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0994 - num_loss: 1.0957 - dig1_loss: 1.4416 - dig2_loss: 1.2328 - dig3_loss: 0.5552 - dig4_loss: 0.1068 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00037: loss did not improve from 5.09794\n",
      "Epoch 38/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0995 - num_loss: 1.0955 - dig1_loss: 1.4413 - dig2_loss: 1.2327 - dig3_loss: 0.5556 - dig4_loss: 0.1071 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00038: loss did not improve from 5.09794\n",
      "Epoch 39/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0990 - num_loss: 1.0954 - dig1_loss: 1.4415 - dig2_loss: 1.2328 - dig3_loss: 0.5554 - dig4_loss: 0.1068 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00039: loss did not improve from 5.09794\n",
      "Epoch 40/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0994 - num_loss: 1.0955 - dig1_loss: 1.4413 - dig2_loss: 1.2327 - dig3_loss: 0.5557 - dig4_loss: 0.1069 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00040: loss did not improve from 5.09794\n",
      "Epoch 41/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1002 - num_loss: 1.0958 - dig1_loss: 1.4417 - dig2_loss: 1.2327 - dig3_loss: 0.5556 - dig4_loss: 0.1070 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00041: loss did not improve from 5.09794\n",
      "Epoch 42/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0998 - num_loss: 1.0956 - dig1_loss: 1.4417 - dig2_loss: 1.2333 - dig3_loss: 0.5553 - dig4_loss: 0.1068 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00042: loss did not improve from 5.09794\n",
      "Epoch 43/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0996 - num_loss: 1.0957 - dig1_loss: 1.4416 - dig2_loss: 1.2328 - dig3_loss: 0.5555 - dig4_loss: 0.1069 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00043: loss did not improve from 5.09794\n",
      "Epoch 44/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0995 - num_loss: 1.0957 - dig1_loss: 1.4416 - dig2_loss: 1.2328 - dig3_loss: 0.5551 - dig4_loss: 0.1069 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00044: loss did not improve from 5.09794\n",
      "Epoch 45/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0998 - num_loss: 1.0958 - dig1_loss: 1.4416 - dig2_loss: 1.2328 - dig3_loss: 0.5554 - dig4_loss: 0.1071 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00045: loss did not improve from 5.09794\n",
      "Epoch 46/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0998 - num_loss: 1.0958 - dig1_loss: 1.4414 - dig2_loss: 1.2331 - dig3_loss: 0.5554 - dig4_loss: 0.1068 - nC_loss: 0.6673 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00046: loss did not improve from 5.09794\n",
      "Epoch 47/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.1004 - num_loss: 1.0958 - dig1_loss: 1.4416 - dig2_loss: 1.2331 - dig3_loss: 0.5558 - dig4_loss: 0.1070 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00047: loss did not improve from 5.09794\n",
      "Epoch 48/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0990 - num_loss: 1.0956 - dig1_loss: 1.4414 - dig2_loss: 1.2327 - dig3_loss: 0.5553 - dig4_loss: 0.1067 - nC_loss: 0.6672 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00048: loss did not improve from 5.09794\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0990 - num_loss: 1.0956 - dig1_loss: 1.4413 - dig2_loss: 1.2327 - dig3_loss: 0.5554 - dig4_loss: 0.1069 - nC_loss: 0.6671 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00049: loss did not improve from 5.09794\n",
      "Epoch 50/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 5.0990 - num_loss: 1.0954 - dig1_loss: 1.4413 - dig2_loss: 1.2329 - dig3_loss: 0.5553 - dig4_loss: 0.1070 - nC_loss: 0.6671 - num_acc: 0.6136 - dig1_acc: 0.6146 - dig2_acc: 0.7120 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.6136 - val_loss: 5.0999 - val_num_loss: 1.0936 - val_dig1_loss: 1.4393 - val_dig2_loss: 1.2354 - val_dig3_loss: 0.5625 - val_dig4_loss: 0.1012 - val_nC_loss: 0.6679 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00050: loss did not improve from 5.09794\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n"
     ]
    }
   ],
   "source": [
    "vgg16History = vgg16.fit(x = X_train,\n",
    "                         y = y_train,\n",
    "                         batch_size = batch_size,\n",
    "                         epochs=epochs,\n",
    "                         verbose=1,\n",
    "                         shuffle = True,\n",
    "                         validation_data = (X_val, y_val),\n",
    "                         callbacks = callback)\n",
    "\n",
    "print(vgg16History.history.keys())\n",
    "modName = 'vgg16_Scratch'\n",
    "print(vgg16History.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.model_evaluation_utils import evaluate_model_performance\n",
    "\n",
    "evaluate_model_performance(fitted_model=vgg16History, \n",
    "                           model_name = modName,\n",
    "                           data=data,\n",
    "                           model=vgg16\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
