{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def show_img(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        img2 = img\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get three channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.preprocess_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try scratched Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "import keras.utils as ku\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n"
     ]
    }
   ],
   "source": [
    "SHAPE = (64, 64)\n",
    "CHANNEL = 3\n",
    "    \n",
    "data = generate_data_set_for_training(shape=SHAPE, channel=CHANNEL)\n",
    "# Extract Train, val from data\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "# Format as the input of VGG\n",
    "y_train = list(data['y_train'].T)\n",
    "y_val = list(data['y_val'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "customModel (InputLayer)        (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_1 (Conv2D)              (None, 64, 64, 16)   448         customModel[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_2 (Conv2D)              (None, 64, 64, 16)   2320        conv_16_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv_16_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_32_01 (Conv2D)            (None, 32, 32, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_32_02 (Conv2D)            (None, 32, 32, 32)   9248        conv2_32_01[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2_32_02[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_48_01 (Conv2D)            (None, 16, 16, 48)   13872       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_48_02 (Conv2D)            (None, 16, 16, 48)   20784       conv2_48_01[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 48)   192         conv2_48_02[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 48)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_64_1 (Conv2D)             (None, 8, 8, 64)     27712       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_64_2 (Conv2D)             (None, 8, 8, 64)     36928       conv2_64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_64_3 (Conv2D)             (None, 8, 8, 64)     36928       conv2_64_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2_64_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_128_1 (Conv2D)            (None, 7, 7, 128)    204928      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_128_2 (Conv2D)            (None, 7, 7, 128)    409728      conv2_128_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2_128_3 (Conv2D)            (None, 7, 7, 128)    409728      conv2_128_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 128)    512         conv2_128_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_128_5 (Conv2D)            (None, 6, 6, 256)    819456      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_128_6 (Conv2D)            (None, 6, 6, 256)    1638656     conv2_128_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 6, 256)    1024        conv2_128_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 5, 5, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 5, 256)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv256_1 (Conv2D)              (None, 5, 5, 256)    1638656     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv256_2 (Conv2D)              (None, 5, 5, 256)    1638656     conv256_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv256_3 (Conv2D)              (None, 5, 5, 256)    1638656     conv256_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 5, 5, 256)    1024        conv256_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_512_1 (Conv2D)            (None, 4, 4, 512)    3277312     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_512_2 (Conv2D)            (None, 4, 4, 512)    6554112     conv2_512_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        conv2_512_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 3, 3, 512)    0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4608)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC1_2048 (Dense)                (None, 2048)         9439232     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC1_1024 (Dense)                (None, 1024)         2098176     FC1_2048[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FC2_1024 (Dense)                (None, 1024)         1049600     FC1_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "num (Dense)                     (None, 5)            5125        FC2_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dig1 (Dense)                    (None, 11)           11275       FC2_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dig2 (Dense)                    (None, 11)           11275       FC2_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dig3 (Dense)                    (None, 11)           11275       FC2_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dig4 (Dense)                    (None, 11)           11275       FC2_1024[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "nC (Dense)                      (None, 2)            2050        FC2_1024[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,027,299\n",
      "Trainable params: 31,024,675\n",
      "Non-trainable params: 2,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_,row, col,channel = X_train.shape\n",
    "digLen = 5 # including category 0\n",
    "numDigits = 11\n",
    "epochs = 75\n",
    "batch_size = 64\n",
    "\n",
    "optim = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "# optim = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.Session(config = config)\n",
    "\n",
    "input = keras.Input(shape=(row,col,channel), name='customModel')\n",
    "M = Conv2D(16,(3,3),activation='relu',padding='same',name = 'conv_16_1')(input)\n",
    "M = Conv2D(16,(3, 3), activation ='relu', padding='same',name = 'conv_16_2')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2))(M)\n",
    "\n",
    "M = Conv2D(32, (3, 3), activation ='relu', padding='same', name = 'conv2_32_01')(M)\n",
    "M = Conv2D(32, (3, 3), activation ='relu', padding='same', name = 'conv2_32_02')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2))(M)\n",
    "M = Dropout(0.5)(M)\n",
    "\n",
    "M = Conv2D(48, (3, 3), activation ='relu', padding='same', name = 'conv2_48_01')(M)\n",
    "M = Conv2D(48, (3, 3), activation ='relu', padding='same', name = 'conv2_48_02')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2))(M)\n",
    "\n",
    "M = Conv2D(64, (3, 3), activation ='relu', padding='same',name = 'conv2_64_1')(M)\n",
    "M = Conv2D(64, (3, 3), activation ='relu', padding='same', name = 'conv2_64_2')(M)\n",
    "M = Conv2D(64, (3, 3), activation ='relu', padding='same',name = 'conv2_64_3')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D((2, 2), strides= 1)(M)\n",
    "\n",
    "M = Conv2D(128, kernel_size=(5, 5), activation='relu', padding='same',name = 'conv2_128_1')(M)\n",
    "M = Conv2D(128, kernel_size=(5, 5), activation='relu', padding='same',name = 'conv2_128_2')(M)\n",
    "M = Conv2D(128, kernel_size=(5, 5), activation='relu', padding='same',name = 'conv2_128_3')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2),strides = 1)(M)\n",
    "\n",
    "M = Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same',name = 'conv2_128_5')(M)\n",
    "M = Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same',name = 'conv2_128_6')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2),strides = 1)(M)\n",
    "M = Dropout(0.5)(M)\n",
    "\n",
    "M = Conv2D(256, (5, 5), activation='relu', padding='same',name = 'conv256_1')(M)\n",
    "M = Conv2D(256, (5, 5), activation='relu', padding='same',name = 'conv256_2')(M)\n",
    "M = Conv2D(256, (5, 5), activation='relu', padding='same',name = 'conv256_3')(M)\n",
    "            # kernel_regularizer=regularizers.l2(0.01),\n",
    "            # activity_regularizer=regularizers.l1(0.01))(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D((2, 2), strides= 1)(M)\n",
    "\n",
    "M = Conv2D(512, (5, 5), activation='relu', padding='same',name = 'conv2_512_1')(M)\n",
    "M = Conv2D(512, (5, 5), activation='relu', padding='same',name = 'conv2_512_2')(M)\n",
    "M = BatchNormalization(axis=-1)(M)\n",
    "M = MaxPooling2D(pool_size=(2, 2),strides= 1)(M)\n",
    "M = Dropout(0.25)(M)\n",
    "# M = keras.layers.BatchNormalization(axis=-1)(M)\n",
    "\n",
    "Mout = Flatten()(M)\n",
    "Mout = Dense(2048, activation='relu', name = 'FC1_2048')(Mout)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_1024')(Mout)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC2_1024')(Mout)\n",
    "# Mout = Dropout(0.5)(Mout)\n",
    "\n",
    "numd_SM = Dense(digLen,    activation='softmax',name = 'num')(Mout)\n",
    "dig1_SM = Dense(numDigits, activation='softmax',name = 'dig1')(Mout)\n",
    "dig2_SM = Dense(numDigits, activation='softmax',name = 'dig2')(Mout)\n",
    "dig3_SM = Dense(numDigits, activation='softmax',name = 'dig3')(Mout)\n",
    "dig4_SM = Dense(numDigits, activation='softmax',name = 'dig4')(Mout)\n",
    "numB_SM = Dense(2,         activation='softmax',name = 'nC')(Mout)\n",
    "out = [numd_SM, dig1_SM ,dig2_SM, dig3_SM, dig4_SM, numB_SM]\n",
    "\n",
    "svhnModel = keras.Model(inputs = input, outputs = out)\n",
    "\n",
    "lr_metric = get_lr_metric(optim)\n",
    "svhnModel.compile(loss = 'sparse_categorical_crossentropy', #ceLoss ,\n",
    "                  optimizer= optim,\n",
    "                  metrics=  ['accuracy']) #[])\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                              factor = 0.1,\n",
    "                                              verbose = 1,\n",
    "                                              patience= 2,\n",
    "                                              cooldown= 1,\n",
    "                                              min_lr = 0.00001)\n",
    "svhnModel.summary()\n",
    "\n",
    "callback = []\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='saved_models/designedBGRClassifier.hdf5',\n",
    "                                               monitor='loss',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=2)\n",
    "tb = keras.callbacks.TensorBoard(log_dir = 'logs',\n",
    "                                  write_graph = True,\n",
    "                                  batch_size = batch_size,\n",
    "                                  write_images = True)\n",
    "es = keras.callbacks.EarlyStopping(monitor= 'loss',  #'dig1_loss',\n",
    "                                   min_delta=0.000001,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   mode='auto')\n",
    "callback.append(tb)\n",
    "callback.append(es)\n",
    "callback.append(checkpointer)\n",
    "callback.append(reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/75\n",
      "69076/69076 [==============================] - 162s 2ms/step - loss: 3.5808 - num_loss: 0.7027 - dig1_loss: 1.0480 - dig2_loss: 0.9620 - dig3_loss: 0.4927 - dig4_loss: 0.1048 - nC_loss: 0.2706 - num_acc: 0.7648 - dig1_acc: 0.6789 - dig2_acc: 0.7108 - dig3_acc: 0.8972 - dig4_acc: 0.9849 - nC_acc: 0.9057 - val_loss: 4.7780 - val_num_loss: 1.0115 - val_dig1_loss: 1.3837 - val_dig2_loss: 1.1193 - val_dig3_loss: 0.5255 - val_dig4_loss: 0.0971 - val_nC_loss: 0.6409 - val_num_acc: 0.7546 - val_dig1_acc: 0.6833 - val_dig2_acc: 0.7012 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9080\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.58076, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 2/75\n",
      "69076/69076 [==============================] - 129s 2ms/step - loss: 2.9905 - num_loss: 0.4987 - dig1_loss: 0.9267 - dig2_loss: 0.8845 - dig3_loss: 0.4333 - dig4_loss: 0.0931 - nC_loss: 0.1541 - num_acc: 0.8188 - dig1_acc: 0.6973 - dig2_acc: 0.7107 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.9533 - val_loss: 2.6766 - val_num_loss: 0.3709 - val_dig1_loss: 0.8822 - val_dig2_loss: 0.8566 - val_dig3_loss: 0.3719 - val_dig4_loss: 0.0740 - val_nC_loss: 0.1210 - val_num_acc: 0.8691 - val_dig1_acc: 0.7032 - val_dig2_acc: 0.7049 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9636\n",
      "\n",
      "Epoch 00002: loss improved from 3.58076 to 2.99049, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 3/75\n",
      "69076/69076 [==============================] - 147s 2ms/step - loss: 2.5889 - num_loss: 0.3493 - dig1_loss: 0.8542 - dig2_loss: 0.8374 - dig3_loss: 0.3738 - dig4_loss: 0.0841 - nC_loss: 0.0901 - num_acc: 0.8799 - dig1_acc: 0.7045 - dig2_acc: 0.7100 - dig3_acc: 0.8980 - dig4_acc: 0.9858 - nC_acc: 0.9725 - val_loss: 4.6153 - val_num_loss: 1.0258 - val_dig1_loss: 1.2627 - val_dig2_loss: 1.1581 - val_dig3_loss: 0.5606 - val_dig4_loss: 0.1048 - val_nC_loss: 0.5033 - val_num_acc: 0.7186 - val_dig1_acc: 0.6660 - val_dig2_acc: 0.7064 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.8478\n",
      "\n",
      "Epoch 00003: loss improved from 2.99049 to 2.58887, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 4/75\n",
      "69076/69076 [==============================] - 131s 2ms/step - loss: 2.4295 - num_loss: 0.2793 - dig1_loss: 0.8338 - dig2_loss: 0.8167 - dig3_loss: 0.3467 - dig4_loss: 0.0801 - nC_loss: 0.0729 - num_acc: 0.9107 - dig1_acc: 0.7071 - dig2_acc: 0.7102 - dig3_acc: 0.8977 - dig4_acc: 0.9858 - nC_acc: 0.9790 - val_loss: 2.3650 - val_num_loss: 0.2441 - val_dig1_loss: 0.8140 - val_dig2_loss: 0.8238 - val_dig3_loss: 0.3542 - val_dig4_loss: 0.0741 - val_nC_loss: 0.0549 - val_num_acc: 0.9247 - val_dig1_acc: 0.7100 - val_dig2_acc: 0.7091 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9840\n",
      "\n",
      "Epoch 00004: loss improved from 2.58887 to 2.42951, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 5/75\n",
      "69076/69076 [==============================] - 153s 2ms/step - loss: 2.3152 - num_loss: 0.2257 - dig1_loss: 0.8183 - dig2_loss: 0.8007 - dig3_loss: 0.3321 - dig4_loss: 0.0796 - nC_loss: 0.0588 - num_acc: 0.9305 - dig1_acc: 0.7095 - dig2_acc: 0.7097 - dig3_acc: 0.8976 - dig4_acc: 0.9858 - nC_acc: 0.9829 - val_loss: 2.1780 - val_num_loss: 0.1649 - val_dig1_loss: 0.7900 - val_dig2_loss: 0.7999 - val_dig3_loss: 0.3161 - val_dig4_loss: 0.0702 - val_nC_loss: 0.0369 - val_num_acc: 0.9469 - val_dig1_acc: 0.7150 - val_dig2_acc: 0.7112 - val_dig3_acc: 0.8953 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9898\n",
      "\n",
      "Epoch 00005: loss improved from 2.42951 to 2.31517, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 6/75\n",
      "69076/69076 [==============================] - 152s 2ms/step - loss: 2.2065 - num_loss: 0.1826 - dig1_loss: 0.7993 - dig2_loss: 0.7869 - dig3_loss: 0.3170 - dig4_loss: 0.0749 - nC_loss: 0.0457 - num_acc: 0.9407 - dig1_acc: 0.7184 - dig2_acc: 0.7130 - dig3_acc: 0.8972 - dig4_acc: 0.9858 - nC_acc: 0.9860 - val_loss: 2.1866 - val_num_loss: 0.1778 - val_dig1_loss: 0.7626 - val_dig2_loss: 0.7956 - val_dig3_loss: 0.3395 - val_dig4_loss: 0.0739 - val_nC_loss: 0.0372 - val_num_acc: 0.9374 - val_dig1_acc: 0.7372 - val_dig2_acc: 0.7053 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9890\n",
      "\n",
      "Epoch 00006: loss improved from 2.31517 to 2.20652, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 7/75\n",
      "69076/69076 [==============================] - 94s 1ms/step - loss: 2.1197 - num_loss: 0.1624 - dig1_loss: 0.7518 - dig2_loss: 0.7835 - dig3_loss: 0.3125 - dig4_loss: 0.0701 - nC_loss: 0.0393 - num_acc: 0.9471 - dig1_acc: 0.7358 - dig2_acc: 0.7110 - dig3_acc: 0.8976 - dig4_acc: 0.9858 - nC_acc: 0.9879 - val_loss: 2.0293 - val_num_loss: 0.1307 - val_dig1_loss: 0.7031 - val_dig2_loss: 0.7912 - val_dig3_loss: 0.3165 - val_dig4_loss: 0.0579 - val_nC_loss: 0.0300 - val_num_acc: 0.9566 - val_dig1_acc: 0.7528 - val_dig2_acc: 0.7073 - val_dig3_acc: 0.8952 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9909\n",
      "\n",
      "Epoch 00007: loss improved from 2.20652 to 2.11971, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 8/75\n",
      "69076/69076 [==============================] - 94s 1ms/step - loss: 2.3298 - num_loss: 0.2406 - dig1_loss: 0.7906 - dig2_loss: 0.8087 - dig3_loss: 0.3345 - dig4_loss: 0.0719 - nC_loss: 0.0835 - num_acc: 0.9228 - dig1_acc: 0.7319 - dig2_acc: 0.7121 - dig3_acc: 0.8975 - dig4_acc: 0.9858 - nC_acc: 0.9739 - val_loss: 2.1611 - val_num_loss: 0.1993 - val_dig1_loss: 0.7183 - val_dig2_loss: 0.7957 - val_dig3_loss: 0.3255 - val_dig4_loss: 0.0764 - val_nC_loss: 0.0459 - val_num_acc: 0.9202 - val_dig1_acc: 0.7431 - val_dig2_acc: 0.7115 - val_dig3_acc: 0.8929 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9853\n",
      "\n",
      "Epoch 00008: loss did not improve from 2.11971\n",
      "Epoch 9/75\n",
      "69076/69076 [==============================] - 94s 1ms/step - loss: 2.0579 - num_loss: 0.1535 - dig1_loss: 0.7031 - dig2_loss: 0.7829 - dig3_loss: 0.3102 - dig4_loss: 0.0639 - nC_loss: 0.0443 - num_acc: 0.9511 - dig1_acc: 0.7537 - dig2_acc: 0.7142 - dig3_acc: 0.8973 - dig4_acc: 0.9858 - nC_acc: 0.9866 - val_loss: 2.0356 - val_num_loss: 0.1441 - val_dig1_loss: 0.6750 - val_dig2_loss: 0.7929 - val_dig3_loss: 0.3174 - val_dig4_loss: 0.0634 - val_nC_loss: 0.0428 - val_num_acc: 0.9522 - val_dig1_acc: 0.7604 - val_dig2_acc: 0.7129 - val_dig3_acc: 0.8966 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9846\n",
      "\n",
      "Epoch 00009: loss improved from 2.11971 to 2.05793, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/75\n",
      "69076/69076 [==============================] - 94s 1ms/step - loss: 1.9317 - num_loss: 0.1212 - dig1_loss: 0.6465 - dig2_loss: 0.7710 - dig3_loss: 0.3016 - dig4_loss: 0.0565 - nC_loss: 0.0350 - num_acc: 0.9624 - dig1_acc: 0.7719 - dig2_acc: 0.7177 - dig3_acc: 0.8982 - dig4_acc: 0.9858 - nC_acc: 0.9893 - val_loss: 1.8787 - val_num_loss: 0.1045 - val_dig1_loss: 0.6112 - val_dig2_loss: 0.7787 - val_dig3_loss: 0.3065 - val_dig4_loss: 0.0485 - val_nC_loss: 0.0294 - val_num_acc: 0.9676 - val_dig1_acc: 0.7818 - val_dig2_acc: 0.7183 - val_dig3_acc: 0.8964 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9906\n",
      "\n",
      "Epoch 00010: loss improved from 2.05793 to 1.93175, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 11/75\n",
      "69076/69076 [==============================] - 94s 1ms/step - loss: 1.8943 - num_loss: 0.1138 - dig1_loss: 0.6280 - dig2_loss: 0.7671 - dig3_loss: 0.2985 - dig4_loss: 0.0551 - nC_loss: 0.0319 - num_acc: 0.9646 - dig1_acc: 0.7791 - dig2_acc: 0.7193 - dig3_acc: 0.8984 - dig4_acc: 0.9858 - nC_acc: 0.9901 - val_loss: 1.8580 - val_num_loss: 0.1023 - val_dig1_loss: 0.5965 - val_dig2_loss: 0.7759 - val_dig3_loss: 0.3046 - val_dig4_loss: 0.0477 - val_nC_loss: 0.0310 - val_num_acc: 0.9673 - val_dig1_acc: 0.7859 - val_dig2_acc: 0.7193 - val_dig3_acc: 0.8969 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9897\n",
      "\n",
      "Epoch 00011: loss improved from 1.93175 to 1.89434, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 12/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 95s 1ms/step - loss: 1.8797 - num_loss: 0.1102 - dig1_loss: 0.6205 - dig2_loss: 0.7661 - dig3_loss: 0.2977 - dig4_loss: 0.0548 - nC_loss: 0.0305 - num_acc: 0.9653 - dig1_acc: 0.7797 - dig2_acc: 0.7195 - dig3_acc: 0.8983 - dig4_acc: 0.9858 - nC_acc: 0.9905 - val_loss: 1.8421 - val_num_loss: 0.0988 - val_dig1_loss: 0.5886 - val_dig2_loss: 0.7743 - val_dig3_loss: 0.3034 - val_dig4_loss: 0.0475 - val_nC_loss: 0.0294 - val_num_acc: 0.9686 - val_dig1_acc: 0.7903 - val_dig2_acc: 0.7185 - val_dig3_acc: 0.8973 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9902\n",
      "\n",
      "Epoch 00012: loss improved from 1.89434 to 1.87970, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 13/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.8673 - num_loss: 0.1092 - dig1_loss: 0.6115 - dig2_loss: 0.7645 - dig3_loss: 0.2976 - dig4_loss: 0.0543 - nC_loss: 0.0302 - num_acc: 0.9658 - dig1_acc: 0.7837 - dig2_acc: 0.7200 - dig3_acc: 0.8983 - dig4_acc: 0.9857 - nC_acc: 0.9907 - val_loss: 1.8315 - val_num_loss: 0.0957 - val_dig1_loss: 0.5858 - val_dig2_loss: 0.7739 - val_dig3_loss: 0.3012 - val_dig4_loss: 0.0473 - val_nC_loss: 0.0278 - val_num_acc: 0.9693 - val_dig1_acc: 0.7907 - val_dig2_acc: 0.7188 - val_dig3_acc: 0.8977 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9907\n",
      "\n",
      "Epoch 00013: loss improved from 1.87970 to 1.86727, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 14/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.8479 - num_loss: 0.1044 - dig1_loss: 0.6026 - dig2_loss: 0.7630 - dig3_loss: 0.2963 - dig4_loss: 0.0535 - nC_loss: 0.0282 - num_acc: 0.9666 - dig1_acc: 0.7876 - dig2_acc: 0.7201 - dig3_acc: 0.8982 - dig4_acc: 0.9857 - nC_acc: 0.9909 - val_loss: 1.8227 - val_num_loss: 0.0978 - val_dig1_loss: 0.5743 - val_dig2_loss: 0.7720 - val_dig3_loss: 0.3025 - val_dig4_loss: 0.0472 - val_nC_loss: 0.0290 - val_num_acc: 0.9687 - val_dig1_acc: 0.7967 - val_dig2_acc: 0.7210 - val_dig3_acc: 0.8976 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9905\n",
      "\n",
      "Epoch 00014: loss improved from 1.86727 to 1.84793, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 15/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.8416 - num_loss: 0.1047 - dig1_loss: 0.5957 - dig2_loss: 0.7627 - dig3_loss: 0.2967 - dig4_loss: 0.0538 - nC_loss: 0.0279 - num_acc: 0.9672 - dig1_acc: 0.7892 - dig2_acc: 0.7205 - dig3_acc: 0.8984 - dig4_acc: 0.9857 - nC_acc: 0.9909 - val_loss: 1.8155 - val_num_loss: 0.0989 - val_dig1_loss: 0.5650 - val_dig2_loss: 0.7712 - val_dig3_loss: 0.3039 - val_dig4_loss: 0.0471 - val_nC_loss: 0.0294 - val_num_acc: 0.9685 - val_dig1_acc: 0.7980 - val_dig2_acc: 0.7205 - val_dig3_acc: 0.8977 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9895\n",
      "\n",
      "Epoch 00015: loss improved from 1.84793 to 1.84160, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 16/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.8265 - num_loss: 0.1019 - dig1_loss: 0.5874 - dig2_loss: 0.7598 - dig3_loss: 0.2968 - dig4_loss: 0.0528 - nC_loss: 0.0277 - num_acc: 0.9682 - dig1_acc: 0.7919 - dig2_acc: 0.7226 - dig3_acc: 0.8985 - dig4_acc: 0.9858 - nC_acc: 0.9911 - val_loss: 1.8083 - val_num_loss: 0.1007 - val_dig1_loss: 0.5569 - val_dig2_loss: 0.7701 - val_dig3_loss: 0.3020 - val_dig4_loss: 0.0471 - val_nC_loss: 0.0314 - val_num_acc: 0.9678 - val_dig1_acc: 0.8016 - val_dig2_acc: 0.7198 - val_dig3_acc: 0.8966 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9889\n",
      "\n",
      "Epoch 00016: loss improved from 1.84160 to 1.82652, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 17/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.8162 - num_loss: 0.1014 - dig1_loss: 0.5807 - dig2_loss: 0.7588 - dig3_loss: 0.2958 - dig4_loss: 0.0527 - nC_loss: 0.0268 - num_acc: 0.9683 - dig1_acc: 0.7949 - dig2_acc: 0.7224 - dig3_acc: 0.8987 - dig4_acc: 0.9857 - nC_acc: 0.9913 - val_loss: 1.7943 - val_num_loss: 0.0978 - val_dig1_loss: 0.5505 - val_dig2_loss: 0.7674 - val_dig3_loss: 0.3020 - val_dig4_loss: 0.0471 - val_nC_loss: 0.0295 - val_num_acc: 0.9689 - val_dig1_acc: 0.8030 - val_dig2_acc: 0.7230 - val_dig3_acc: 0.8975 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9899\n",
      "\n",
      "Epoch 00017: loss improved from 1.82652 to 1.81623, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 18/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.8089 - num_loss: 0.1018 - dig1_loss: 0.5741 - dig2_loss: 0.7579 - dig3_loss: 0.2955 - dig4_loss: 0.0525 - nC_loss: 0.0270 - num_acc: 0.9681 - dig1_acc: 0.7991 - dig2_acc: 0.7236 - dig3_acc: 0.8981 - dig4_acc: 0.9857 - nC_acc: 0.9915 - val_loss: 1.7882 - val_num_loss: 0.1008 - val_dig1_loss: 0.5385 - val_dig2_loss: 0.7674 - val_dig3_loss: 0.3049 - val_dig4_loss: 0.0471 - val_nC_loss: 0.0295 - val_num_acc: 0.9691 - val_dig1_acc: 0.8066 - val_dig2_acc: 0.7196 - val_dig3_acc: 0.8975 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9897\n",
      "\n",
      "Epoch 00018: loss improved from 1.81623 to 1.80885, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 19/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.7952 - num_loss: 0.0992 - dig1_loss: 0.5663 - dig2_loss: 0.7552 - dig3_loss: 0.2957 - dig4_loss: 0.0521 - nC_loss: 0.0266 - num_acc: 0.9695 - dig1_acc: 0.8008 - dig2_acc: 0.7247 - dig3_acc: 0.8986 - dig4_acc: 0.9856 - nC_acc: 0.9917 - val_loss: 1.7781 - val_num_loss: 0.0966 - val_dig1_loss: 0.5371 - val_dig2_loss: 0.7653 - val_dig3_loss: 0.3030 - val_dig4_loss: 0.0469 - val_nC_loss: 0.0292 - val_num_acc: 0.9697 - val_dig1_acc: 0.8098 - val_dig2_acc: 0.7220 - val_dig3_acc: 0.8972 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9902\n",
      "\n",
      "Epoch 00019: loss improved from 1.80885 to 1.79524, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 20/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.7815 - num_loss: 0.0998 - dig1_loss: 0.5543 - dig2_loss: 0.7540 - dig3_loss: 0.2955 - dig4_loss: 0.0522 - nC_loss: 0.0258 - num_acc: 0.9691 - dig1_acc: 0.8059 - dig2_acc: 0.7256 - dig3_acc: 0.8983 - dig4_acc: 0.9857 - nC_acc: 0.9919 - val_loss: 1.7552 - val_num_loss: 0.0937 - val_dig1_loss: 0.5252 - val_dig2_loss: 0.7611 - val_dig3_loss: 0.3007 - val_dig4_loss: 0.0468 - val_nC_loss: 0.0277 - val_num_acc: 0.9716 - val_dig1_acc: 0.8161 - val_dig2_acc: 0.7251 - val_dig3_acc: 0.8974 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9904\n",
      "\n",
      "Epoch 00020: loss improved from 1.79524 to 1.78150, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 21/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.7649 - num_loss: 0.0970 - dig1_loss: 0.5464 - dig2_loss: 0.7498 - dig3_loss: 0.2944 - dig4_loss: 0.0517 - nC_loss: 0.0256 - num_acc: 0.9710 - dig1_acc: 0.8101 - dig2_acc: 0.7279 - dig3_acc: 0.8986 - dig4_acc: 0.9857 - nC_acc: 0.9922 - val_loss: 1.7447 - val_num_loss: 0.0965 - val_dig1_loss: 0.5150 - val_dig2_loss: 0.7551 - val_dig3_loss: 0.3023 - val_dig4_loss: 0.0464 - val_nC_loss: 0.0292 - val_num_acc: 0.9706 - val_dig1_acc: 0.8201 - val_dig2_acc: 0.7294 - val_dig3_acc: 0.8970 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9904\n",
      "\n",
      "Epoch 00021: loss improved from 1.78150 to 1.76488, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 22/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.7526 - num_loss: 0.0979 - dig1_loss: 0.5364 - dig2_loss: 0.7457 - dig3_loss: 0.2945 - dig4_loss: 0.0519 - nC_loss: 0.0261 - num_acc: 0.9701 - dig1_acc: 0.8146 - dig2_acc: 0.7289 - dig3_acc: 0.8983 - dig4_acc: 0.9858 - nC_acc: 0.9919 - val_loss: 1.7390 - val_num_loss: 0.1013 - val_dig1_loss: 0.5040 - val_dig2_loss: 0.7505 - val_dig3_loss: 0.3075 - val_dig4_loss: 0.0476 - val_nC_loss: 0.0280 - val_num_acc: 0.9695 - val_dig1_acc: 0.8260 - val_dig2_acc: 0.7284 - val_dig3_acc: 0.8973 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9902\n",
      "\n",
      "Epoch 00022: loss improved from 1.76488 to 1.75255, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 23/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.7358 - num_loss: 0.0968 - dig1_loss: 0.5298 - dig2_loss: 0.7373 - dig3_loss: 0.2943 - dig4_loss: 0.0524 - nC_loss: 0.0252 - num_acc: 0.9707 - dig1_acc: 0.8165 - dig2_acc: 0.7333 - dig3_acc: 0.8984 - dig4_acc: 0.9857 - nC_acc: 0.9922 - val_loss: 1.7094 - val_num_loss: 0.0969 - val_dig1_loss: 0.4990 - val_dig2_loss: 0.7354 - val_dig3_loss: 0.3034 - val_dig4_loss: 0.0470 - val_nC_loss: 0.0277 - val_num_acc: 0.9711 - val_dig1_acc: 0.8267 - val_dig2_acc: 0.7372 - val_dig3_acc: 0.8964 - val_dig4_acc: 0.9852 - val_nC_acc: 0.9907\n",
      "\n",
      "Epoch 00023: loss improved from 1.75255 to 1.73582, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 24/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.7161 - num_loss: 0.0959 - dig1_loss: 0.5211 - dig2_loss: 0.7276 - dig3_loss: 0.2951 - dig4_loss: 0.0521 - nC_loss: 0.0243 - num_acc: 0.9714 - dig1_acc: 0.8195 - dig2_acc: 0.7365 - dig3_acc: 0.8980 - dig4_acc: 0.9856 - nC_acc: 0.9925 - val_loss: 1.7124 - val_num_loss: 0.1024 - val_dig1_loss: 0.5066 - val_dig2_loss: 0.7219 - val_dig3_loss: 0.3045 - val_dig4_loss: 0.0467 - val_nC_loss: 0.0304 - val_num_acc: 0.9693 - val_dig1_acc: 0.8234 - val_dig2_acc: 0.7408 - val_dig3_acc: 0.8974 - val_dig4_acc: 0.9854 - val_nC_acc: 0.9898\n",
      "\n",
      "Epoch 00024: loss improved from 1.73582 to 1.71609, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 25/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6953 - num_loss: 0.0946 - dig1_loss: 0.5129 - dig2_loss: 0.7185 - dig3_loss: 0.2950 - dig4_loss: 0.0509 - nC_loss: 0.0233 - num_acc: 0.9721 - dig1_acc: 0.8245 - dig2_acc: 0.7399 - dig3_acc: 0.8980 - dig4_acc: 0.9857 - nC_acc: 0.9930 - val_loss: 1.7072 - val_num_loss: 0.1083 - val_dig1_loss: 0.4884 - val_dig2_loss: 0.7211 - val_dig3_loss: 0.3107 - val_dig4_loss: 0.0481 - val_nC_loss: 0.0306 - val_num_acc: 0.9686 - val_dig1_acc: 0.8345 - val_dig2_acc: 0.7380 - val_dig3_acc: 0.8973 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9903\n",
      "\n",
      "Epoch 00025: loss improved from 1.71609 to 1.69531, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 26/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6791 - num_loss: 0.0929 - dig1_loss: 0.5088 - dig2_loss: 0.7106 - dig3_loss: 0.2940 - dig4_loss: 0.0509 - nC_loss: 0.0221 - num_acc: 0.9724 - dig1_acc: 0.8258 - dig2_acc: 0.7417 - dig3_acc: 0.8981 - dig4_acc: 0.9856 - nC_acc: 0.9929 - val_loss: 1.6569 - val_num_loss: 0.0969 - val_dig1_loss: 0.4753 - val_dig2_loss: 0.7050 - val_dig3_loss: 0.3056 - val_dig4_loss: 0.0457 - val_nC_loss: 0.0284 - val_num_acc: 0.9736 - val_dig1_acc: 0.8373 - val_dig2_acc: 0.7447 - val_dig3_acc: 0.8971 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9913\n",
      "\n",
      "Epoch 00026: loss improved from 1.69531 to 1.67914, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 27/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6622 - num_loss: 0.0923 - dig1_loss: 0.4985 - dig2_loss: 0.7038 - dig3_loss: 0.2937 - dig4_loss: 0.0508 - nC_loss: 0.0232 - num_acc: 0.9732 - dig1_acc: 0.8293 - dig2_acc: 0.7435 - dig3_acc: 0.8984 - dig4_acc: 0.9857 - nC_acc: 0.9927 - val_loss: 1.6688 - val_num_loss: 0.0971 - val_dig1_loss: 0.4938 - val_dig2_loss: 0.6987 - val_dig3_loss: 0.3027 - val_dig4_loss: 0.0458 - val_nC_loss: 0.0307 - val_num_acc: 0.9730 - val_dig1_acc: 0.8329 - val_dig2_acc: 0.7413 - val_dig3_acc: 0.8968 - val_dig4_acc: 0.9854 - val_nC_acc: 0.9904\n",
      "\n",
      "Epoch 00027: loss improved from 1.67914 to 1.66221, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 28/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6501 - num_loss: 0.0920 - dig1_loss: 0.4926 - dig2_loss: 0.6978 - dig3_loss: 0.2938 - dig4_loss: 0.0507 - nC_loss: 0.0232 - num_acc: 0.9733 - dig1_acc: 0.8318 - dig2_acc: 0.7447 - dig3_acc: 0.8985 - dig4_acc: 0.9860 - nC_acc: 0.9929 - val_loss: 1.6452 - val_num_loss: 0.1009 - val_dig1_loss: 0.4714 - val_dig2_loss: 0.6909 - val_dig3_loss: 0.3055 - val_dig4_loss: 0.0481 - val_nC_loss: 0.0284 - val_num_acc: 0.9704 - val_dig1_acc: 0.8431 - val_dig2_acc: 0.7436 - val_dig3_acc: 0.8967 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9900\n",
      "\n",
      "Epoch 00028: loss improved from 1.66221 to 1.65013, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 29/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6385 - num_loss: 0.0928 - dig1_loss: 0.4861 - dig2_loss: 0.6926 - dig3_loss: 0.2933 - dig4_loss: 0.0512 - nC_loss: 0.0224 - num_acc: 0.9729 - dig1_acc: 0.8364 - dig2_acc: 0.7461 - dig3_acc: 0.8986 - dig4_acc: 0.9857 - nC_acc: 0.9934 - val_loss: 1.6388 - val_num_loss: 0.1028 - val_dig1_loss: 0.4633 - val_dig2_loss: 0.6891 - val_dig3_loss: 0.3066 - val_dig4_loss: 0.0482 - val_nC_loss: 0.0287 - val_num_acc: 0.9702 - val_dig1_acc: 0.8456 - val_dig2_acc: 0.7502 - val_dig3_acc: 0.8971 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9905\n",
      "\n",
      "Epoch 00029: loss improved from 1.65013 to 1.63847, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 30/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6255 - num_loss: 0.0903 - dig1_loss: 0.4818 - dig2_loss: 0.6875 - dig3_loss: 0.2920 - dig4_loss: 0.0510 - nC_loss: 0.0231 - num_acc: 0.9740 - dig1_acc: 0.8383 - dig2_acc: 0.7494 - dig3_acc: 0.8987 - dig4_acc: 0.9857 - nC_acc: 0.9928 - val_loss: 1.6137 - val_num_loss: 0.0946 - val_dig1_loss: 0.4614 - val_dig2_loss: 0.6816 - val_dig3_loss: 0.3026 - val_dig4_loss: 0.0473 - val_nC_loss: 0.0261 - val_num_acc: 0.9727 - val_dig1_acc: 0.8475 - val_dig2_acc: 0.7506 - val_dig3_acc: 0.8973 - val_dig4_acc: 0.9857 - val_nC_acc: 0.9913\n",
      "\n",
      "Epoch 00030: loss improved from 1.63847 to 1.62555, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 31/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.6074 - num_loss: 0.0888 - dig1_loss: 0.4740 - dig2_loss: 0.6804 - dig3_loss: 0.2921 - dig4_loss: 0.0502 - nC_loss: 0.0220 - num_acc: 0.9745 - dig1_acc: 0.8402 - dig2_acc: 0.7525 - dig3_acc: 0.8984 - dig4_acc: 0.9856 - nC_acc: 0.9931 - val_loss: 1.5967 - val_num_loss: 0.0916 - val_dig1_loss: 0.4552 - val_dig2_loss: 0.6751 - val_dig3_loss: 0.3015 - val_dig4_loss: 0.0470 - val_nC_loss: 0.0263 - val_num_acc: 0.9731 - val_dig1_acc: 0.8503 - val_dig2_acc: 0.7558 - val_dig3_acc: 0.8966 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9911\n",
      "\n",
      "Epoch 00031: loss improved from 1.62555 to 1.60740, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 32/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.5868 - num_loss: 0.0855 - dig1_loss: 0.4683 - dig2_loss: 0.6700 - dig3_loss: 0.2916 - dig4_loss: 0.0498 - nC_loss: 0.0215 - num_acc: 0.9746 - dig1_acc: 0.8432 - dig2_acc: 0.7556 - dig3_acc: 0.8982 - dig4_acc: 0.9857 - nC_acc: 0.9931 - val_loss: 1.5841 - val_num_loss: 0.0917 - val_dig1_loss: 0.4533 - val_dig2_loss: 0.6644 - val_dig3_loss: 0.3020 - val_dig4_loss: 0.0468 - val_nC_loss: 0.0260 - val_num_acc: 0.9743 - val_dig1_acc: 0.8526 - val_dig2_acc: 0.7596 - val_dig3_acc: 0.8969 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9917\n",
      "\n",
      "Epoch 00032: loss improved from 1.60740 to 1.58681, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 33/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.5775 - num_loss: 0.0867 - dig1_loss: 0.4643 - dig2_loss: 0.6632 - dig3_loss: 0.2920 - dig4_loss: 0.0495 - nC_loss: 0.0217 - num_acc: 0.9744 - dig1_acc: 0.8468 - dig2_acc: 0.7578 - dig3_acc: 0.8986 - dig4_acc: 0.9857 - nC_acc: 0.9930 - val_loss: 1.5716 - val_num_loss: 0.0924 - val_dig1_loss: 0.4471 - val_dig2_loss: 0.6560 - val_dig3_loss: 0.3035 - val_dig4_loss: 0.0456 - val_nC_loss: 0.0270 - val_num_acc: 0.9752 - val_dig1_acc: 0.8552 - val_dig2_acc: 0.7592 - val_dig3_acc: 0.8966 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9925\n",
      "\n",
      "Epoch 00033: loss improved from 1.58681 to 1.57753, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 34/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.5607 - num_loss: 0.0853 - dig1_loss: 0.4585 - dig2_loss: 0.6550 - dig3_loss: 0.2916 - dig4_loss: 0.0490 - nC_loss: 0.0214 - num_acc: 0.9753 - dig1_acc: 0.8475 - dig2_acc: 0.7612 - dig3_acc: 0.8982 - dig4_acc: 0.9857 - nC_acc: 0.9930 - val_loss: 1.5678 - val_num_loss: 0.0958 - val_dig1_loss: 0.4444 - val_dig2_loss: 0.6500 - val_dig3_loss: 0.3009 - val_dig4_loss: 0.0499 - val_nC_loss: 0.0267 - val_num_acc: 0.9717 - val_dig1_acc: 0.8555 - val_dig2_acc: 0.7645 - val_dig3_acc: 0.8976 - val_dig4_acc: 0.9856 - val_nC_acc: 0.9917\n",
      "\n",
      "Epoch 00034: loss improved from 1.57753 to 1.56069, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 35/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.5456 - num_loss: 0.0847 - dig1_loss: 0.4505 - dig2_loss: 0.6483 - dig3_loss: 0.2916 - dig4_loss: 0.0496 - nC_loss: 0.0210 - num_acc: 0.9756 - dig1_acc: 0.8524 - dig2_acc: 0.7622 - dig3_acc: 0.8981 - dig4_acc: 0.9857 - nC_acc: 0.9935 - val_loss: 1.5444 - val_num_loss: 0.0993 - val_dig1_loss: 0.4273 - val_dig2_loss: 0.6386 - val_dig3_loss: 0.3007 - val_dig4_loss: 0.0520 - val_nC_loss: 0.0265 - val_num_acc: 0.9730 - val_dig1_acc: 0.8635 - val_dig2_acc: 0.7684 - val_dig3_acc: 0.8969 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00035: loss improved from 1.56069 to 1.54564, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 36/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.5284 - num_loss: 0.0840 - dig1_loss: 0.4433 - dig2_loss: 0.6388 - dig3_loss: 0.2912 - dig4_loss: 0.0498 - nC_loss: 0.0213 - num_acc: 0.9751 - dig1_acc: 0.8551 - dig2_acc: 0.7678 - dig3_acc: 0.8983 - dig4_acc: 0.9857 - nC_acc: 0.9931 - val_loss: 1.5145 - val_num_loss: 0.0912 - val_dig1_loss: 0.4199 - val_dig2_loss: 0.6293 - val_dig3_loss: 0.3018 - val_dig4_loss: 0.0461 - val_nC_loss: 0.0263 - val_num_acc: 0.9748 - val_dig1_acc: 0.8648 - val_dig2_acc: 0.7722 - val_dig3_acc: 0.8965 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9915\n",
      "\n",
      "Epoch 00036: loss improved from 1.54564 to 1.52844, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 37/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.5060 - num_loss: 0.0808 - dig1_loss: 0.4338 - dig2_loss: 0.6321 - dig3_loss: 0.2905 - dig4_loss: 0.0490 - nC_loss: 0.0197 - num_acc: 0.9764 - dig1_acc: 0.8579 - dig2_acc: 0.7683 - dig3_acc: 0.8976 - dig4_acc: 0.9859 - nC_acc: 0.9935 - val_loss: 1.5263 - val_num_loss: 0.0994 - val_dig1_loss: 0.4131 - val_dig2_loss: 0.6319 - val_dig3_loss: 0.3050 - val_dig4_loss: 0.0517 - val_nC_loss: 0.0254 - val_num_acc: 0.9726 - val_dig1_acc: 0.8682 - val_dig2_acc: 0.7737 - val_dig3_acc: 0.8969 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9918\n",
      "\n",
      "Epoch 00037: loss improved from 1.52844 to 1.50601, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 38/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.4860 - num_loss: 0.0808 - dig1_loss: 0.4239 - dig2_loss: 0.6228 - dig3_loss: 0.2903 - dig4_loss: 0.0490 - nC_loss: 0.0192 - num_acc: 0.9767 - dig1_acc: 0.8622 - dig2_acc: 0.7726 - dig3_acc: 0.8979 - dig4_acc: 0.9858 - nC_acc: 0.9939 - val_loss: 1.4811 - val_num_loss: 0.0906 - val_dig1_loss: 0.4002 - val_dig2_loss: 0.6142 - val_dig3_loss: 0.3044 - val_dig4_loss: 0.0463 - val_nC_loss: 0.0254 - val_num_acc: 0.9749 - val_dig1_acc: 0.8729 - val_dig2_acc: 0.7785 - val_dig3_acc: 0.8968 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00038: loss improved from 1.50601 to 1.48597, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 39/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.4685 - num_loss: 0.0794 - dig1_loss: 0.4161 - dig2_loss: 0.6144 - dig3_loss: 0.2896 - dig4_loss: 0.0490 - nC_loss: 0.0199 - num_acc: 0.9773 - dig1_acc: 0.8639 - dig2_acc: 0.7746 - dig3_acc: 0.8984 - dig4_acc: 0.9856 - nC_acc: 0.9940 - val_loss: 1.4855 - val_num_loss: 0.0858 - val_dig1_loss: 0.4068 - val_dig2_loss: 0.6211 - val_dig3_loss: 0.2991 - val_dig4_loss: 0.0469 - val_nC_loss: 0.0256 - val_num_acc: 0.9754 - val_dig1_acc: 0.8699 - val_dig2_acc: 0.7733 - val_dig3_acc: 0.8963 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9918\n",
      "\n",
      "Epoch 00039: loss improved from 1.48597 to 1.46846, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 40/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.4474 - num_loss: 0.0769 - dig1_loss: 0.4092 - dig2_loss: 0.6048 - dig3_loss: 0.2891 - dig4_loss: 0.0483 - nC_loss: 0.0190 - num_acc: 0.9774 - dig1_acc: 0.8670 - dig2_acc: 0.7792 - dig3_acc: 0.8983 - dig4_acc: 0.9857 - nC_acc: 0.9941 - val_loss: 1.4637 - val_num_loss: 0.0974 - val_dig1_loss: 0.3881 - val_dig2_loss: 0.5976 - val_dig3_loss: 0.3029 - val_dig4_loss: 0.0461 - val_nC_loss: 0.0315 - val_num_acc: 0.9726 - val_dig1_acc: 0.8764 - val_dig2_acc: 0.7879 - val_dig3_acc: 0.8974 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9904\n",
      "\n",
      "Epoch 00040: loss improved from 1.46846 to 1.44742, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 41/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.4294 - num_loss: 0.0763 - dig1_loss: 0.4017 - dig2_loss: 0.5969 - dig3_loss: 0.2880 - dig4_loss: 0.0479 - nC_loss: 0.0186 - num_acc: 0.9781 - dig1_acc: 0.8702 - dig2_acc: 0.7812 - dig3_acc: 0.8987 - dig4_acc: 0.9858 - nC_acc: 0.9945 - val_loss: 1.4310 - val_num_loss: 0.0877 - val_dig1_loss: 0.3800 - val_dig2_loss: 0.5926 - val_dig3_loss: 0.2992 - val_dig4_loss: 0.0455 - val_nC_loss: 0.0260 - val_num_acc: 0.9748 - val_dig1_acc: 0.8796 - val_dig2_acc: 0.7867 - val_dig3_acc: 0.8972 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9914\n",
      "\n",
      "Epoch 00041: loss improved from 1.44742 to 1.42940, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 42/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.4081 - num_loss: 0.0734 - dig1_loss: 0.3933 - dig2_loss: 0.5884 - dig3_loss: 0.2870 - dig4_loss: 0.0478 - nC_loss: 0.0181 - num_acc: 0.9782 - dig1_acc: 0.8722 - dig2_acc: 0.7831 - dig3_acc: 0.8989 - dig4_acc: 0.9858 - nC_acc: 0.9939 - val_loss: 1.4309 - val_num_loss: 0.0911 - val_dig1_loss: 0.3807 - val_dig2_loss: 0.5839 - val_dig3_loss: 0.3027 - val_dig4_loss: 0.0460 - val_nC_loss: 0.0264 - val_num_acc: 0.9746 - val_dig1_acc: 0.8787 - val_dig2_acc: 0.7928 - val_dig3_acc: 0.8980 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9919\n",
      "\n",
      "Epoch 00042: loss improved from 1.42940 to 1.40808, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 43/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.3844 - num_loss: 0.0733 - dig1_loss: 0.3842 - dig2_loss: 0.5743 - dig3_loss: 0.2866 - dig4_loss: 0.0480 - nC_loss: 0.0180 - num_acc: 0.9787 - dig1_acc: 0.8746 - dig2_acc: 0.7891 - dig3_acc: 0.8989 - dig4_acc: 0.9856 - nC_acc: 0.9946 - val_loss: 1.4150 - val_num_loss: 0.0908 - val_dig1_loss: 0.3660 - val_dig2_loss: 0.5858 - val_dig3_loss: 0.2982 - val_dig4_loss: 0.0456 - val_nC_loss: 0.0286 - val_num_acc: 0.9738 - val_dig1_acc: 0.8856 - val_dig2_acc: 0.7860 - val_dig3_acc: 0.8984 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9913\n",
      "\n",
      "Epoch 00043: loss improved from 1.40808 to 1.38437, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 44/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.3673 - num_loss: 0.0722 - dig1_loss: 0.3785 - dig2_loss: 0.5651 - dig3_loss: 0.2863 - dig4_loss: 0.0468 - nC_loss: 0.0183 - num_acc: 0.9785 - dig1_acc: 0.8760 - dig2_acc: 0.7924 - dig3_acc: 0.8992 - dig4_acc: 0.9859 - nC_acc: 0.9942 - val_loss: 1.3867 - val_num_loss: 0.0860 - val_dig1_loss: 0.3622 - val_dig2_loss: 0.5681 - val_dig3_loss: 0.2979 - val_dig4_loss: 0.0459 - val_nC_loss: 0.0267 - val_num_acc: 0.9748 - val_dig1_acc: 0.8830 - val_dig2_acc: 0.7968 - val_dig3_acc: 0.8984 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00044: loss improved from 1.38437 to 1.36728, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 45/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.3417 - num_loss: 0.0694 - dig1_loss: 0.3648 - dig2_loss: 0.5590 - dig3_loss: 0.2846 - dig4_loss: 0.0469 - nC_loss: 0.0170 - num_acc: 0.9795 - dig1_acc: 0.8805 - dig2_acc: 0.7933 - dig3_acc: 0.9002 - dig4_acc: 0.9859 - nC_acc: 0.9946 - val_loss: 1.3771 - val_num_loss: 0.0920 - val_dig1_loss: 0.3526 - val_dig2_loss: 0.5568 - val_dig3_loss: 0.3021 - val_dig4_loss: 0.0454 - val_nC_loss: 0.0282 - val_num_acc: 0.9735 - val_dig1_acc: 0.8881 - val_dig2_acc: 0.7986 - val_dig3_acc: 0.8999 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9910\n",
      "\n",
      "Epoch 00045: loss improved from 1.36728 to 1.34172, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 46/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.3300 - num_loss: 0.0717 - dig1_loss: 0.3603 - dig2_loss: 0.5478 - dig3_loss: 0.2843 - dig4_loss: 0.0474 - nC_loss: 0.0186 - num_acc: 0.9786 - dig1_acc: 0.8822 - dig2_acc: 0.7975 - dig3_acc: 0.9008 - dig4_acc: 0.9859 - nC_acc: 0.9943 - val_loss: 1.3562 - val_num_loss: 0.0801 - val_dig1_loss: 0.3584 - val_dig2_loss: 0.5538 - val_dig3_loss: 0.2939 - val_dig4_loss: 0.0445 - val_nC_loss: 0.0256 - val_num_acc: 0.9770 - val_dig1_acc: 0.8899 - val_dig2_acc: 0.8021 - val_dig3_acc: 0.8990 - val_dig4_acc: 0.9861 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00046: loss improved from 1.34172 to 1.33004, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 47/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.3126 - num_loss: 0.0694 - dig1_loss: 0.3558 - dig2_loss: 0.5411 - dig3_loss: 0.2817 - dig4_loss: 0.0471 - nC_loss: 0.0174 - num_acc: 0.9793 - dig1_acc: 0.8838 - dig2_acc: 0.7990 - dig3_acc: 0.9013 - dig4_acc: 0.9859 - nC_acc: 0.9945 - val_loss: 1.3353 - val_num_loss: 0.0839 - val_dig1_loss: 0.3340 - val_dig2_loss: 0.5531 - val_dig3_loss: 0.2937 - val_dig4_loss: 0.0450 - val_nC_loss: 0.0257 - val_num_acc: 0.9757 - val_dig1_acc: 0.8957 - val_dig2_acc: 0.7941 - val_dig3_acc: 0.9013 - val_dig4_acc: 0.9863 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00047: loss improved from 1.33004 to 1.31260, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 48/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2875 - num_loss: 0.0665 - dig1_loss: 0.3447 - dig2_loss: 0.5336 - dig3_loss: 0.2798 - dig4_loss: 0.0468 - nC_loss: 0.0162 - num_acc: 0.9802 - dig1_acc: 0.8871 - dig2_acc: 0.8031 - dig3_acc: 0.9016 - dig4_acc: 0.9858 - nC_acc: 0.9953 - val_loss: 1.3134 - val_num_loss: 0.0799 - val_dig1_loss: 0.3406 - val_dig2_loss: 0.5324 - val_dig3_loss: 0.2910 - val_dig4_loss: 0.0451 - val_nC_loss: 0.0244 - val_num_acc: 0.9762 - val_dig1_acc: 0.8940 - val_dig2_acc: 0.8074 - val_dig3_acc: 0.9011 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00048: loss improved from 1.31260 to 1.28753, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 49/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2677 - num_loss: 0.0661 - dig1_loss: 0.3365 - dig2_loss: 0.5242 - dig3_loss: 0.2784 - dig4_loss: 0.0463 - nC_loss: 0.0162 - num_acc: 0.9802 - dig1_acc: 0.8894 - dig2_acc: 0.8062 - dig3_acc: 0.9017 - dig4_acc: 0.9857 - nC_acc: 0.9950 - val_loss: 1.2991 - val_num_loss: 0.0820 - val_dig1_loss: 0.3322 - val_dig2_loss: 0.5243 - val_dig3_loss: 0.2891 - val_dig4_loss: 0.0451 - val_nC_loss: 0.0264 - val_num_acc: 0.9758 - val_dig1_acc: 0.8961 - val_dig2_acc: 0.8081 - val_dig3_acc: 0.9017 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00049: loss improved from 1.28753 to 1.26771, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 50/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2530 - num_loss: 0.0651 - dig1_loss: 0.3322 - dig2_loss: 0.5184 - dig3_loss: 0.2744 - dig4_loss: 0.0464 - nC_loss: 0.0164 - num_acc: 0.9807 - dig1_acc: 0.8909 - dig2_acc: 0.8071 - dig3_acc: 0.9033 - dig4_acc: 0.9858 - nC_acc: 0.9950 - val_loss: 1.2986 - val_num_loss: 0.0873 - val_dig1_loss: 0.3289 - val_dig2_loss: 0.5203 - val_dig3_loss: 0.2888 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0281 - val_num_acc: 0.9737 - val_dig1_acc: 0.8977 - val_dig2_acc: 0.8134 - val_dig3_acc: 0.9011 - val_dig4_acc: 0.9857 - val_nC_acc: 0.9910\n",
      "\n",
      "Epoch 00050: loss improved from 1.26771 to 1.25295, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 51/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2380 - num_loss: 0.0650 - dig1_loss: 0.3249 - dig2_loss: 0.5126 - dig3_loss: 0.2734 - dig4_loss: 0.0464 - nC_loss: 0.0157 - num_acc: 0.9805 - dig1_acc: 0.8944 - dig2_acc: 0.8096 - dig3_acc: 0.9039 - dig4_acc: 0.9857 - nC_acc: 0.9951 - val_loss: 1.2750 - val_num_loss: 0.0795 - val_dig1_loss: 0.3246 - val_dig2_loss: 0.5153 - val_dig3_loss: 0.2853 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0253 - val_num_acc: 0.9765 - val_dig1_acc: 0.8967 - val_dig2_acc: 0.8126 - val_dig3_acc: 0.9019 - val_dig4_acc: 0.9858 - val_nC_acc: 0.9920\n",
      "\n",
      "Epoch 00051: loss improved from 1.25295 to 1.23800, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 52/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2228 - num_loss: 0.0647 - dig1_loss: 0.3198 - dig2_loss: 0.5065 - dig3_loss: 0.2702 - dig4_loss: 0.0460 - nC_loss: 0.0156 - num_acc: 0.9810 - dig1_acc: 0.8959 - dig2_acc: 0.8118 - dig3_acc: 0.9054 - dig4_acc: 0.9859 - nC_acc: 0.9951 - val_loss: 1.2701 - val_num_loss: 0.0827 - val_dig1_loss: 0.3188 - val_dig2_loss: 0.5154 - val_dig3_loss: 0.2799 - val_dig4_loss: 0.0457 - val_nC_loss: 0.0276 - val_num_acc: 0.9763 - val_dig1_acc: 0.8978 - val_dig2_acc: 0.8142 - val_dig3_acc: 0.9032 - val_dig4_acc: 0.9857 - val_nC_acc: 0.9920\n",
      "\n",
      "Epoch 00052: loss improved from 1.23800 to 1.22277, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 53/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.2085 - num_loss: 0.0637 - dig1_loss: 0.3152 - dig2_loss: 0.5017 - dig3_loss: 0.2658 - dig4_loss: 0.0465 - nC_loss: 0.0155 - num_acc: 0.9812 - dig1_acc: 0.8981 - dig2_acc: 0.8133 - dig3_acc: 0.9058 - dig4_acc: 0.9857 - nC_acc: 0.9950 - val_loss: 1.2404 - val_num_loss: 0.0793 - val_dig1_loss: 0.3094 - val_dig2_loss: 0.5052 - val_dig3_loss: 0.2761 - val_dig4_loss: 0.0453 - val_nC_loss: 0.0252 - val_num_acc: 0.9777 - val_dig1_acc: 0.9036 - val_dig2_acc: 0.8195 - val_dig3_acc: 0.9049 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9927\n",
      "\n",
      "Epoch 00053: loss improved from 1.22277 to 1.20851, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 54/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.1958 - num_loss: 0.0642 - dig1_loss: 0.3117 - dig2_loss: 0.4948 - dig3_loss: 0.2629 - dig4_loss: 0.0464 - nC_loss: 0.0158 - num_acc: 0.9809 - dig1_acc: 0.8987 - dig2_acc: 0.8163 - dig3_acc: 0.9068 - dig4_acc: 0.9858 - nC_acc: 0.9950 - val_loss: 1.2408 - val_num_loss: 0.0817 - val_dig1_loss: 0.3044 - val_dig2_loss: 0.5085 - val_dig3_loss: 0.2732 - val_dig4_loss: 0.0457 - val_nC_loss: 0.0273 - val_num_acc: 0.9759 - val_dig1_acc: 0.9055 - val_dig2_acc: 0.8167 - val_dig3_acc: 0.9063 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9917\n",
      "\n",
      "Epoch 00054: loss improved from 1.20851 to 1.19582, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 55/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.1742 - num_loss: 0.0616 - dig1_loss: 0.3023 - dig2_loss: 0.4897 - dig3_loss: 0.2602 - dig4_loss: 0.0458 - nC_loss: 0.0146 - num_acc: 0.9820 - dig1_acc: 0.9021 - dig2_acc: 0.8190 - dig3_acc: 0.9075 - dig4_acc: 0.9856 - nC_acc: 0.9955 - val_loss: 1.2589 - val_num_loss: 0.0983 - val_dig1_loss: 0.3055 - val_dig2_loss: 0.4957 - val_dig3_loss: 0.2877 - val_dig4_loss: 0.0456 - val_nC_loss: 0.0260 - val_num_acc: 0.9731 - val_dig1_acc: 0.9049 - val_dig2_acc: 0.8277 - val_dig3_acc: 0.9052 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9927\n",
      "\n",
      "Epoch 00055: loss improved from 1.19582 to 1.17420, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.1206 - num_loss: 0.0576 - dig1_loss: 0.2825 - dig2_loss: 0.4657 - dig3_loss: 0.2557 - dig4_loss: 0.0449 - nC_loss: 0.0141 - num_acc: 0.9828 - dig1_acc: 0.9093 - dig2_acc: 0.8289 - dig3_acc: 0.9091 - dig4_acc: 0.9857 - nC_acc: 0.9957 - val_loss: 1.2025 - val_num_loss: 0.0857 - val_dig1_loss: 0.2920 - val_dig2_loss: 0.4794 - val_dig3_loss: 0.2738 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0267 - val_num_acc: 0.9764 - val_dig1_acc: 0.9105 - val_dig2_acc: 0.8325 - val_dig3_acc: 0.9065 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00056: loss improved from 1.17420 to 1.12055, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 57/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.1123 - num_loss: 0.0564 - dig1_loss: 0.2803 - dig2_loss: 0.4634 - dig3_loss: 0.2540 - dig4_loss: 0.0447 - nC_loss: 0.0136 - num_acc: 0.9839 - dig1_acc: 0.9107 - dig2_acc: 0.8299 - dig3_acc: 0.9099 - dig4_acc: 0.9858 - nC_acc: 0.9960 - val_loss: 1.1951 - val_num_loss: 0.0854 - val_dig1_loss: 0.2894 - val_dig2_loss: 0.4767 - val_dig3_loss: 0.2723 - val_dig4_loss: 0.0450 - val_nC_loss: 0.0264 - val_num_acc: 0.9760 - val_dig1_acc: 0.9117 - val_dig2_acc: 0.8343 - val_dig3_acc: 0.9075 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9924\n",
      "\n",
      "Epoch 00057: loss improved from 1.12055 to 1.11230, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 58/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.1110 - num_loss: 0.0563 - dig1_loss: 0.2784 - dig2_loss: 0.4637 - dig3_loss: 0.2544 - dig4_loss: 0.0449 - nC_loss: 0.0132 - num_acc: 0.9832 - dig1_acc: 0.9107 - dig2_acc: 0.8312 - dig3_acc: 0.9094 - dig4_acc: 0.9859 - nC_acc: 0.9958 - val_loss: 1.1930 - val_num_loss: 0.0850 - val_dig1_loss: 0.2898 - val_dig2_loss: 0.4755 - val_dig3_loss: 0.2711 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0263 - val_num_acc: 0.9764 - val_dig1_acc: 0.9102 - val_dig2_acc: 0.8329 - val_dig3_acc: 0.9067 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00058: loss improved from 1.11230 to 1.11101, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 59/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.1017 - num_loss: 0.0549 - dig1_loss: 0.2759 - dig2_loss: 0.4612 - dig3_loss: 0.2524 - dig4_loss: 0.0445 - nC_loss: 0.0128 - num_acc: 0.9840 - dig1_acc: 0.9114 - dig2_acc: 0.8306 - dig3_acc: 0.9101 - dig4_acc: 0.9859 - nC_acc: 0.9961 - val_loss: 1.1945 - val_num_loss: 0.0851 - val_dig1_loss: 0.2906 - val_dig2_loss: 0.4762 - val_dig3_loss: 0.2712 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0264 - val_num_acc: 0.9765 - val_dig1_acc: 0.9115 - val_dig2_acc: 0.8333 - val_dig3_acc: 0.9070 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9924\n",
      "\n",
      "Epoch 00059: loss improved from 1.11101 to 1.10173, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 60/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0989 - num_loss: 0.0547 - dig1_loss: 0.2764 - dig2_loss: 0.4588 - dig3_loss: 0.2518 - dig4_loss: 0.0448 - nC_loss: 0.0124 - num_acc: 0.9839 - dig1_acc: 0.9103 - dig2_acc: 0.8331 - dig3_acc: 0.9100 - dig4_acc: 0.9860 - nC_acc: 0.9960 - val_loss: 1.1904 - val_num_loss: 0.0857 - val_dig1_loss: 0.2881 - val_dig2_loss: 0.4734 - val_dig3_loss: 0.2716 - val_dig4_loss: 0.0450 - val_nC_loss: 0.0267 - val_num_acc: 0.9760 - val_dig1_acc: 0.9123 - val_dig2_acc: 0.8337 - val_dig3_acc: 0.9069 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00060: loss improved from 1.10173 to 1.09893, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 61/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0934 - num_loss: 0.0542 - dig1_loss: 0.2764 - dig2_loss: 0.4557 - dig3_loss: 0.2500 - dig4_loss: 0.0446 - nC_loss: 0.0125 - num_acc: 0.9845 - dig1_acc: 0.9112 - dig2_acc: 0.8341 - dig3_acc: 0.9106 - dig4_acc: 0.9858 - nC_acc: 0.9964 - val_loss: 1.1986 - val_num_loss: 0.0880 - val_dig1_loss: 0.2897 - val_dig2_loss: 0.4765 - val_dig3_loss: 0.2717 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0276 - val_num_acc: 0.9750 - val_dig1_acc: 0.9113 - val_dig2_acc: 0.8306 - val_dig3_acc: 0.9069 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9918\n",
      "\n",
      "Epoch 00061: loss improved from 1.09893 to 1.09345, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 62/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0974 - num_loss: 0.0571 - dig1_loss: 0.2744 - dig2_loss: 0.4556 - dig3_loss: 0.2523 - dig4_loss: 0.0453 - nC_loss: 0.0128 - num_acc: 0.9831 - dig1_acc: 0.9113 - dig2_acc: 0.8330 - dig3_acc: 0.9104 - dig4_acc: 0.9859 - nC_acc: 0.9959 - val_loss: 1.1835 - val_num_loss: 0.0844 - val_dig1_loss: 0.2861 - val_dig2_loss: 0.4716 - val_dig3_loss: 0.2699 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0262 - val_num_acc: 0.9765 - val_dig1_acc: 0.9134 - val_dig2_acc: 0.8353 - val_dig3_acc: 0.9073 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9924\n",
      "\n",
      "Epoch 00062: loss did not improve from 1.09345\n",
      "Epoch 63/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0908 - num_loss: 0.0540 - dig1_loss: 0.2738 - dig2_loss: 0.4552 - dig3_loss: 0.2507 - dig4_loss: 0.0445 - nC_loss: 0.0126 - num_acc: 0.9840 - dig1_acc: 0.9117 - dig2_acc: 0.8326 - dig3_acc: 0.9104 - dig4_acc: 0.9861 - nC_acc: 0.9960 - val_loss: 1.1917 - val_num_loss: 0.0866 - val_dig1_loss: 0.2870 - val_dig2_loss: 0.4752 - val_dig3_loss: 0.2716 - val_dig4_loss: 0.0450 - val_nC_loss: 0.0262 - val_num_acc: 0.9759 - val_dig1_acc: 0.9124 - val_dig2_acc: 0.8343 - val_dig3_acc: 0.9072 - val_dig4_acc: 0.9861 - val_nC_acc: 0.9926\n",
      "\n",
      "Epoch 00063: loss improved from 1.09345 to 1.09078, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 64/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0870 - num_loss: 0.0550 - dig1_loss: 0.2725 - dig2_loss: 0.4512 - dig3_loss: 0.2510 - dig4_loss: 0.0447 - nC_loss: 0.0127 - num_acc: 0.9840 - dig1_acc: 0.9126 - dig2_acc: 0.8352 - dig3_acc: 0.9104 - dig4_acc: 0.9860 - nC_acc: 0.9959 - val_loss: 1.1794 - val_num_loss: 0.0841 - val_dig1_loss: 0.2871 - val_dig2_loss: 0.4685 - val_dig3_loss: 0.2676 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0273 - val_num_acc: 0.9764 - val_dig1_acc: 0.9121 - val_dig2_acc: 0.8359 - val_dig3_acc: 0.9074 - val_dig4_acc: 0.9856 - val_nC_acc: 0.9919\n",
      "\n",
      "Epoch 00064: loss improved from 1.09078 to 1.08704, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 65/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0866 - num_loss: 0.0542 - dig1_loss: 0.2720 - dig2_loss: 0.4536 - dig3_loss: 0.2503 - dig4_loss: 0.0444 - nC_loss: 0.0122 - num_acc: 0.9841 - dig1_acc: 0.9121 - dig2_acc: 0.8345 - dig3_acc: 0.9104 - dig4_acc: 0.9859 - nC_acc: 0.9964 - val_loss: 1.1861 - val_num_loss: 0.0863 - val_dig1_loss: 0.2870 - val_dig2_loss: 0.4705 - val_dig3_loss: 0.2696 - val_dig4_loss: 0.0453 - val_nC_loss: 0.0274 - val_num_acc: 0.9759 - val_dig1_acc: 0.9128 - val_dig2_acc: 0.8360 - val_dig3_acc: 0.9078 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00065: loss improved from 1.08704 to 1.08660, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 66/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.0789 - num_loss: 0.0546 - dig1_loss: 0.2685 - dig2_loss: 0.4486 - dig3_loss: 0.2500 - dig4_loss: 0.0447 - nC_loss: 0.0126 - num_acc: 0.9836 - dig1_acc: 0.9138 - dig2_acc: 0.8353 - dig3_acc: 0.9102 - dig4_acc: 0.9858 - nC_acc: 0.9959 - val_loss: 1.1793 - val_num_loss: 0.0847 - val_dig1_loss: 0.2849 - val_dig2_loss: 0.4685 - val_dig3_loss: 0.2693 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0270 - val_num_acc: 0.9762 - val_dig1_acc: 0.9131 - val_dig2_acc: 0.8361 - val_dig3_acc: 0.9077 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00066: loss improved from 1.08660 to 1.07894, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 67/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.0826 - num_loss: 0.0546 - dig1_loss: 0.2715 - dig2_loss: 0.4495 - dig3_loss: 0.2497 - dig4_loss: 0.0444 - nC_loss: 0.0129 - num_acc: 0.9843 - dig1_acc: 0.9113 - dig2_acc: 0.8367 - dig3_acc: 0.9111 - dig4_acc: 0.9860 - nC_acc: 0.9961 - val_loss: 1.1785 - val_num_loss: 0.0842 - val_dig1_loss: 0.2856 - val_dig2_loss: 0.4693 - val_dig3_loss: 0.2676 - val_dig4_loss: 0.0451 - val_nC_loss: 0.0267 - val_num_acc: 0.9763 - val_dig1_acc: 0.9134 - val_dig2_acc: 0.8366 - val_dig3_acc: 0.9072 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.07894\n",
      "Epoch 68/75\n",
      "69076/69076 [==============================] - 97s 1ms/step - loss: 1.0826 - num_loss: 0.0542 - dig1_loss: 0.2715 - dig2_loss: 0.4495 - dig3_loss: 0.2500 - dig4_loss: 0.0448 - nC_loss: 0.0126 - num_acc: 0.9841 - dig1_acc: 0.9126 - dig2_acc: 0.8356 - dig3_acc: 0.9109 - dig4_acc: 0.9859 - nC_acc: 0.9960 - val_loss: 1.1779 - val_num_loss: 0.0856 - val_dig1_loss: 0.2847 - val_dig2_loss: 0.4668 - val_dig3_loss: 0.2697 - val_dig4_loss: 0.0448 - val_nC_loss: 0.0263 - val_num_acc: 0.9756 - val_dig1_acc: 0.9135 - val_dig2_acc: 0.8376 - val_dig3_acc: 0.9079 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9924\n",
      "\n",
      "Epoch 00068: loss did not improve from 1.07894\n",
      "Epoch 69/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0788 - num_loss: 0.0553 - dig1_loss: 0.2686 - dig2_loss: 0.4492 - dig3_loss: 0.2488 - dig4_loss: 0.0441 - nC_loss: 0.0129 - num_acc: 0.9837 - dig1_acc: 0.9143 - dig2_acc: 0.8352 - dig3_acc: 0.9114 - dig4_acc: 0.9860 - nC_acc: 0.9961 - val_loss: 1.1770 - val_num_loss: 0.0854 - val_dig1_loss: 0.2842 - val_dig2_loss: 0.4670 - val_dig3_loss: 0.2685 - val_dig4_loss: 0.0448 - val_nC_loss: 0.0270 - val_num_acc: 0.9762 - val_dig1_acc: 0.9136 - val_dig2_acc: 0.8369 - val_dig3_acc: 0.9081 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00069: loss improved from 1.07894 to 1.07878, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 70/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0802 - num_loss: 0.0547 - dig1_loss: 0.2690 - dig2_loss: 0.4489 - dig3_loss: 0.2500 - dig4_loss: 0.0451 - nC_loss: 0.0125 - num_acc: 0.9837 - dig1_acc: 0.9134 - dig2_acc: 0.8371 - dig3_acc: 0.9107 - dig4_acc: 0.9859 - nC_acc: 0.9962 - val_loss: 1.1668 - val_num_loss: 0.0833 - val_dig1_loss: 0.2832 - val_dig2_loss: 0.4621 - val_dig3_loss: 0.2667 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0266 - val_num_acc: 0.9765 - val_dig1_acc: 0.9140 - val_dig2_acc: 0.8388 - val_dig3_acc: 0.9078 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00070: loss did not improve from 1.07878\n",
      "Epoch 71/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0728 - num_loss: 0.0541 - dig1_loss: 0.2680 - dig2_loss: 0.4456 - dig3_loss: 0.2485 - dig4_loss: 0.0442 - nC_loss: 0.0124 - num_acc: 0.9838 - dig1_acc: 0.9138 - dig2_acc: 0.8374 - dig3_acc: 0.9111 - dig4_acc: 0.9860 - nC_acc: 0.9963 - val_loss: 1.1745 - val_num_loss: 0.0859 - val_dig1_loss: 0.2852 - val_dig2_loss: 0.4628 - val_dig3_loss: 0.2680 - val_dig4_loss: 0.0449 - val_nC_loss: 0.0279 - val_num_acc: 0.9757 - val_dig1_acc: 0.9136 - val_dig2_acc: 0.8395 - val_dig3_acc: 0.9080 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9919\n",
      "\n",
      "Epoch 00071: loss improved from 1.07878 to 1.07284, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 72/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0708 - num_loss: 0.0539 - dig1_loss: 0.2657 - dig2_loss: 0.4460 - dig3_loss: 0.2485 - dig4_loss: 0.0447 - nC_loss: 0.0121 - num_acc: 0.9839 - dig1_acc: 0.9150 - dig2_acc: 0.8384 - dig3_acc: 0.9113 - dig4_acc: 0.9860 - nC_acc: 0.9963 - val_loss: 1.1781 - val_num_loss: 0.0868 - val_dig1_loss: 0.2854 - val_dig2_loss: 0.4650 - val_dig3_loss: 0.2689 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0268 - val_num_acc: 0.9758 - val_dig1_acc: 0.9135 - val_dig2_acc: 0.8398 - val_dig3_acc: 0.9090 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00072: loss improved from 1.07284 to 1.07082, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 73/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0656 - num_loss: 0.0532 - dig1_loss: 0.2651 - dig2_loss: 0.4439 - dig3_loss: 0.2470 - dig4_loss: 0.0447 - nC_loss: 0.0117 - num_acc: 0.9845 - dig1_acc: 0.9145 - dig2_acc: 0.8379 - dig3_acc: 0.9116 - dig4_acc: 0.9860 - nC_acc: 0.9965 - val_loss: 1.1717 - val_num_loss: 0.0857 - val_dig1_loss: 0.2835 - val_dig2_loss: 0.4625 - val_dig3_loss: 0.2681 - val_dig4_loss: 0.0450 - val_nC_loss: 0.0268 - val_num_acc: 0.9754 - val_dig1_acc: 0.9128 - val_dig2_acc: 0.8402 - val_dig3_acc: 0.9086 - val_dig4_acc: 0.9859 - val_nC_acc: 0.9922\n",
      "\n",
      "Epoch 00073: loss improved from 1.07082 to 1.06555, saving model to saved_models/designedBGRClassifier.hdf5\n",
      "Epoch 74/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0657 - num_loss: 0.0540 - dig1_loss: 0.2655 - dig2_loss: 0.4413 - dig3_loss: 0.2481 - dig4_loss: 0.0443 - nC_loss: 0.0125 - num_acc: 0.9843 - dig1_acc: 0.9158 - dig2_acc: 0.8383 - dig3_acc: 0.9112 - dig4_acc: 0.9861 - nC_acc: 0.9960 - val_loss: 1.1687 - val_num_loss: 0.0850 - val_dig1_loss: 0.2825 - val_dig2_loss: 0.4616 - val_dig3_loss: 0.2677 - val_dig4_loss: 0.0447 - val_nC_loss: 0.0272 - val_num_acc: 0.9765 - val_dig1_acc: 0.9146 - val_dig2_acc: 0.8395 - val_dig3_acc: 0.9078 - val_dig4_acc: 0.9860 - val_nC_acc: 0.9926\n",
      "\n",
      "Epoch 00074: loss did not improve from 1.06555\n",
      "Epoch 75/75\n",
      "69076/69076 [==============================] - 96s 1ms/step - loss: 1.0613 - num_loss: 0.0521 - dig1_loss: 0.2649 - dig2_loss: 0.4407 - dig3_loss: 0.2481 - dig4_loss: 0.0441 - nC_loss: 0.0114 - num_acc: 0.9844 - dig1_acc: 0.9149 - dig2_acc: 0.8394 - dig3_acc: 0.9112 - dig4_acc: 0.9859 - nC_acc: 0.9965 - val_loss: 1.1679 - val_num_loss: 0.0858 - val_dig1_loss: 0.2824 - val_dig2_loss: 0.4598 - val_dig3_loss: 0.2676 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0271 - val_num_acc: 0.9762 - val_dig1_acc: 0.9149 - val_dig2_acc: 0.8407 - val_dig3_acc: 0.9087 - val_dig4_acc: 0.9862 - val_nC_acc: 0.9925\n",
      "\n",
      "Epoch 00075: loss improved from 1.06555 to 1.06132, saving model to saved_models/designedBGRClassifier.hdf5\n"
     ]
    }
   ],
   "source": [
    "designHist = svhnModel.fit(x = X_train,\n",
    "                          y = y_train,\n",
    "                          batch_size = batch_size,\n",
    "                          epochs = epochs,\n",
    "                          verbose=1,\n",
    "                          shuffle = True,\n",
    "                          validation_data = (X_val, y_val),\n",
    "                          callbacks= callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train loss: 0.9507963826754848\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Train accuracy: [98.74486073310557, 92.90057328160287, 85.60136661068968, 91.34576408593433, 98.60009265157218, 99.77560947362325]\n",
      "Train sequence accuracy: 80.0958364699751\n",
      "Validation loss: 1.1678723588553928\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Validation accuracy: [97.62001273959117, 91.48763680583704, 84.06972030806648, 90.8738201401355, 98.61601714054086, 99.24720597602641]\n",
      "Validation sequence accuracy: 78.06474028606173\n",
      "Test loss: 2.521751479790146\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Test accuracy: [95.73702739935712, 76.44267564671668, 61.24292055717129, 87.32588397367212, 99.12750650543394, 99.24996173274147]\n",
      "Test sequence accuracy: 47.09168835144651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [98.74486073310557,\n",
       "  92.90057328160287,\n",
       "  85.60136661068968,\n",
       "  91.34576408593433,\n",
       "  98.60009265157218,\n",
       "  99.77560947362325],\n",
       " 'test_acc': [95.73702739935712,\n",
       "  76.44267564671668,\n",
       "  61.24292055717129,\n",
       "  87.32588397367212,\n",
       "  99.12750650543394,\n",
       "  99.24996173274147],\n",
       " 'val_acc': [97.62001273959117,\n",
       "  91.48763680583704,\n",
       "  84.06972030806648,\n",
       "  90.8738201401355,\n",
       "  98.61601714054086,\n",
       "  99.24720597602641],\n",
       " 'train_seq_acc': 80.0958364699751,\n",
       " 'test_seq_acc': 47.09168835144651,\n",
       " 'val_seq_acc': 78.06474028606173,\n",
       " 'train_score': [0.9507963826754848,\n",
       "  0.04283636021068769,\n",
       "  0.2223040749370617,\n",
       "  0.3976787031656828,\n",
       "  0.2371753952157807,\n",
       "  0.04253297603639911,\n",
       "  0.0082688738790532,\n",
       "  0.9874486073310557,\n",
       "  0.9290057328160287,\n",
       "  0.8560136661068968,\n",
       "  0.9134576408593433,\n",
       "  0.9860009265157218,\n",
       "  0.9977560947362325],\n",
       " 'test_score': [2.521751479790146,\n",
       "  0.16193167699625513,\n",
       "  0.7790317756146508,\n",
       "  1.1408709731781517,\n",
       "  0.37813642449060003,\n",
       "  0.03367830629113174,\n",
       "  0.028102322761237586,\n",
       "  0.9573702739935711,\n",
       "  0.7644267564489194,\n",
       "  0.6124292055717129,\n",
       "  0.8732588397367212,\n",
       "  0.9912750650360923,\n",
       "  0.9924996173274147],\n",
       " 'val_score': [1.1678723588553928,\n",
       "  0.08580589498241639,\n",
       "  0.2824130888314921,\n",
       "  0.45981065515182645,\n",
       "  0.26755778571755456,\n",
       "  0.04522464729333314,\n",
       "  0.027060286776742354,\n",
       "  0.9762001274028148,\n",
       "  0.9148763680652736,\n",
       "  0.8406972031048255,\n",
       "  0.9087382014151612,\n",
       "  0.9861601714054086,\n",
       "  0.9924720597602641]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.model_evaluation_utils import evaluate_model_performance\n",
    "modName = 'designed_model'\n",
    "evaluate_model_performance(fitted_model=designHist, \n",
    "                           model_name = modName,\n",
    "                           data=data,\n",
    "                           model=svhnModel\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
