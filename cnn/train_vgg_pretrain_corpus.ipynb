{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        img2 = img\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get three channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.preprocess_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n"
     ]
    }
   ],
   "source": [
    "shape = (64, 64)\n",
    "channel = 3\n",
    "data = generate_data_set_for_training(shape, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try pretrianed Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "import keras.utils as ku\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vgg16_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n",
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# from scratch\n",
    "run_pretrained_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chanel 3\n",
      "row 64\n",
      "col 64\n"
     ]
    }
   ],
   "source": [
    "_, row, col, channel = X_train.shape\n",
    "print('chanel', channel)\n",
    "print('row', row)\n",
    "print('col', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "digLen = 5\n",
    "numDigits = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "preTrainModel = VGG16(include_top = False, weights = 'imagenet')\n",
    "preTrainModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptInput = keras.Input(shape = (row,col,channel), name  = 'inputVGGPreTrain')\n",
    "pt_vgg16 = preTrainModel(ptInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mout = Flatten(name = 'flatten')(pt_vgg16)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_4096')(Mout)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_512')(Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numd_SM = Dense(digLen,    activation='softmax',name = 'num')(Mout)\n",
    "dig1_SM = Dense(numDigits, activation='softmax',name = 'dig1')(Mout)\n",
    "dig2_SM = Dense(numDigits, activation='softmax',name = 'dig2')(Mout)\n",
    "dig3_SM = Dense(numDigits, activation='softmax',name = 'dig3')(Mout)\n",
    "dig4_SM = Dense(numDigits, activation='softmax',name = 'dig4')(Mout)\n",
    "numB_SM = Dense(2, activation='softmax',name = 'nC')(Mout)\n",
    "out = [numd_SM, dig1_SM ,dig2_SM, dig3_SM, dig4_SM,numB_SM] #numd_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    lr = 0.001\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999\n",
    "    epsilon = None\n",
    "    decay = 0.0\n",
    "    amsgrad = True\n",
    "    # defind optimizer\n",
    "\n",
    "\n",
    "\n",
    "    optim = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay, amsgrad=amsgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputVGGPreTrain (InputLayer)   (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   multiple             14714688    inputVGGPreTrain[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC1_4096 (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FC1_512 (Dense)                 (None, 1024)         1049600     FC1_4096[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "num (Dense)                     (None, 5)            5125        FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig1 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig2 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig3 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig4 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "nC (Dense)                      (None, 2)            2050        FC1_512[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,914,739\n",
      "Trainable params: 17,914,739\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggPreTrain = keras.Model(inputs = ptInput, outputs = out)\n",
    "\n",
    "vggPreTrain.compile(loss = 'sparse_categorical_crossentropy', #ceLoss ,\n",
    "                    optimizer= optim,\n",
    "                    metrics=  ['accuracy']) #[])\n",
    "vggPreTrain.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = []\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='saved_models/VGGPreTrained_classifier_corrected.hdf5',\n",
    "                                               monitor='loss',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
    "                                              factor = 0.1,\n",
    "                                              verbose = 1,\n",
    "                                              patience= 4,\n",
    "                                              cooldown= 1,\n",
    "                                              min_lr = 0.0001)\n",
    "es = keras.callbacks.EarlyStopping(monitor= 'loss',\n",
    "                                   min_delta=0.000001,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   mode='auto')\n",
    "callback.append(es)\n",
    "callback.append(checkpointer)\n",
    "callback.append(reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 2.3541 - num_loss: 0.2782 - dig1_loss: 0.7762 - dig2_loss: 0.8120 - dig3_loss: 0.3901 - dig4_loss: 0.0851 - nC_loss: 0.0125 - num_acc: 0.8871 - dig1_acc: 0.7272 - dig2_acc: 0.7126 - dig3_acc: 0.8973 - dig4_acc: 0.9849 - nC_acc: 0.9968 - val_loss: 2.1584 - val_num_loss: 0.2337 - val_dig1_loss: 0.6788 - val_dig2_loss: 0.8026 - val_dig3_loss: 0.3728 - val_dig4_loss: 0.0702 - val_nC_loss: 3.9290e-04 - val_num_acc: 0.9056 - val_dig1_acc: 0.7723 - val_dig2_acc: 0.7128 - val_dig3_acc: 0.8953 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.35407, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 2/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 2.1642 - num_loss: 0.2668 - dig1_loss: 0.6669 - dig2_loss: 0.7713 - dig3_loss: 0.3691 - dig4_loss: 0.0824 - nC_loss: 0.0076 - num_acc: 0.8998 - dig1_acc: 0.7687 - dig2_acc: 0.7323 - dig3_acc: 0.8975 - dig4_acc: 0.9857 - nC_acc: 0.9993 - val_loss: 1.7477 - val_num_loss: 0.1531 - val_dig1_loss: 0.5623 - val_dig2_loss: 0.6469 - val_dig3_loss: 0.3168 - val_dig4_loss: 0.0685 - val_nC_loss: 4.8656e-05 - val_num_acc: 0.9416 - val_dig1_acc: 0.8069 - val_dig2_acc: 0.7634 - val_dig3_acc: 0.8972 - val_dig4_acc: 0.9865 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00002: loss improved from 2.35407 to 2.16416, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 3/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 1.4056 - num_loss: 0.1168 - dig1_loss: 0.4322 - dig2_loss: 0.5240 - dig3_loss: 0.2703 - dig4_loss: 0.0622 - nC_loss: 1.0377e-04 - num_acc: 0.9588 - dig1_acc: 0.8525 - dig2_acc: 0.8133 - dig3_acc: 0.9101 - dig4_acc: 0.9855 - nC_acc: 1.0000 - val_loss: 1.0722 - val_num_loss: 0.0781 - val_dig1_loss: 0.3203 - val_dig2_loss: 0.3957 - val_dig3_loss: 0.2321 - val_dig4_loss: 0.0461 - val_nC_loss: 6.2389e-05 - val_num_acc: 0.9727 - val_dig1_acc: 0.8925 - val_dig2_acc: 0.8619 - val_dig3_acc: 0.9179 - val_dig4_acc: 0.9864 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00003: loss improved from 2.16416 to 1.40556, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 4/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 1.6239 - num_loss: 0.2054 - dig1_loss: 0.4892 - dig2_loss: 0.5560 - dig3_loss: 0.3015 - dig4_loss: 0.0659 - nC_loss: 0.0060 - num_acc: 0.9192 - dig1_acc: 0.8331 - dig2_acc: 0.8109 - dig3_acc: 0.9162 - dig4_acc: 0.9858 - nC_acc: 0.9994 - val_loss: 2.3693 - val_num_loss: 0.2926 - val_dig1_loss: 0.7372 - val_dig2_loss: 0.8114 - val_dig3_loss: 0.4382 - val_dig4_loss: 0.0888 - val_nC_loss: 0.0011 - val_num_acc: 0.8732 - val_dig1_acc: 0.7456 - val_dig2_acc: 0.7116 - val_dig3_acc: 0.8814 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00004: loss did not improve from 1.40556\n",
      "Epoch 5/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 1.7576 - num_loss: 0.2014 - dig1_loss: 0.5265 - dig2_loss: 0.6266 - dig3_loss: 0.3279 - dig4_loss: 0.0741 - nC_loss: 0.0012 - num_acc: 0.9210 - dig1_acc: 0.8218 - dig2_acc: 0.7808 - dig3_acc: 0.9031 - dig4_acc: 0.9858 - nC_acc: 0.9998 - val_loss: 1.4062 - val_num_loss: 0.1512 - val_dig1_loss: 0.3847 - val_dig2_loss: 0.5342 - val_dig3_loss: 0.2760 - val_dig4_loss: 0.0596 - val_nC_loss: 4.7535e-04 - val_num_acc: 0.9416 - val_dig1_acc: 0.8681 - val_dig2_acc: 0.8151 - val_dig3_acc: 0.9109 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00005: loss did not improve from 1.40556\n",
      "Epoch 6/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 1.0236 - num_loss: 0.0999 - dig1_loss: 0.2822 - dig2_loss: 0.3629 - dig3_loss: 0.2217 - dig4_loss: 0.0561 - nC_loss: 7.4908e-04 - num_acc: 0.9644 - dig1_acc: 0.9087 - dig2_acc: 0.8785 - dig3_acc: 0.9267 - dig4_acc: 0.9858 - nC_acc: 0.9999 - val_loss: 0.9808 - val_num_loss: 0.1120 - val_dig1_loss: 0.2477 - val_dig2_loss: 0.3480 - val_dig3_loss: 0.2123 - val_dig4_loss: 0.0607 - val_nC_loss: 3.6858e-05 - val_num_acc: 0.9609 - val_dig1_acc: 0.9197 - val_dig2_acc: 0.8860 - val_dig3_acc: 0.9316 - val_dig4_acc: 0.9865 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00006: loss improved from 1.40556 to 1.02358, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 7/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.7508 - num_loss: 0.0679 - dig1_loss: 0.2021 - dig2_loss: 0.2642 - dig3_loss: 0.1703 - dig4_loss: 0.0461 - nC_loss: 8.9349e-05 - num_acc: 0.9763 - dig1_acc: 0.9369 - dig2_acc: 0.9135 - dig3_acc: 0.9430 - dig4_acc: 0.9865 - nC_acc: 1.0000 - val_loss: 0.7139 - val_num_loss: 0.0587 - val_dig1_loss: 0.1895 - val_dig2_loss: 0.2566 - val_dig3_loss: 0.1697 - val_dig4_loss: 0.0394 - val_nC_loss: 3.0813e-05 - val_num_acc: 0.9805 - val_dig1_acc: 0.9406 - val_dig2_acc: 0.9172 - val_dig3_acc: 0.9470 - val_dig4_acc: 0.9878 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00007: loss improved from 1.02358 to 0.75075, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 8/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.6147 - num_loss: 0.0548 - dig1_loss: 0.1624 - dig2_loss: 0.2133 - dig3_loss: 0.1418 - dig4_loss: 0.0424 - nC_loss: 1.0765e-04 - num_acc: 0.9810 - dig1_acc: 0.9495 - dig2_acc: 0.9310 - dig3_acc: 0.9537 - dig4_acc: 0.9871 - nC_acc: 1.0000 - val_loss: 0.6277 - val_num_loss: 0.0592 - val_dig1_loss: 0.1551 - val_dig2_loss: 0.2274 - val_dig3_loss: 0.1451 - val_dig4_loss: 0.0410 - val_nC_loss: 2.2429e-05 - val_num_acc: 0.9804 - val_dig1_acc: 0.9529 - val_dig2_acc: 0.9266 - val_dig3_acc: 0.9544 - val_dig4_acc: 0.9873 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00008: loss improved from 0.75075 to 0.61468, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 9/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.5171 - num_loss: 0.0447 - dig1_loss: 0.1367 - dig2_loss: 0.1785 - dig3_loss: 0.1184 - dig4_loss: 0.0385 - nC_loss: 2.0776e-04 - num_acc: 0.9851 - dig1_acc: 0.9575 - dig2_acc: 0.9427 - dig3_acc: 0.9613 - dig4_acc: 0.9876 - nC_acc: 1.0000 - val_loss: 0.5940 - val_num_loss: 0.0516 - val_dig1_loss: 0.1552 - val_dig2_loss: 0.2138 - val_dig3_loss: 0.1353 - val_dig4_loss: 0.0380 - val_nC_loss: 4.4409e-05 - val_num_acc: 0.9829 - val_dig1_acc: 0.9522 - val_dig2_acc: 0.9344 - val_dig3_acc: 0.9590 - val_dig4_acc: 0.9875 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00009: loss improved from 0.61468 to 0.51711, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 10/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.4422 - num_loss: 0.0369 - dig1_loss: 0.1168 - dig2_loss: 0.1494 - dig3_loss: 0.1028 - dig4_loss: 0.0358 - nC_loss: 5.0746e-04 - num_acc: 0.9876 - dig1_acc: 0.9630 - dig2_acc: 0.9521 - dig3_acc: 0.9671 - dig4_acc: 0.9888 - nC_acc: 1.0000 - val_loss: 0.5581 - val_num_loss: 0.0512 - val_dig1_loss: 0.1427 - val_dig2_loss: 0.1975 - val_dig3_loss: 0.1282 - val_dig4_loss: 0.0384 - val_nC_loss: 2.4414e-05 - val_num_acc: 0.9837 - val_dig1_acc: 0.9571 - val_dig2_acc: 0.9403 - val_dig3_acc: 0.9628 - val_dig4_acc: 0.9878 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.51711 to 0.44216, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 11/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.4517 - num_loss: 0.0395 - dig1_loss: 0.1200 - dig2_loss: 0.1530 - dig3_loss: 0.1030 - dig4_loss: 0.0358 - nC_loss: 3.5487e-04 - num_acc: 0.9866 - dig1_acc: 0.9626 - dig2_acc: 0.9511 - dig3_acc: 0.9671 - dig4_acc: 0.9884 - nC_acc: 0.9999 - val_loss: 0.5319 - val_num_loss: 0.0471 - val_dig1_loss: 0.1361 - val_dig2_loss: 0.1915 - val_dig3_loss: 0.1211 - val_dig4_loss: 0.0362 - val_nC_loss: 2.1543e-05 - val_num_acc: 0.9849 - val_dig1_acc: 0.9578 - val_dig2_acc: 0.9422 - val_dig3_acc: 0.9641 - val_dig4_acc: 0.9885 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.44216\n",
      "Epoch 12/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.3504 - num_loss: 0.0275 - dig1_loss: 0.0913 - dig2_loss: 0.1185 - dig3_loss: 0.0820 - dig4_loss: 0.0310 - nC_loss: 2.0116e-05 - num_acc: 0.9903 - dig1_acc: 0.9714 - dig2_acc: 0.9618 - dig3_acc: 0.9734 - dig4_acc: 0.9897 - nC_acc: 1.0000 - val_loss: 0.5422 - val_num_loss: 0.0510 - val_dig1_loss: 0.1436 - val_dig2_loss: 0.1880 - val_dig3_loss: 0.1250 - val_dig4_loss: 0.0345 - val_nC_loss: 1.5250e-05 - val_num_acc: 0.9844 - val_dig1_acc: 0.9567 - val_dig2_acc: 0.9448 - val_dig3_acc: 0.9636 - val_dig4_acc: 0.9893 - val_nC_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: loss improved from 0.44216 to 0.35039, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 13/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2932 - num_loss: 0.0226 - dig1_loss: 0.0756 - dig2_loss: 0.0985 - dig3_loss: 0.0697 - dig4_loss: 0.0267 - nC_loss: 1.5327e-05 - num_acc: 0.9923 - dig1_acc: 0.9762 - dig2_acc: 0.9685 - dig3_acc: 0.9764 - dig4_acc: 0.9909 - nC_acc: 1.0000 - val_loss: 0.5383 - val_num_loss: 0.0562 - val_dig1_loss: 0.1336 - val_dig2_loss: 0.1956 - val_dig3_loss: 0.1193 - val_dig4_loss: 0.0336 - val_nC_loss: 1.2015e-05 - val_num_acc: 0.9844 - val_dig1_acc: 0.9625 - val_dig2_acc: 0.9440 - val_dig3_acc: 0.9655 - val_dig4_acc: 0.9899 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00013: loss improved from 0.35039 to 0.29315, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 14/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2656 - num_loss: 0.0196 - dig1_loss: 0.0699 - dig2_loss: 0.0883 - dig3_loss: 0.0621 - dig4_loss: 0.0257 - nC_loss: 1.2332e-05 - num_acc: 0.9932 - dig1_acc: 0.9781 - dig2_acc: 0.9714 - dig3_acc: 0.9792 - dig4_acc: 0.9911 - nC_acc: 1.0000 - val_loss: 0.5514 - val_num_loss: 0.0562 - val_dig1_loss: 0.1421 - val_dig2_loss: 0.1926 - val_dig3_loss: 0.1276 - val_dig4_loss: 0.0327 - val_nC_loss: 2.7233e-04 - val_num_acc: 0.9840 - val_dig1_acc: 0.9601 - val_dig2_acc: 0.9448 - val_dig3_acc: 0.9657 - val_dig4_acc: 0.9904 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00014: loss improved from 0.29315 to 0.26563, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 15/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2370 - num_loss: 0.0173 - dig1_loss: 0.0632 - dig2_loss: 0.0788 - dig3_loss: 0.0559 - dig4_loss: 0.0218 - nC_loss: 2.5747e-05 - num_acc: 0.9940 - dig1_acc: 0.9805 - dig2_acc: 0.9747 - dig3_acc: 0.9815 - dig4_acc: 0.9929 - nC_acc: 1.0000 - val_loss: 0.5449 - val_num_loss: 0.0563 - val_dig1_loss: 0.1432 - val_dig2_loss: 0.1940 - val_dig3_loss: 0.1198 - val_dig4_loss: 0.0317 - val_nC_loss: 7.1843e-06 - val_num_acc: 0.9849 - val_dig1_acc: 0.9619 - val_dig2_acc: 0.9492 - val_dig3_acc: 0.9682 - val_dig4_acc: 0.9903 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00015: loss improved from 0.26563 to 0.23701, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 16/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2152 - num_loss: 0.0153 - dig1_loss: 0.0578 - dig2_loss: 0.0730 - dig3_loss: 0.0497 - dig4_loss: 0.0192 - nC_loss: 2.4151e-04 - num_acc: 0.9949 - dig1_acc: 0.9820 - dig2_acc: 0.9765 - dig3_acc: 0.9833 - dig4_acc: 0.9935 - nC_acc: 1.0000 - val_loss: 0.5716 - val_num_loss: 0.0604 - val_dig1_loss: 0.1487 - val_dig2_loss: 0.2039 - val_dig3_loss: 0.1256 - val_dig4_loss: 0.0330 - val_nC_loss: 2.4906e-05 - val_num_acc: 0.9844 - val_dig1_acc: 0.9608 - val_dig2_acc: 0.9463 - val_dig3_acc: 0.9677 - val_dig4_acc: 0.9916 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00016: loss improved from 0.23701 to 0.21522, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 17/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2060 - num_loss: 0.0150 - dig1_loss: 0.0539 - dig2_loss: 0.0713 - dig3_loss: 0.0483 - dig4_loss: 0.0174 - nC_loss: 1.5900e-05 - num_acc: 0.9950 - dig1_acc: 0.9831 - dig2_acc: 0.9772 - dig3_acc: 0.9839 - dig4_acc: 0.9943 - nC_acc: 1.0000 - val_loss: 0.6001 - val_num_loss: 0.0648 - val_dig1_loss: 0.1615 - val_dig2_loss: 0.2080 - val_dig3_loss: 0.1322 - val_dig4_loss: 0.0337 - val_nC_loss: 9.2180e-06 - val_num_acc: 0.9825 - val_dig1_acc: 0.9592 - val_dig2_acc: 0.9456 - val_dig3_acc: 0.9654 - val_dig4_acc: 0.9910 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00017: loss improved from 0.21522 to 0.20601, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 18/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2048 - num_loss: 0.0154 - dig1_loss: 0.0560 - dig2_loss: 0.0699 - dig3_loss: 0.0461 - dig4_loss: 0.0173 - nC_loss: 1.4456e-04 - num_acc: 0.9947 - dig1_acc: 0.9829 - dig2_acc: 0.9771 - dig3_acc: 0.9847 - dig4_acc: 0.9941 - nC_acc: 1.0000 - val_loss: 0.8265 - val_num_loss: 0.0884 - val_dig1_loss: 0.2162 - val_dig2_loss: 0.3068 - val_dig3_loss: 0.1751 - val_dig4_loss: 0.0395 - val_nC_loss: 4.3526e-04 - val_num_acc: 0.9695 - val_dig1_acc: 0.9351 - val_dig2_acc: 0.9029 - val_dig3_acc: 0.9453 - val_dig4_acc: 0.9887 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00018: loss improved from 0.20601 to 0.20476, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 19/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2405 - num_loss: 0.0194 - dig1_loss: 0.0646 - dig2_loss: 0.0836 - dig3_loss: 0.0545 - dig4_loss: 0.0181 - nC_loss: 1.8797e-04 - num_acc: 0.9929 - dig1_acc: 0.9794 - dig2_acc: 0.9740 - dig3_acc: 0.9819 - dig4_acc: 0.9938 - nC_acc: 1.0000 - val_loss: 0.5988 - val_num_loss: 0.0653 - val_dig1_loss: 0.1497 - val_dig2_loss: 0.2110 - val_dig3_loss: 0.1395 - val_dig4_loss: 0.0333 - val_nC_loss: 2.5674e-05 - val_num_acc: 0.9840 - val_dig1_acc: 0.9618 - val_dig2_acc: 0.9478 - val_dig3_acc: 0.9678 - val_dig4_acc: 0.9911 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.20476\n",
      "Epoch 20/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.2008 - num_loss: 0.0147 - dig1_loss: 0.0547 - dig2_loss: 0.0693 - dig3_loss: 0.0451 - dig4_loss: 0.0169 - nC_loss: 9.1930e-05 - num_acc: 0.9947 - dig1_acc: 0.9827 - dig2_acc: 0.9777 - dig3_acc: 0.9848 - dig4_acc: 0.9942 - nC_acc: 1.0000 - val_loss: 0.5746 - val_num_loss: 0.0586 - val_dig1_loss: 0.1495 - val_dig2_loss: 0.2113 - val_dig3_loss: 0.1230 - val_dig4_loss: 0.0321 - val_nC_loss: 7.3588e-06 - val_num_acc: 0.9866 - val_dig1_acc: 0.9645 - val_dig2_acc: 0.9497 - val_dig3_acc: 0.9693 - val_dig4_acc: 0.9920 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00020: loss improved from 0.20476 to 0.20081, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 21/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.1365 - num_loss: 0.0089 - dig1_loss: 0.0368 - dig2_loss: 0.0466 - dig3_loss: 0.0320 - dig4_loss: 0.0123 - nC_loss: 5.6272e-06 - num_acc: 0.9969 - dig1_acc: 0.9883 - dig2_acc: 0.9845 - dig3_acc: 0.9894 - dig4_acc: 0.9958 - nC_acc: 1.0000 - val_loss: 0.6568 - val_num_loss: 0.0650 - val_dig1_loss: 0.1750 - val_dig2_loss: 0.2324 - val_dig3_loss: 0.1458 - val_dig4_loss: 0.0386 - val_nC_loss: 6.4378e-06 - val_num_acc: 0.9852 - val_dig1_acc: 0.9626 - val_dig2_acc: 0.9478 - val_dig3_acc: 0.9684 - val_dig4_acc: 0.9909 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.20081 to 0.13647, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 22/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.1369 - num_loss: 0.0097 - dig1_loss: 0.0361 - dig2_loss: 0.0464 - dig3_loss: 0.0337 - dig4_loss: 0.0111 - nC_loss: 9.8621e-06 - num_acc: 0.9966 - dig1_acc: 0.9884 - dig2_acc: 0.9850 - dig3_acc: 0.9890 - dig4_acc: 0.9962 - nC_acc: 1.0000 - val_loss: 0.5966 - val_num_loss: 0.0618 - val_dig1_loss: 0.1561 - val_dig2_loss: 0.2095 - val_dig3_loss: 0.1379 - val_dig4_loss: 0.0314 - val_nC_loss: 4.8984e-06 - val_num_acc: 0.9861 - val_dig1_acc: 0.9646 - val_dig2_acc: 0.9529 - val_dig3_acc: 0.9700 - val_dig4_acc: 0.9925 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.13647\n",
      "Epoch 23/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.1272 - num_loss: 0.0090 - dig1_loss: 0.0353 - dig2_loss: 0.0433 - dig3_loss: 0.0295 - dig4_loss: 0.0101 - nC_loss: 1.4819e-05 - num_acc: 0.9967 - dig1_acc: 0.9887 - dig2_acc: 0.9857 - dig3_acc: 0.9906 - dig4_acc: 0.9966 - nC_acc: 1.0000 - val_loss: 0.6340 - val_num_loss: 0.0673 - val_dig1_loss: 0.1616 - val_dig2_loss: 0.2259 - val_dig3_loss: 0.1434 - val_dig4_loss: 0.0357 - val_nC_loss: 3.9695e-05 - val_num_acc: 0.9847 - val_dig1_acc: 0.9624 - val_dig2_acc: 0.9511 - val_dig3_acc: 0.9692 - val_dig4_acc: 0.9917 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00023: loss improved from 0.13647 to 0.12717, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 24/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.1226 - num_loss: 0.0080 - dig1_loss: 0.0333 - dig2_loss: 0.0431 - dig3_loss: 0.0281 - dig4_loss: 0.0101 - nC_loss: 7.8946e-06 - num_acc: 0.9972 - dig1_acc: 0.9895 - dig2_acc: 0.9859 - dig3_acc: 0.9905 - dig4_acc: 0.9968 - nC_acc: 1.0000 - val_loss: 0.6435 - val_num_loss: 0.0690 - val_dig1_loss: 0.1650 - val_dig2_loss: 0.2258 - val_dig3_loss: 0.1472 - val_dig4_loss: 0.0365 - val_nC_loss: 1.0987e-05 - val_num_acc: 0.9852 - val_dig1_acc: 0.9636 - val_dig2_acc: 0.9516 - val_dig3_acc: 0.9697 - val_dig4_acc: 0.9920 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00024: loss improved from 0.12717 to 0.12263, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 25/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.1067 - num_loss: 0.0073 - dig1_loss: 0.0291 - dig2_loss: 0.0362 - dig3_loss: 0.0250 - dig4_loss: 0.0092 - nC_loss: 5.8632e-06 - num_acc: 0.9977 - dig1_acc: 0.9908 - dig2_acc: 0.9888 - dig3_acc: 0.9917 - dig4_acc: 0.9969 - nC_acc: 1.0000 - val_loss: 0.6949 - val_num_loss: 0.0711 - val_dig1_loss: 0.1918 - val_dig2_loss: 0.2475 - val_dig3_loss: 0.1486 - val_dig4_loss: 0.0359 - val_nC_loss: 4.4343e-06 - val_num_acc: 0.9851 - val_dig1_acc: 0.9622 - val_dig2_acc: 0.9508 - val_dig3_acc: 0.9701 - val_dig4_acc: 0.9932 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00025: loss improved from 0.12263 to 0.10675, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 26/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.1215 - num_loss: 0.0094 - dig1_loss: 0.0336 - dig2_loss: 0.0420 - dig3_loss: 0.0271 - dig4_loss: 0.0093 - nC_loss: 5.3166e-06 - num_acc: 0.9967 - dig1_acc: 0.9895 - dig2_acc: 0.9870 - dig3_acc: 0.9910 - dig4_acc: 0.9968 - nC_acc: 1.0000 - val_loss: 0.6745 - val_num_loss: 0.0695 - val_dig1_loss: 0.1752 - val_dig2_loss: 0.2495 - val_dig3_loss: 0.1470 - val_dig4_loss: 0.0332 - val_nC_loss: 5.0483e-06 - val_num_acc: 0.9828 - val_dig1_acc: 0.9620 - val_dig2_acc: 0.9444 - val_dig3_acc: 0.9687 - val_dig4_acc: 0.9926 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.10675\n",
      "Epoch 27/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.1152 - num_loss: 0.0085 - dig1_loss: 0.0333 - dig2_loss: 0.0401 - dig3_loss: 0.0264 - dig4_loss: 0.0070 - nC_loss: 6.7190e-06 - num_acc: 0.9970 - dig1_acc: 0.9902 - dig2_acc: 0.9870 - dig3_acc: 0.9916 - dig4_acc: 0.9975 - nC_acc: 1.0000 - val_loss: 0.6052 - val_num_loss: 0.0657 - val_dig1_loss: 0.1528 - val_dig2_loss: 0.2140 - val_dig3_loss: 0.1412 - val_dig4_loss: 0.0314 - val_nC_loss: 5.9183e-06 - val_num_acc: 0.9847 - val_dig1_acc: 0.9643 - val_dig2_acc: 0.9533 - val_dig3_acc: 0.9706 - val_dig4_acc: 0.9929 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.10675\n",
      "Epoch 28/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.1069 - num_loss: 0.0080 - dig1_loss: 0.0293 - dig2_loss: 0.0378 - dig3_loss: 0.0239 - dig4_loss: 0.0079 - nC_loss: 1.8884e-05 - num_acc: 0.9973 - dig1_acc: 0.9908 - dig2_acc: 0.9878 - dig3_acc: 0.9923 - dig4_acc: 0.9974 - nC_acc: 1.0000 - val_loss: 0.6578 - val_num_loss: 0.0756 - val_dig1_loss: 0.1681 - val_dig2_loss: 0.2274 - val_dig3_loss: 0.1533 - val_dig4_loss: 0.0335 - val_nC_loss: 1.1415e-05 - val_num_acc: 0.9827 - val_dig1_acc: 0.9622 - val_dig2_acc: 0.9496 - val_dig3_acc: 0.9688 - val_dig4_acc: 0.9933 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.10675\n",
      "Epoch 29/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0923 - num_loss: 0.0060 - dig1_loss: 0.0266 - dig2_loss: 0.0304 - dig3_loss: 0.0217 - dig4_loss: 0.0077 - nC_loss: 4.7610e-06 - num_acc: 0.9981 - dig1_acc: 0.9919 - dig2_acc: 0.9906 - dig3_acc: 0.9929 - dig4_acc: 0.9975 - nC_acc: 1.0000 - val_loss: 0.6442 - val_num_loss: 0.0708 - val_dig1_loss: 0.1672 - val_dig2_loss: 0.2328 - val_dig3_loss: 0.1428 - val_dig4_loss: 0.0307 - val_nC_loss: 6.4247e-06 - val_num_acc: 0.9853 - val_dig1_acc: 0.9638 - val_dig2_acc: 0.9508 - val_dig3_acc: 0.9708 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00029: loss improved from 0.10675 to 0.09235, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 30/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0794 - num_loss: 0.0048 - dig1_loss: 0.0229 - dig2_loss: 0.0282 - dig3_loss: 0.0184 - dig4_loss: 0.0051 - nC_loss: 1.5558e-05 - num_acc: 0.9984 - dig1_acc: 0.9931 - dig2_acc: 0.9912 - dig3_acc: 0.9941 - dig4_acc: 0.9984 - nC_acc: 1.0000 - val_loss: 0.6872 - val_num_loss: 0.0705 - val_dig1_loss: 0.1765 - val_dig2_loss: 0.2450 - val_dig3_loss: 0.1616 - val_dig4_loss: 0.0337 - val_nC_loss: 5.1314e-06 - val_num_acc: 0.9860 - val_dig1_acc: 0.9652 - val_dig2_acc: 0.9525 - val_dig3_acc: 0.9701 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00030: loss improved from 0.09235 to 0.07936, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 31/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0871 - num_loss: 0.0061 - dig1_loss: 0.0257 - dig2_loss: 0.0292 - dig3_loss: 0.0201 - dig4_loss: 0.0059 - nC_loss: 3.9353e-06 - num_acc: 0.9979 - dig1_acc: 0.9920 - dig2_acc: 0.9899 - dig3_acc: 0.9938 - dig4_acc: 0.9981 - nC_acc: 1.0000 - val_loss: 0.6875 - val_num_loss: 0.0728 - val_dig1_loss: 0.1820 - val_dig2_loss: 0.2497 - val_dig3_loss: 0.1484 - val_dig4_loss: 0.0346 - val_nC_loss: 6.2870e-06 - val_num_acc: 0.9850 - val_dig1_acc: 0.9638 - val_dig2_acc: 0.9525 - val_dig3_acc: 0.9714 - val_dig4_acc: 0.9927 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.07936\n",
      "Epoch 32/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0825 - num_loss: 0.0053 - dig1_loss: 0.0244 - dig2_loss: 0.0277 - dig3_loss: 0.0192 - dig4_loss: 0.0060 - nC_loss: 5.6732e-06 - num_acc: 0.9983 - dig1_acc: 0.9926 - dig2_acc: 0.9912 - dig3_acc: 0.9938 - dig4_acc: 0.9982 - nC_acc: 1.0000 - val_loss: 0.6913 - val_num_loss: 0.0728 - val_dig1_loss: 0.1838 - val_dig2_loss: 0.2497 - val_dig3_loss: 0.1508 - val_dig4_loss: 0.0342 - val_nC_loss: 1.0047e-05 - val_num_acc: 0.9845 - val_dig1_acc: 0.9625 - val_dig2_acc: 0.9509 - val_dig3_acc: 0.9709 - val_dig4_acc: 0.9931 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.07936\n",
      "Epoch 33/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0888 - num_loss: 0.0070 - dig1_loss: 0.0241 - dig2_loss: 0.0314 - dig3_loss: 0.0201 - dig4_loss: 0.0062 - nC_loss: 5.9797e-06 - num_acc: 0.9977 - dig1_acc: 0.9926 - dig2_acc: 0.9906 - dig3_acc: 0.9934 - dig4_acc: 0.9980 - nC_acc: 1.0000 - val_loss: 0.6986 - val_num_loss: 0.0758 - val_dig1_loss: 0.1801 - val_dig2_loss: 0.2603 - val_dig3_loss: 0.1448 - val_dig4_loss: 0.0377 - val_nC_loss: 7.0166e-06 - val_num_acc: 0.9847 - val_dig1_acc: 0.9623 - val_dig2_acc: 0.9482 - val_dig3_acc: 0.9702 - val_dig4_acc: 0.9924 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.07936\n",
      "Epoch 34/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0906 - num_loss: 0.0075 - dig1_loss: 0.0232 - dig2_loss: 0.0324 - dig3_loss: 0.0207 - dig4_loss: 0.0069 - nC_loss: 7.5280e-06 - num_acc: 0.9974 - dig1_acc: 0.9926 - dig2_acc: 0.9899 - dig3_acc: 0.9937 - dig4_acc: 0.9975 - nC_acc: 1.0000 - val_loss: 0.7240 - val_num_loss: 0.0786 - val_dig1_loss: 0.1879 - val_dig2_loss: 0.2564 - val_dig3_loss: 0.1591 - val_dig4_loss: 0.0420 - val_nC_loss: 6.1268e-06 - val_num_acc: 0.9837 - val_dig1_acc: 0.9626 - val_dig2_acc: 0.9515 - val_dig3_acc: 0.9705 - val_dig4_acc: 0.9923 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.07936\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 35/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0385 - num_loss: 0.0027 - dig1_loss: 0.0103 - dig2_loss: 0.0131 - dig3_loss: 0.0091 - dig4_loss: 0.0033 - nC_loss: 2.7610e-06 - num_acc: 0.9992 - dig1_acc: 0.9968 - dig2_acc: 0.9960 - dig3_acc: 0.9971 - dig4_acc: 0.9989 - nC_acc: 1.0000 - val_loss: 0.6556 - val_num_loss: 0.0678 - val_dig1_loss: 0.1734 - val_dig2_loss: 0.2332 - val_dig3_loss: 0.1480 - val_dig4_loss: 0.0332 - val_nC_loss: 3.3828e-06 - val_num_acc: 0.9862 - val_dig1_acc: 0.9660 - val_dig2_acc: 0.9560 - val_dig3_acc: 0.9737 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: loss improved from 0.07936 to 0.03852, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 36/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0129 - num_loss: 9.3879e-04 - dig1_loss: 0.0033 - dig2_loss: 0.0044 - dig3_loss: 0.0031 - dig4_loss: 0.0012 - nC_loss: 1.7067e-06 - num_acc: 0.9998 - dig1_acc: 0.9993 - dig2_acc: 0.9989 - dig3_acc: 0.9993 - dig4_acc: 0.9998 - nC_acc: 1.0000 - val_loss: 0.6957 - val_num_loss: 0.0732 - val_dig1_loss: 0.1842 - val_dig2_loss: 0.2447 - val_dig3_loss: 0.1579 - val_dig4_loss: 0.0358 - val_nC_loss: 2.1615e-06 - val_num_acc: 0.9863 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9567 - val_dig3_acc: 0.9744 - val_dig4_acc: 0.9934 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00036: loss improved from 0.03852 to 0.01288, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 37/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0078 - num_loss: 5.7797e-04 - dig1_loss: 0.0021 - dig2_loss: 0.0028 - dig3_loss: 0.0017 - dig4_loss: 6.0184e-04 - nC_loss: 1.1433e-06 - num_acc: 0.9999 - dig1_acc: 0.9997 - dig2_acc: 0.9994 - dig3_acc: 0.9997 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.7250 - val_num_loss: 0.0769 - val_dig1_loss: 0.1916 - val_dig2_loss: 0.2548 - val_dig3_loss: 0.1646 - val_dig4_loss: 0.0371 - val_nC_loss: 1.4979e-06 - val_num_acc: 0.9862 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9569 - val_dig3_acc: 0.9747 - val_dig4_acc: 0.9934 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00037: loss improved from 0.01288 to 0.00778, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 38/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0056 - num_loss: 4.2794e-04 - dig1_loss: 0.0016 - dig2_loss: 0.0020 - dig3_loss: 0.0012 - dig4_loss: 3.7970e-04 - nC_loss: 8.8658e-07 - num_acc: 0.9999 - dig1_acc: 0.9997 - dig2_acc: 0.9997 - dig3_acc: 0.9999 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7521 - val_num_loss: 0.0803 - val_dig1_loss: 0.1995 - val_dig2_loss: 0.2634 - val_dig3_loss: 0.1707 - val_dig4_loss: 0.0382 - val_nC_loss: 1.1793e-06 - val_num_acc: 0.9861 - val_dig1_acc: 0.9667 - val_dig2_acc: 0.9569 - val_dig3_acc: 0.9746 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00038: loss improved from 0.00778 to 0.00564, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 39/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0044 - num_loss: 3.3598e-04 - dig1_loss: 0.0013 - dig2_loss: 0.0016 - dig3_loss: 9.2072e-04 - dig4_loss: 2.8232e-04 - nC_loss: 7.1467e-07 - num_acc: 1.0000 - dig1_acc: 0.9998 - dig2_acc: 0.9998 - dig3_acc: 0.9999 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7725 - val_num_loss: 0.0827 - val_dig1_loss: 0.2049 - val_dig2_loss: 0.2703 - val_dig3_loss: 0.1755 - val_dig4_loss: 0.0391 - val_nC_loss: 9.6208e-07 - val_num_acc: 0.9864 - val_dig1_acc: 0.9669 - val_dig2_acc: 0.9576 - val_dig3_acc: 0.9749 - val_dig4_acc: 0.9934 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00039: loss improved from 0.00564 to 0.00442, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 40/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0036 - num_loss: 2.7770e-04 - dig1_loss: 0.0011 - dig2_loss: 0.0013 - dig3_loss: 7.3061e-04 - dig4_loss: 2.2026e-04 - nC_loss: 6.1160e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 0.9998 - dig3_acc: 0.9999 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7911 - val_num_loss: 0.0848 - val_dig1_loss: 0.2098 - val_dig2_loss: 0.2766 - val_dig3_loss: 0.1799 - val_dig4_loss: 0.0399 - val_nC_loss: 8.2271e-07 - val_num_acc: 0.9863 - val_dig1_acc: 0.9669 - val_dig2_acc: 0.9576 - val_dig3_acc: 0.9750 - val_dig4_acc: 0.9933 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00040: loss improved from 0.00442 to 0.00362, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 41/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0030 - num_loss: 2.3559e-04 - dig1_loss: 9.6545e-04 - dig2_loss: 0.0011 - dig3_loss: 6.0554e-04 - dig4_loss: 1.8104e-04 - nC_loss: 5.3240e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 0.9998 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8067 - val_num_loss: 0.0868 - val_dig1_loss: 0.2141 - val_dig2_loss: 0.2821 - val_dig3_loss: 0.1832 - val_dig4_loss: 0.0405 - val_nC_loss: 7.1421e-07 - val_num_acc: 0.9866 - val_dig1_acc: 0.9668 - val_dig2_acc: 0.9574 - val_dig3_acc: 0.9752 - val_dig4_acc: 0.9933 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00041: loss improved from 0.00362 to 0.00304, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 42/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0066 - num_loss: 5.2987e-04 - dig1_loss: 0.0023 - dig2_loss: 0.0021 - dig3_loss: 0.0012 - dig4_loss: 4.3007e-04 - nC_loss: 5.8931e-07 - num_acc: 0.9999 - dig1_acc: 0.9996 - dig2_acc: 0.9994 - dig3_acc: 0.9997 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.7709 - val_num_loss: 0.0831 - val_dig1_loss: 0.2076 - val_dig2_loss: 0.2692 - val_dig3_loss: 0.1714 - val_dig4_loss: 0.0393 - val_nC_loss: 2.3957e-04 - val_num_acc: 0.9864 - val_dig1_acc: 0.9655 - val_dig2_acc: 0.9573 - val_dig3_acc: 0.9742 - val_dig4_acc: 0.9932 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00304\n",
      "Epoch 43/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0060 - num_loss: 4.2306e-04 - dig1_loss: 0.0018 - dig2_loss: 0.0020 - dig3_loss: 0.0014 - dig4_loss: 4.2325e-04 - nC_loss: 5.4105e-07 - num_acc: 0.9999 - dig1_acc: 0.9997 - dig2_acc: 0.9995 - dig3_acc: 0.9997 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7809 - val_num_loss: 0.0845 - val_dig1_loss: 0.2086 - val_dig2_loss: 0.2734 - val_dig3_loss: 0.1757 - val_dig4_loss: 0.0387 - val_nC_loss: 1.2083e-05 - val_num_acc: 0.9865 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9578 - val_dig3_acc: 0.9755 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00304\n",
      "Epoch 44/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0029 - num_loss: 2.2721e-04 - dig1_loss: 8.9380e-04 - dig2_loss: 9.5573e-04 - dig3_loss: 6.2662e-04 - dig4_loss: 1.8847e-04 - nC_loss: 4.3380e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 0.9999 - dig3_acc: 0.9999 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7984 - val_num_loss: 0.0865 - val_dig1_loss: 0.2130 - val_dig2_loss: 0.2795 - val_dig3_loss: 0.1798 - val_dig4_loss: 0.0395 - val_nC_loss: 1.0275e-05 - val_num_acc: 0.9867 - val_dig1_acc: 0.9665 - val_dig2_acc: 0.9581 - val_dig3_acc: 0.9755 - val_dig4_acc: 0.9935 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00044: loss improved from 0.00304 to 0.00289, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 45/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0023 - num_loss: 1.8425e-04 - dig1_loss: 7.5642e-04 - dig2_loss: 7.6215e-04 - dig3_loss: 4.7783e-04 - dig4_loss: 1.4487e-04 - nC_loss: 4.2706e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 0.9999 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8129 - val_num_loss: 0.0881 - val_dig1_loss: 0.2167 - val_dig2_loss: 0.2848 - val_dig3_loss: 0.1832 - val_dig4_loss: 0.0402 - val_nC_loss: 6.5849e-06 - val_num_acc: 0.9867 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9582 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9936 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.00289 to 0.00233, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 46/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0020 - num_loss: 1.5929e-04 - dig1_loss: 6.6976e-04 - dig2_loss: 6.4173e-04 - dig3_loss: 4.0004e-04 - dig4_loss: 1.1860e-04 - nC_loss: 4.2234e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 1.0000 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8253 - val_num_loss: 0.0896 - val_dig1_loss: 0.2200 - val_dig2_loss: 0.2891 - val_dig3_loss: 0.1859 - val_dig4_loss: 0.0408 - val_nC_loss: 4.7466e-06 - val_num_acc: 0.9866 - val_dig1_acc: 0.9669 - val_dig2_acc: 0.9585 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9936 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00046: loss improved from 0.00233 to 0.00199, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 47/50\n",
      "69076/69076 [==============================] - 80s 1ms/step - loss: 0.0018 - num_loss: 1.3904e-04 - dig1_loss: 6.0964e-04 - dig2_loss: 5.5611e-04 - dig3_loss: 3.4397e-04 - dig4_loss: 1.0157e-04 - nC_loss: 3.7990e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 1.0000 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8363 - val_num_loss: 0.0909 - val_dig1_loss: 0.2230 - val_dig2_loss: 0.2930 - val_dig3_loss: 0.1882 - val_dig4_loss: 0.0412 - val_nC_loss: 3.5483e-06 - val_num_acc: 0.9866 - val_dig1_acc: 0.9669 - val_dig2_acc: 0.9585 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9937 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00047: loss improved from 0.00199 to 0.00175, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 48/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0016 - num_loss: 1.2478e-04 - dig1_loss: 5.6400e-04 - dig2_loss: 4.9113e-04 - dig3_loss: 3.0141e-04 - dig4_loss: 8.8120e-05 - nC_loss: 3.4865e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 1.0000 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8458 - val_num_loss: 0.0920 - val_dig1_loss: 0.2255 - val_dig2_loss: 0.2964 - val_dig3_loss: 0.1902 - val_dig4_loss: 0.0417 - val_nC_loss: 2.4517e-06 - val_num_acc: 0.9866 - val_dig1_acc: 0.9669 - val_dig2_acc: 0.9586 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9936 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00048: loss improved from 0.00175 to 0.00157, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 49/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0014 - num_loss: 1.1265e-04 - dig1_loss: 5.2795e-04 - dig2_loss: 4.3721e-04 - dig3_loss: 2.6809e-04 - dig4_loss: 7.7831e-05 - nC_loss: 3.2369e-07 - num_acc: 1.0000 - dig1_acc: 0.9999 - dig2_acc: 1.0000 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8548 - val_num_loss: 0.0931 - val_dig1_loss: 0.2280 - val_dig2_loss: 0.2995 - val_dig3_loss: 0.1921 - val_dig4_loss: 0.0421 - val_nC_loss: 1.8899e-06 - val_num_acc: 0.9865 - val_dig1_acc: 0.9668 - val_dig2_acc: 0.9585 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9936 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00049: loss improved from 0.00157 to 0.00142, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 50/50\n",
      "69076/69076 [==============================] - 81s 1ms/step - loss: 0.0013 - num_loss: 1.0230e-04 - dig1_loss: 4.9721e-04 - dig2_loss: 3.9418e-04 - dig3_loss: 2.4088e-04 - dig4_loss: 6.9420e-05 - nC_loss: 3.0989e-07 - num_acc: 1.0000 - dig1_acc: 1.0000 - dig2_acc: 1.0000 - dig3_acc: 1.0000 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.8633 - val_num_loss: 0.0941 - val_dig1_loss: 0.2302 - val_dig2_loss: 0.3026 - val_dig3_loss: 0.1939 - val_dig4_loss: 0.0425 - val_nC_loss: 1.5411e-06 - val_num_acc: 0.9865 - val_dig1_acc: 0.9670 - val_dig2_acc: 0.9589 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9936 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00050: loss improved from 0.00142 to 0.00130, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "CPU times: user 1h 3min 7s, sys: 13min 50s, total: 1h 16min 57s\n",
      "Wall time: 1h 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vggHistory = vggPreTrain.fit(x = X_train,\n",
    "                             y = list(y_train.T),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             shuffle = True,\n",
    "                             validation_data = (X_val, list(y_val.T)),\n",
    "                             callbacks= callback)\n",
    "\n",
    "print(vggHistory.history.keys())\n",
    "modName = 'vgg16_PreTrain_corrected'\n",
    "# list all data in history\n",
    "print(vggHistory.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg_pretrain_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train loss: 0.0012191442427505605\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Train accuracy: [100.0, 99.99710463836932, 99.99710463836932, 100.0, 100.0, 100.0]\n",
      "Train sequence accuracy: 99.99420927673867\n",
      "Validation loss: 0.8632769504238671\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Validation accuracy: [98.65076148010886, 96.69928774103886, 95.89437720771325, 97.56789623023916, 99.35722971799179, 100.0]\n",
      "Validation sequence accuracy: 92.33887312525334\n",
      "Test loss: 1.9249597305217272\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Test accuracy: [96.96157967243226, 91.51997550895454, 89.759681616409, 95.83652227154447, 99.44129802540947, 100.0]\n",
      "Test sequence accuracy: 81.93020052043471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [100.0,\n",
       "  99.99710463836932,\n",
       "  99.99710463836932,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0],\n",
       " 'test_acc': [96.96157967243226,\n",
       "  91.51997550895454,\n",
       "  89.759681616409,\n",
       "  95.83652227154447,\n",
       "  99.44129802540947,\n",
       "  100.0],\n",
       " 'val_acc': [98.65076148010886,\n",
       "  96.69928774103886,\n",
       "  95.89437720771325,\n",
       "  97.56789623023916,\n",
       "  99.35722971799179,\n",
       "  100.0],\n",
       " 'train_seq_acc': 99.99420927673867,\n",
       " 'test_seq_acc': 81.93020052043471,\n",
       " 'val_seq_acc': 92.33887312525334,\n",
       " 'train_score': [0.0012191442427505605,\n",
       "  9.542184659218849e-05,\n",
       "  0.00047577119569368494,\n",
       "  0.0003629728998552712,\n",
       "  0.00022080434270599865,\n",
       "  6.387599376335974e-05,\n",
       "  2.979689108205491e-07,\n",
       "  1.0,\n",
       "  0.9999710463836933,\n",
       "  0.9999710463836933,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'test_score': [1.9249597305217272,\n",
       "  0.22608713149070242,\n",
       "  0.6083131103722972,\n",
       "  0.7564571753749809,\n",
       "  0.2903091489847405,\n",
       "  0.04378623184903659,\n",
       "  6.951734232663811e-06,\n",
       "  0.9696157967243226,\n",
       "  0.9151997550712981,\n",
       "  0.89759681616409,\n",
       "  0.9583652226971974,\n",
       "  0.9944129802540946,\n",
       "  1.0],\n",
       " 'val_score': [0.8632769504238671,\n",
       "  0.0940574583885234,\n",
       "  0.2302493174947017,\n",
       "  0.30255114309782905,\n",
       "  0.19391753407335105,\n",
       "  0.04249996233630721,\n",
       "  1.541354273413108e-06,\n",
       "  0.9865076148010886,\n",
       "  0.9669928774103885,\n",
       "  0.958943772087487,\n",
       "  0.9756789623058431,\n",
       "  0.9935722971799178,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
