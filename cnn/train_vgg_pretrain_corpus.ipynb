{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        img2 = img\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get three channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.preprocess_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n"
     ]
    }
   ],
   "source": [
    "shape = (64, 64)\n",
    "channel = 3\n",
    "data = generate_data_set_for_training(shape, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try pretrianed Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "import keras.utils as ku\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vgg16_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n",
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 25.1023 - num_loss: 6.2045 - dig1_loss: 6.1920 - dig2_loss: 4.6267 - dig3_loss: 1.6416 - dig4_loss: 0.2354 - nC_loss: 6.2021 - num_acc: 0.6134 - dig1_acc: 0.6142 - dig2_acc: 0.7115 - dig3_acc: 0.8972 - dig4_acc: 0.9848 - nC_acc: 0.6142 - val_loss: 25.3144 - val_num_loss: 6.2563 - val_dig1_loss: 6.2423 - val_dig2_loss: 4.6640 - val_dig3_loss: 1.6782 - val_dig4_loss: 0.2175 - val_nC_loss: 6.2563 - val_num_acc: 0.6118 - val_dig1_acc: 0.6127 - val_dig2_acc: 0.7106 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6118\n",
      "\n",
      "Epoch 00001: loss improved from inf to 25.10234, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 2/50\n",
      "58944/69076 [========================>.....] - ETA: 11s - loss: 25.1449 - num_loss: 6.2163 - dig1_loss: 6.1991 - dig2_loss: 4.6328 - dig3_loss: 1.6464 - dig4_loss: 0.2341 - nC_loss: 6.2163 - num_acc: 0.6143 - dig1_acc: 0.6154 - dig2_acc: 0.7126 - dig3_acc: 0.8979 - dig4_acc: 0.9855 - nC_acc: 0.6143"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eac255ec6f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_pretrained_vgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Yue/projects/cnn/utils/vgg16_utils.py\u001b[0m in \u001b[0;36mrun_pretrained_vgg16\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                                               callbacks=callback)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pretrain_vgg16'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/airbus/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/airbus/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/airbus/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/airbus/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/airbus/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from scratch\n",
    "run_pretrained_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chanel 3\n",
      "row 64\n",
      "col 64\n"
     ]
    }
   ],
   "source": [
    "_, row, col, channel = X_train.shape\n",
    "print('chanel', channel)\n",
    "print('row', row)\n",
    "print('col', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "digLen = 5\n",
    "numDigits = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "preTrainModel = VGG16(include_top = False, weights = 'imagenet')\n",
    "preTrainModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptInput = keras.Input(shape = (row,col,channel), name  = 'inputVGGPreTrain')\n",
    "pt_vgg16 = preTrainModel(ptInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mout = Flatten(name = 'flatten')(pt_vgg16)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_4096')(Mout)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_512')(Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "numd_SM = Dense(digLen,    activation='softmax',name = 'num')(Mout)\n",
    "dig1_SM = Dense(numDigits, activation='softmax',name = 'dig1')(Mout)\n",
    "dig2_SM = Dense(numDigits, activation='softmax',name = 'dig2')(Mout)\n",
    "dig3_SM = Dense(numDigits, activation='softmax',name = 'dig3')(Mout)\n",
    "dig4_SM = Dense(numDigits, activation='softmax',name = 'dig4')(Mout)\n",
    "numB_SM = Dense(2, activation='softmax',name = 'nC')(Mout)\n",
    "out = [numd_SM, dig1_SM ,dig2_SM, dig3_SM, dig4_SM,numB_SM] #numd_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputVGGPreTrain (InputLayer)   (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   multiple             14714688    inputVGGPreTrain[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC1_4096 (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FC1_512 (Dense)                 (None, 1024)         1049600     FC1_4096[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "num (Dense)                     (None, 5)            5125        FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig1 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig2 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig3 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig4 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "nC (Dense)                      (None, 2)            2050        FC1_512[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,914,739\n",
      "Trainable params: 17,914,739\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggPreTrain = keras.Model(inputs = ptInput, outputs = out)\n",
    "\n",
    "vggPreTrain.compile(loss = 'sparse_categorical_crossentropy', #ceLoss ,\n",
    "                    optimizer= optim,\n",
    "                    metrics=  ['accuracy']) #[])\n",
    "vggPreTrain.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = []\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='saved_models/VGGPreTrained.classifier.hdf5',\n",
    "                                               monitor='loss',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
    "                                              factor = 0.1,\n",
    "                                              verbose = 1,\n",
    "                                              patience= 4,\n",
    "                                              cooldown= 1,\n",
    "                                              min_lr = 0.0001)\n",
    "es = keras.callbacks.EarlyStopping(monitor= 'loss',\n",
    "                                   min_delta=0.000001,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   mode='auto')\n",
    "callback.append(es)\n",
    "callback.append(checkpointer)\n",
    "callback.append(reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 2.3698 - num_loss: 0.2870 - dig1_loss: 0.7737 - dig2_loss: 0.8096 - dig3_loss: 0.3982 - dig4_loss: 0.0864 - nC_loss: 0.0149 - num_acc: 0.8856 - dig1_acc: 0.7285 - dig2_acc: 0.7145 - dig3_acc: 0.8970 - dig4_acc: 0.9849 - nC_acc: 0.9940 - val_loss: 2.0318 - val_num_loss: 0.2093 - val_dig1_loss: 0.6195 - val_dig2_loss: 0.7659 - val_dig3_loss: 0.3629 - val_dig4_loss: 0.0726 - val_nC_loss: 0.0016 - val_num_acc: 0.9184 - val_dig1_acc: 0.7934 - val_dig2_acc: 0.7268 - val_dig3_acc: 0.8959 - val_dig4_acc: 0.9865 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.36981, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 2/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 1.6196 - num_loss: 0.1428 - dig1_loss: 0.4816 - dig2_loss: 0.6163 - dig3_loss: 0.3084 - dig4_loss: 0.0695 - nC_loss: 9.2504e-04 - num_acc: 0.9486 - dig1_acc: 0.8344 - dig2_acc: 0.7806 - dig3_acc: 0.9009 - dig4_acc: 0.9857 - nC_acc: 0.9999 - val_loss: 1.2356 - val_num_loss: 0.1000 - val_dig1_loss: 0.3377 - val_dig2_loss: 0.4875 - val_dig3_loss: 0.2586 - val_dig4_loss: 0.0515 - val_nC_loss: 3.2401e-04 - val_num_acc: 0.9660 - val_dig1_acc: 0.8893 - val_dig2_acc: 0.8343 - val_dig3_acc: 0.9114 - val_dig4_acc: 0.9868 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00002: loss improved from 2.36981 to 1.61956, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 3/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 1.4465 - num_loss: 0.1963 - dig1_loss: 0.4210 - dig2_loss: 0.4300 - dig3_loss: 0.2412 - dig4_loss: 0.0675 - nC_loss: 0.0906 - num_acc: 0.9590 - dig1_acc: 0.8905 - dig2_acc: 0.8557 - dig3_acc: 0.9208 - dig4_acc: 0.9849 - nC_acc: 0.9943 - val_loss: 18.7437 - val_num_loss: 5.4110 - val_dig1_loss: 7.3571 - val_dig2_loss: 0.7057 - val_dig3_loss: 0.3573 - val_dig4_loss: 0.0795 - val_nC_loss: 4.8332 - val_num_acc: 0.5853 - val_dig1_acc: 0.2928 - val_dig2_acc: 0.7714 - val_dig3_acc: 0.8969 - val_dig4_acc: 0.9865 - val_nC_acc: 0.6911\n",
      "\n",
      "Epoch 00003: loss improved from 1.61956 to 1.44651, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 4/50\n",
      "69076/69076 [==============================] - 86s 1ms/step - loss: 1.0872 - num_loss: 0.1198 - dig1_loss: 0.3034 - dig2_loss: 0.3793 - dig3_loss: 0.2182 - dig4_loss: 0.0568 - nC_loss: 0.0097 - num_acc: 0.9607 - dig1_acc: 0.9054 - dig2_acc: 0.8738 - dig3_acc: 0.9308 - dig4_acc: 0.9859 - nC_acc: 0.9992 - val_loss: 0.7656 - val_num_loss: 0.0723 - val_dig1_loss: 0.1983 - val_dig2_loss: 0.2761 - val_dig3_loss: 0.1740 - val_dig4_loss: 0.0444 - val_nC_loss: 4.7018e-04 - val_num_acc: 0.9752 - val_dig1_acc: 0.9385 - val_dig2_acc: 0.9098 - val_dig3_acc: 0.9450 - val_dig4_acc: 0.9873 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00004: loss improved from 1.44651 to 1.08716, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 5/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.6737 - num_loss: 0.0641 - dig1_loss: 0.1831 - dig2_loss: 0.2364 - dig3_loss: 0.1446 - dig4_loss: 0.0441 - nC_loss: 0.0014 - num_acc: 0.9786 - dig1_acc: 0.9438 - dig2_acc: 0.9253 - dig3_acc: 0.9540 - dig4_acc: 0.9865 - nC_acc: 0.9998 - val_loss: 0.6629 - val_num_loss: 0.0667 - val_dig1_loss: 0.1765 - val_dig2_loss: 0.2359 - val_dig3_loss: 0.1414 - val_dig4_loss: 0.0421 - val_nC_loss: 2.9927e-04 - val_num_acc: 0.9792 - val_dig1_acc: 0.9469 - val_dig2_acc: 0.9275 - val_dig3_acc: 0.9562 - val_dig4_acc: 0.9870 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00005: loss improved from 1.08716 to 0.67368, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 6/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.5209 - num_loss: 0.0480 - dig1_loss: 0.1418 - dig2_loss: 0.1795 - dig3_loss: 0.1125 - dig4_loss: 0.0390 - nC_loss: 7.7946e-05 - num_acc: 0.9848 - dig1_acc: 0.9568 - dig2_acc: 0.9445 - dig3_acc: 0.9649 - dig4_acc: 0.9875 - nC_acc: 1.0000 - val_loss: 0.5253 - val_num_loss: 0.0499 - val_dig1_loss: 0.1345 - val_dig2_loss: 0.1862 - val_dig3_loss: 0.1158 - val_dig4_loss: 0.0388 - val_nC_loss: 7.5758e-05 - val_num_acc: 0.9842 - val_dig1_acc: 0.9598 - val_dig2_acc: 0.9426 - val_dig3_acc: 0.9654 - val_dig4_acc: 0.9882 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00006: loss improved from 0.67368 to 0.52089, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 7/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.4229 - num_loss: 0.0384 - dig1_loss: 0.1152 - dig2_loss: 0.1448 - dig3_loss: 0.0888 - dig4_loss: 0.0353 - nC_loss: 2.8694e-04 - num_acc: 0.9874 - dig1_acc: 0.9645 - dig2_acc: 0.9555 - dig3_acc: 0.9722 - dig4_acc: 0.9885 - nC_acc: 1.0000 - val_loss: 0.5143 - val_num_loss: 0.0477 - val_dig1_loss: 0.1330 - val_dig2_loss: 0.1812 - val_dig3_loss: 0.1138 - val_dig4_loss: 0.0385 - val_nC_loss: 2.8200e-05 - val_num_acc: 0.9846 - val_dig1_acc: 0.9610 - val_dig2_acc: 0.9450 - val_dig3_acc: 0.9671 - val_dig4_acc: 0.9884 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00007: loss improved from 0.52089 to 0.42292, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 8/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 0.3563 - num_loss: 0.0306 - dig1_loss: 0.0990 - dig2_loss: 0.1201 - dig3_loss: 0.0751 - dig4_loss: 0.0315 - nC_loss: 2.7767e-05 - num_acc: 0.9901 - dig1_acc: 0.9694 - dig2_acc: 0.9628 - dig3_acc: 0.9765 - dig4_acc: 0.9893 - nC_acc: 1.0000 - val_loss: 0.4955 - val_num_loss: 0.0477 - val_dig1_loss: 0.1335 - val_dig2_loss: 0.1695 - val_dig3_loss: 0.1082 - val_dig4_loss: 0.0366 - val_nC_loss: 4.2903e-05 - val_num_acc: 0.9847 - val_dig1_acc: 0.9613 - val_dig2_acc: 0.9494 - val_dig3_acc: 0.9689 - val_dig4_acc: 0.9888 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00008: loss improved from 0.42292 to 0.35628, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 9/50\n",
      "69076/69076 [==============================] - 83s 1ms/step - loss: 0.3417 - num_loss: 0.0308 - dig1_loss: 0.0950 - dig2_loss: 0.1137 - dig3_loss: 0.0726 - dig4_loss: 0.0292 - nC_loss: 4.0978e-04 - num_acc: 0.9898 - dig1_acc: 0.9707 - dig2_acc: 0.9642 - dig3_acc: 0.9772 - dig4_acc: 0.9899 - nC_acc: 0.9999 - val_loss: 0.7332 - val_num_loss: 0.0934 - val_dig1_loss: 0.1647 - val_dig2_loss: 0.2623 - val_dig3_loss: 0.1535 - val_dig4_loss: 0.0592 - val_nC_loss: 6.4378e-05 - val_num_acc: 0.9711 - val_dig1_acc: 0.9519 - val_dig2_acc: 0.9207 - val_dig3_acc: 0.9576 - val_dig4_acc: 0.9874 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00009: loss improved from 0.35628 to 0.34167, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 10/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 0.3355 - num_loss: 0.0313 - dig1_loss: 0.0925 - dig2_loss: 0.1112 - dig3_loss: 0.0702 - dig4_loss: 0.0303 - nC_loss: 8.9924e-05 - num_acc: 0.9895 - dig1_acc: 0.9712 - dig2_acc: 0.9657 - dig3_acc: 0.9775 - dig4_acc: 0.9898 - nC_acc: 1.0000 - val_loss: 0.4903 - val_num_loss: 0.0476 - val_dig1_loss: 0.1232 - val_dig2_loss: 0.1754 - val_dig3_loss: 0.1061 - val_dig4_loss: 0.0379 - val_nC_loss: 2.4043e-05 - val_num_acc: 0.9856 - val_dig1_acc: 0.9650 - val_dig2_acc: 0.9505 - val_dig3_acc: 0.9721 - val_dig4_acc: 0.9887 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00010: loss improved from 0.34167 to 0.33555, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 11/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 0.3052 - num_loss: 0.0274 - dig1_loss: 0.0878 - dig2_loss: 0.1004 - dig3_loss: 0.0639 - dig4_loss: 0.0257 - nC_loss: 2.2678e-05 - num_acc: 0.9908 - dig1_acc: 0.9731 - dig2_acc: 0.9689 - dig3_acc: 0.9793 - dig4_acc: 0.9916 - nC_acc: 1.0000 - val_loss: 0.4769 - val_num_loss: 0.0475 - val_dig1_loss: 0.1266 - val_dig2_loss: 0.1665 - val_dig3_loss: 0.0991 - val_dig4_loss: 0.0372 - val_nC_loss: 2.3991e-05 - val_num_acc: 0.9860 - val_dig1_acc: 0.9665 - val_dig2_acc: 0.9548 - val_dig3_acc: 0.9724 - val_dig4_acc: 0.9885 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00011: loss improved from 0.33555 to 0.30518, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2303 - num_loss: 0.0194 - dig1_loss: 0.0656 - dig2_loss: 0.0779 - dig3_loss: 0.0471 - dig4_loss: 0.0204 - nC_loss: 1.5151e-05 - num_acc: 0.9933 - dig1_acc: 0.9796 - dig2_acc: 0.9761 - dig3_acc: 0.9847 - dig4_acc: 0.9928 - nC_acc: 1.0000 - val_loss: 0.4850 - val_num_loss: 0.0547 - val_dig1_loss: 0.1238 - val_dig2_loss: 0.1733 - val_dig3_loss: 0.0995 - val_dig4_loss: 0.0333 - val_nC_loss: 5.2572e-04 - val_num_acc: 0.9848 - val_dig1_acc: 0.9654 - val_dig2_acc: 0.9530 - val_dig3_acc: 0.9740 - val_dig4_acc: 0.9910 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00012: loss improved from 0.30518 to 0.23032, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 13/50\n",
      "69076/69076 [==============================] - 86s 1ms/step - loss: 0.2095 - num_loss: 0.0179 - dig1_loss: 0.0597 - dig2_loss: 0.0726 - dig3_loss: 0.0414 - dig4_loss: 0.0179 - nC_loss: 1.5698e-05 - num_acc: 0.9941 - dig1_acc: 0.9812 - dig2_acc: 0.9765 - dig3_acc: 0.9860 - dig4_acc: 0.9940 - nC_acc: 1.0000 - val_loss: 0.4894 - val_num_loss: 0.0544 - val_dig1_loss: 0.1272 - val_dig2_loss: 0.1705 - val_dig3_loss: 0.1021 - val_dig4_loss: 0.0351 - val_nC_loss: 2.1366e-05 - val_num_acc: 0.9854 - val_dig1_acc: 0.9679 - val_dig2_acc: 0.9557 - val_dig3_acc: 0.9741 - val_dig4_acc: 0.9911 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00013: loss improved from 0.23032 to 0.20948, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 14/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1811 - num_loss: 0.0144 - dig1_loss: 0.0533 - dig2_loss: 0.0609 - dig3_loss: 0.0369 - dig4_loss: 0.0155 - nC_loss: 1.3507e-05 - num_acc: 0.9946 - dig1_acc: 0.9830 - dig2_acc: 0.9806 - dig3_acc: 0.9878 - dig4_acc: 0.9946 - nC_acc: 1.0000 - val_loss: 0.5050 - val_num_loss: 0.0558 - val_dig1_loss: 0.1386 - val_dig2_loss: 0.1766 - val_dig3_loss: 0.1023 - val_dig4_loss: 0.0316 - val_nC_loss: 1.6728e-05 - val_num_acc: 0.9840 - val_dig1_acc: 0.9626 - val_dig2_acc: 0.9528 - val_dig3_acc: 0.9735 - val_dig4_acc: 0.9912 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00014: loss improved from 0.20948 to 0.18105, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 15/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1744 - num_loss: 0.0136 - dig1_loss: 0.0502 - dig2_loss: 0.0599 - dig3_loss: 0.0366 - dig4_loss: 0.0140 - nC_loss: 1.2758e-05 - num_acc: 0.9952 - dig1_acc: 0.9840 - dig2_acc: 0.9800 - dig3_acc: 0.9883 - dig4_acc: 0.9951 - nC_acc: 1.0000 - val_loss: 0.5144 - val_num_loss: 0.0574 - val_dig1_loss: 0.1394 - val_dig2_loss: 0.1736 - val_dig3_loss: 0.1119 - val_dig4_loss: 0.0320 - val_nC_loss: 1.5667e-05 - val_num_acc: 0.9848 - val_dig1_acc: 0.9655 - val_dig2_acc: 0.9563 - val_dig3_acc: 0.9739 - val_dig4_acc: 0.9917 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00015: loss improved from 0.18105 to 0.17437, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 16/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1724 - num_loss: 0.0139 - dig1_loss: 0.0508 - dig2_loss: 0.0582 - dig3_loss: 0.0347 - dig4_loss: 0.0147 - nC_loss: 1.6074e-05 - num_acc: 0.9954 - dig1_acc: 0.9842 - dig2_acc: 0.9813 - dig3_acc: 0.9888 - dig4_acc: 0.9953 - nC_acc: 1.0000 - val_loss: 0.5130 - val_num_loss: 0.0572 - val_dig1_loss: 0.1363 - val_dig2_loss: 0.1770 - val_dig3_loss: 0.1118 - val_dig4_loss: 0.0307 - val_nC_loss: 1.8093e-05 - val_num_acc: 0.9870 - val_dig1_acc: 0.9667 - val_dig2_acc: 0.9579 - val_dig3_acc: 0.9759 - val_dig4_acc: 0.9920 - val_nC_acc: 1.0000\n",
      "\n",
      "Epoch 00016: loss improved from 0.17437 to 0.17241, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 17/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 0.1508 - num_loss: 0.0123 - dig1_loss: 0.0456 - dig2_loss: 0.0530 - dig3_loss: 0.0283 - dig4_loss: 0.0115 - nC_loss: 4.1421e-05 - num_acc: 0.9957 - dig1_acc: 0.9857 - dig2_acc: 0.9832 - dig3_acc: 0.9905 - dig4_acc: 0.9960 - nC_acc: 1.0000 - val_loss: 0.5628 - val_num_loss: 0.0665 - val_dig1_loss: 0.1459 - val_dig2_loss: 0.1980 - val_dig3_loss: 0.1160 - val_dig4_loss: 0.0345 - val_nC_loss: 0.0019 - val_num_acc: 0.9841 - val_dig1_acc: 0.9654 - val_dig2_acc: 0.9520 - val_dig3_acc: 0.9746 - val_dig4_acc: 0.9918 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00017: loss improved from 0.17241 to 0.15077, saving model to saved_models/VGGPreTrained.classifier.hdf5\n",
      "Epoch 18/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1574 - num_loss: 0.0140 - dig1_loss: 0.0496 - dig2_loss: 0.0526 - dig3_loss: 0.0297 - dig4_loss: 0.0113 - nC_loss: 2.5176e-04 - num_acc: 0.9955 - dig1_acc: 0.9845 - dig2_acc: 0.9829 - dig3_acc: 0.9904 - dig4_acc: 0.9962 - nC_acc: 1.0000 - val_loss: 0.5394 - val_num_loss: 0.0576 - val_dig1_loss: 0.1413 - val_dig2_loss: 0.1964 - val_dig3_loss: 0.1114 - val_dig4_loss: 0.0318 - val_nC_loss: 9.4967e-04 - val_num_acc: 0.9843 - val_dig1_acc: 0.9664 - val_dig2_acc: 0.9542 - val_dig3_acc: 0.9743 - val_dig4_acc: 0.9917 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.15077\n",
      "Epoch 19/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.4855 - num_loss: 0.0540 - dig1_loss: 0.1398 - dig2_loss: 0.1635 - dig3_loss: 0.0940 - dig4_loss: 0.0308 - nC_loss: 0.0033 - num_acc: 0.9823 - dig1_acc: 0.9571 - dig2_acc: 0.9498 - dig3_acc: 0.9720 - dig4_acc: 0.9916 - nC_acc: 0.9996 - val_loss: 0.5510 - val_num_loss: 0.0532 - val_dig1_loss: 0.1490 - val_dig2_loss: 0.1989 - val_dig3_loss: 0.1114 - val_dig4_loss: 0.0366 - val_nC_loss: 0.0019 - val_num_acc: 0.9836 - val_dig1_acc: 0.9593 - val_dig2_acc: 0.9477 - val_dig3_acc: 0.9718 - val_dig4_acc: 0.9906 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.15077\n",
      "Epoch 20/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 1.0256 - num_loss: 0.1848 - dig1_loss: 0.2649 - dig2_loss: 0.3136 - dig3_loss: 0.1205 - dig4_loss: 0.0342 - nC_loss: 0.1076 - num_acc: 0.9670 - dig1_acc: 0.9382 - dig2_acc: 0.9253 - dig3_acc: 0.9646 - dig4_acc: 0.9910 - nC_acc: 0.9931 - val_loss: 0.5819 - val_num_loss: 0.0586 - val_dig1_loss: 0.1518 - val_dig2_loss: 0.2186 - val_dig3_loss: 0.1194 - val_dig4_loss: 0.0301 - val_nC_loss: 0.0033 - val_num_acc: 0.9813 - val_dig1_acc: 0.9567 - val_dig2_acc: 0.9366 - val_dig3_acc: 0.9676 - val_dig4_acc: 0.9909 - val_nC_acc: 0.9993\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.15077\n",
      "Epoch 21/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.3919 - num_loss: 0.0434 - dig1_loss: 0.1146 - dig2_loss: 0.1296 - dig3_loss: 0.0726 - dig4_loss: 0.0218 - nC_loss: 0.0099 - num_acc: 0.9877 - dig1_acc: 0.9664 - dig2_acc: 0.9606 - dig3_acc: 0.9777 - dig4_acc: 0.9931 - nC_acc: 0.9993 - val_loss: 0.4936 - val_num_loss: 0.0540 - val_dig1_loss: 0.1245 - val_dig2_loss: 0.1756 - val_dig3_loss: 0.1099 - val_dig4_loss: 0.0293 - val_nC_loss: 3.0215e-04 - val_num_acc: 0.9836 - val_dig1_acc: 0.9662 - val_dig2_acc: 0.9534 - val_dig3_acc: 0.9717 - val_dig4_acc: 0.9920 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.15077\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 22/50\n",
      "69076/69076 [==============================] - 86s 1ms/step - loss: 0.1601 - num_loss: 0.0137 - dig1_loss: 0.0506 - dig2_loss: 0.0554 - dig3_loss: 0.0312 - dig4_loss: 0.0091 - nC_loss: 5.6503e-05 - num_acc: 0.9953 - dig1_acc: 0.9836 - dig2_acc: 0.9825 - dig3_acc: 0.9898 - dig4_acc: 0.9972 - nC_acc: 1.0000 - val_loss: 0.4834 - val_num_loss: 0.0533 - val_dig1_loss: 0.1224 - val_dig2_loss: 0.1720 - val_dig3_loss: 0.1084 - val_dig4_loss: 0.0263 - val_nC_loss: 9.5645e-04 - val_num_acc: 0.9854 - val_dig1_acc: 0.9678 - val_dig2_acc: 0.9556 - val_dig3_acc: 0.9740 - val_dig4_acc: 0.9928 - val_nC_acc: 0.9999\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.15077\n",
      "Epoch 00022: early stopping\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "CPU times: user 28min 25s, sys: 7min 13s, total: 35min 38s\n",
      "Wall time: 31min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vggHistory = vggPreTrain.fit(x = X_train,\n",
    "                             y = list(y_train.T),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             shuffle = True,\n",
    "                             validation_data = (X_val, list(y_val.T)),\n",
    "                             callbacks= callback)\n",
    "\n",
    "print(vggHistory.history.keys())\n",
    "modName = 'vgg16_PreTrain'\n",
    "# list all data in history\n",
    "print(vggHistory.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg_pretrain_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.model_evaluation_utils import evaluate_model_performance\n",
    "\n",
    "evaluate_model_performance(fitted_model=vggHistory, \n",
    "                           model_name = 'pretrain_vgg16',\n",
    "                           data=data,\n",
    "                           model=vggPreTrain\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_models/vggPreTrain.pkl', 'wb') as f:\n",
    "    pickle.dump(vggPreTrain, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_models/vggHistory.pkl', 'wb') as f:\n",
    "    pickle.dump(vggHistory, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
