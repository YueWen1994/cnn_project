{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        img2 = img\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get three channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.preprocess_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (86345, 64, 64, 3)\n",
      "labels: (86345, 6)\n",
      "dataset: (13066, 64, 64, 3)\n",
      "labels: (13066, 6)\n"
     ]
    }
   ],
   "source": [
    "shape = (64, 64)\n",
    "channel = 3\n",
    "data = generate_data_set_for_training(shape, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try pretrianed Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "import keras.utils as ku\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vgg16_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scratch\n",
    "run_pretrained_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chanel 3\n",
      "row 64\n",
      "col 64\n"
     ]
    }
   ],
   "source": [
    "_, row, col, channel = X_train.shape\n",
    "print('chanel', channel)\n",
    "print('row', row)\n",
    "print('col', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "digLen = 5\n",
    "numDigits = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "preTrainModel = VGG16(include_top = False, weights = 'imagenet')\n",
    "preTrainModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptInput = keras.Input(shape = (row,col,channel), name  = 'inputVGGPreTrain')\n",
    "pt_vgg16 = preTrainModel(ptInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mout = Flatten(name = 'flatten')(pt_vgg16)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_4096')(Mout)\n",
    "Mout = Dense(1024, activation='relu', name = 'FC1_512')(Mout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numd_SM = Dense(digLen,    activation='softmax',name = 'num')(Mout)\n",
    "dig1_SM = Dense(numDigits, activation='softmax',name = 'dig1')(Mout)\n",
    "dig2_SM = Dense(numDigits, activation='softmax',name = 'dig2')(Mout)\n",
    "dig3_SM = Dense(numDigits, activation='softmax',name = 'dig3')(Mout)\n",
    "dig4_SM = Dense(numDigits, activation='softmax',name = 'dig4')(Mout)\n",
    "numB_SM = Dense(2, activation='softmax',name = 'nC')(Mout)\n",
    "out = [numd_SM, dig1_SM ,dig2_SM, dig3_SM, dig4_SM,numB_SM] #numd_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    lr = 0.001\n",
    "    beta_1 = 0.9\n",
    "    beta_2 = 0.999\n",
    "    epsilon = None\n",
    "    decay = 0.0\n",
    "    amsgrad = True\n",
    "    # defind optimizer\n",
    "\n",
    "\n",
    "\n",
    "    optim = optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay, amsgrad=amsgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputVGGPreTrain (InputLayer)   (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   multiple             14714688    inputVGGPreTrain[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "FC1_4096 (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FC1_512 (Dense)                 (None, 1024)         1049600     FC1_4096[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "num (Dense)                     (None, 5)            5125        FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig1 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig2 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig3 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dig4 (Dense)                    (None, 11)           11275       FC1_512[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "nC (Dense)                      (None, 2)            2050        FC1_512[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,914,739\n",
      "Trainable params: 17,914,739\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggPreTrain = keras.Model(inputs = ptInput, outputs = out)\n",
    "\n",
    "vggPreTrain.compile(loss = 'sparse_categorical_crossentropy', #ceLoss ,\n",
    "                    optimizer= optim,\n",
    "                    metrics=  ['accuracy']) #[])\n",
    "vggPreTrain.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = []\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='saved_models/VGGPreTrained_classifier_corrected.hdf5',\n",
    "                                               monitor='loss',\n",
    "                                               save_best_only=True,\n",
    "                                               verbose=2)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
    "                                              factor = 0.1,\n",
    "                                              verbose = 1,\n",
    "                                              patience= 4,\n",
    "                                              cooldown= 1,\n",
    "                                              min_lr = 0.0001)\n",
    "es = keras.callbacks.EarlyStopping(monitor= 'loss',\n",
    "                                   min_delta=0.000001,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   mode='auto')\n",
    "callback.append(es)\n",
    "callback.append(checkpointer)\n",
    "callback.append(reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69076 samples, validate on 17269 samples\n",
      "Epoch 1/50\n",
      "69076/69076 [==============================] - 91s 1ms/step - loss: 3.0098 - num_loss: 0.5095 - dig1_loss: 0.9262 - dig2_loss: 0.8843 - dig3_loss: 0.4488 - dig4_loss: 0.0972 - nC_loss: 0.1438 - num_acc: 0.8064 - dig1_acc: 0.6899 - dig2_acc: 0.7077 - dig3_acc: 0.8972 - dig4_acc: 0.9849 - nC_acc: 0.9468 - val_loss: 2.9973 - val_num_loss: 0.5401 - val_dig1_loss: 0.8658 - val_dig2_loss: 0.8990 - val_dig3_loss: 0.5226 - val_dig4_loss: 0.0920 - val_nC_loss: 0.0778 - val_num_acc: 0.7702 - val_dig1_acc: 0.7039 - val_dig2_acc: 0.6800 - val_dig3_acc: 0.8925 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9721\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.00977, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 2/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 2.3109 - num_loss: 0.2295 - dig1_loss: 0.8145 - dig2_loss: 0.7972 - dig3_loss: 0.3447 - dig4_loss: 0.0724 - nC_loss: 0.0526 - num_acc: 0.9150 - dig1_acc: 0.7117 - dig2_acc: 0.7119 - dig3_acc: 0.8969 - dig4_acc: 0.9858 - nC_acc: 0.9824 - val_loss: 2.2075 - val_num_loss: 0.1764 - val_dig1_loss: 0.8004 - val_dig2_loss: 0.7812 - val_dig3_loss: 0.3254 - val_dig4_loss: 0.0633 - val_nC_loss: 0.0608 - val_num_acc: 0.9401 - val_dig1_acc: 0.7187 - val_dig2_acc: 0.7209 - val_dig3_acc: 0.8954 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9776\n",
      "\n",
      "Epoch 00002: loss improved from 3.00977 to 2.31088, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 3/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 1.9594 - num_loss: 0.1578 - dig1_loss: 0.6927 - dig2_loss: 0.7045 - dig3_loss: 0.3036 - dig4_loss: 0.0620 - nC_loss: 0.0390 - num_acc: 0.9468 - dig1_acc: 0.7570 - dig2_acc: 0.7441 - dig3_acc: 0.9006 - dig4_acc: 0.9857 - nC_acc: 0.9873 - val_loss: 1.6894 - val_num_loss: 0.1463 - val_dig1_loss: 0.5426 - val_dig2_loss: 0.6333 - val_dig3_loss: 0.2792 - val_dig4_loss: 0.0586 - val_nC_loss: 0.0294 - val_num_acc: 0.9508 - val_dig1_acc: 0.8036 - val_dig2_acc: 0.7651 - val_dig3_acc: 0.9057 - val_dig4_acc: 0.9858 - val_nC_acc: 0.9906\n",
      "\n",
      "Epoch 00003: loss improved from 2.31088 to 1.95944, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 4/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 1.4741 - num_loss: 0.1214 - dig1_loss: 0.4536 - dig2_loss: 0.5551 - dig3_loss: 0.2571 - dig4_loss: 0.0549 - nC_loss: 0.0320 - num_acc: 0.9599 - dig1_acc: 0.8429 - dig2_acc: 0.8043 - dig3_acc: 0.9133 - dig4_acc: 0.9856 - nC_acc: 0.9894 - val_loss: 1.3285 - val_num_loss: 0.1135 - val_dig1_loss: 0.3740 - val_dig2_loss: 0.5157 - val_dig3_loss: 0.2430 - val_dig4_loss: 0.0514 - val_nC_loss: 0.0309 - val_num_acc: 0.9648 - val_dig1_acc: 0.8751 - val_dig2_acc: 0.8244 - val_dig3_acc: 0.9190 - val_dig4_acc: 0.9861 - val_nC_acc: 0.9905\n",
      "\n",
      "Epoch 00004: loss improved from 1.95944 to 1.47414, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 5/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 1.1858 - num_loss: 0.1045 - dig1_loss: 0.3329 - dig2_loss: 0.4546 - dig3_loss: 0.2144 - dig4_loss: 0.0491 - nC_loss: 0.0304 - num_acc: 0.9673 - dig1_acc: 0.8937 - dig2_acc: 0.8445 - dig3_acc: 0.9286 - dig4_acc: 0.9863 - nC_acc: 0.9909 - val_loss: 1.0600 - val_num_loss: 0.0922 - val_dig1_loss: 0.2796 - val_dig2_loss: 0.4145 - val_dig3_loss: 0.1982 - val_dig4_loss: 0.0458 - val_nC_loss: 0.0296 - val_num_acc: 0.9725 - val_dig1_acc: 0.9176 - val_dig2_acc: 0.8628 - val_dig3_acc: 0.9397 - val_dig4_acc: 0.9869 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00005: loss improved from 1.47414 to 1.18584, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 6/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.9353 - num_loss: 0.0854 - dig1_loss: 0.2506 - dig2_loss: 0.3565 - dig3_loss: 0.1747 - dig4_loss: 0.0439 - nC_loss: 0.0242 - num_acc: 0.9733 - dig1_acc: 0.9243 - dig2_acc: 0.8779 - dig3_acc: 0.9426 - dig4_acc: 0.9869 - nC_acc: 0.9926 - val_loss: 0.9398 - val_num_loss: 0.0890 - val_dig1_loss: 0.2432 - val_dig2_loss: 0.3596 - val_dig3_loss: 0.1773 - val_dig4_loss: 0.0426 - val_nC_loss: 0.0281 - val_num_acc: 0.9728 - val_dig1_acc: 0.9289 - val_dig2_acc: 0.8772 - val_dig3_acc: 0.9429 - val_dig4_acc: 0.9864 - val_nC_acc: 0.9921\n",
      "\n",
      "Epoch 00006: loss improved from 1.18584 to 0.93526, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 7/50\n",
      "69076/69076 [==============================] - 86s 1ms/step - loss: 0.7904 - num_loss: 0.0744 - dig1_loss: 0.2089 - dig2_loss: 0.2965 - dig3_loss: 0.1490 - dig4_loss: 0.0409 - nC_loss: 0.0207 - num_acc: 0.9770 - dig1_acc: 0.9374 - dig2_acc: 0.8985 - dig3_acc: 0.9515 - dig4_acc: 0.9872 - nC_acc: 0.9939 - val_loss: 0.9950 - val_num_loss: 0.0957 - val_dig1_loss: 0.2708 - val_dig2_loss: 0.3644 - val_dig3_loss: 0.1860 - val_dig4_loss: 0.0452 - val_nC_loss: 0.0330 - val_num_acc: 0.9702 - val_dig1_acc: 0.9197 - val_dig2_acc: 0.8787 - val_dig3_acc: 0.9402 - val_dig4_acc: 0.9865 - val_nC_acc: 0.9899\n",
      "\n",
      "Epoch 00007: loss improved from 0.93526 to 0.79036, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 8/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.7212 - num_loss: 0.0690 - dig1_loss: 0.1891 - dig2_loss: 0.2688 - dig3_loss: 0.1365 - dig4_loss: 0.0384 - nC_loss: 0.0194 - num_acc: 0.9785 - dig1_acc: 0.9447 - dig2_acc: 0.9088 - dig3_acc: 0.9568 - dig4_acc: 0.9880 - nC_acc: 0.9941 - val_loss: 0.7578 - val_num_loss: 0.0867 - val_dig1_loss: 0.1945 - val_dig2_loss: 0.2679 - val_dig3_loss: 0.1439 - val_dig4_loss: 0.0433 - val_nC_loss: 0.0216 - val_num_acc: 0.9732 - val_dig1_acc: 0.9443 - val_dig2_acc: 0.9125 - val_dig3_acc: 0.9591 - val_dig4_acc: 0.9885 - val_nC_acc: 0.9932\n",
      "\n",
      "Epoch 00008: loss improved from 0.79036 to 0.72118, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 9/50\n",
      "69076/69076 [==============================] - 84s 1ms/step - loss: 0.6304 - num_loss: 0.0634 - dig1_loss: 0.1651 - dig2_loss: 0.2278 - dig3_loss: 0.1200 - dig4_loss: 0.0352 - nC_loss: 0.0188 - num_acc: 0.9807 - dig1_acc: 0.9523 - dig2_acc: 0.9243 - dig3_acc: 0.9618 - dig4_acc: 0.9888 - nC_acc: 0.9943 - val_loss: 0.7257 - val_num_loss: 0.0766 - val_dig1_loss: 0.1823 - val_dig2_loss: 0.2603 - val_dig3_loss: 0.1443 - val_dig4_loss: 0.0389 - val_nC_loss: 0.0233 - val_num_acc: 0.9772 - val_dig1_acc: 0.9485 - val_dig2_acc: 0.9181 - val_dig3_acc: 0.9567 - val_dig4_acc: 0.9896 - val_nC_acc: 0.9930\n",
      "\n",
      "Epoch 00009: loss improved from 0.72118 to 0.63036, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 10/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.5552 - num_loss: 0.0542 - dig1_loss: 0.1478 - dig2_loss: 0.1975 - dig3_loss: 0.1074 - dig4_loss: 0.0331 - nC_loss: 0.0153 - num_acc: 0.9837 - dig1_acc: 0.9570 - dig2_acc: 0.9359 - dig3_acc: 0.9666 - dig4_acc: 0.9896 - nC_acc: 0.9956 - val_loss: 0.6331 - val_num_loss: 0.0707 - val_dig1_loss: 0.1652 - val_dig2_loss: 0.2161 - val_dig3_loss: 0.1225 - val_dig4_loss: 0.0359 - val_nC_loss: 0.0227 - val_num_acc: 0.9793 - val_dig1_acc: 0.9549 - val_dig2_acc: 0.9360 - val_dig3_acc: 0.9653 - val_dig4_acc: 0.9892 - val_nC_acc: 0.9933\n",
      "\n",
      "Epoch 00010: loss improved from 0.63036 to 0.55521, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 11/50\n",
      "69076/69076 [==============================] - 86s 1ms/step - loss: 0.4842 - num_loss: 0.0460 - dig1_loss: 0.1298 - dig2_loss: 0.1710 - dig3_loss: 0.0957 - dig4_loss: 0.0297 - nC_loss: 0.0120 - num_acc: 0.9856 - dig1_acc: 0.9623 - dig2_acc: 0.9464 - dig3_acc: 0.9700 - dig4_acc: 0.9907 - nC_acc: 0.9961 - val_loss: 0.6556 - val_num_loss: 0.0814 - val_dig1_loss: 0.1736 - val_dig2_loss: 0.2200 - val_dig3_loss: 0.1188 - val_dig4_loss: 0.0321 - val_nC_loss: 0.0297 - val_num_acc: 0.9746 - val_dig1_acc: 0.9512 - val_dig2_acc: 0.9346 - val_dig3_acc: 0.9650 - val_dig4_acc: 0.9903 - val_nC_acc: 0.9903\n",
      "\n",
      "Epoch 00011: loss improved from 0.55521 to 0.48424, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.4782 - num_loss: 0.0495 - dig1_loss: 0.1287 - dig2_loss: 0.1633 - dig3_loss: 0.0952 - dig4_loss: 0.0277 - nC_loss: 0.0138 - num_acc: 0.9851 - dig1_acc: 0.9626 - dig2_acc: 0.9499 - dig3_acc: 0.9713 - dig4_acc: 0.9913 - nC_acc: 0.9957 - val_loss: 0.9018 - val_num_loss: 0.1331 - val_dig1_loss: 0.2461 - val_dig2_loss: 0.2967 - val_dig3_loss: 0.1546 - val_dig4_loss: 0.0380 - val_nC_loss: 0.0332 - val_num_acc: 0.9609 - val_dig1_acc: 0.9301 - val_dig2_acc: 0.9127 - val_dig3_acc: 0.9545 - val_dig4_acc: 0.9903 - val_nC_acc: 0.9907\n",
      "\n",
      "Epoch 00012: loss improved from 0.48424 to 0.47821, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 13/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.4947 - num_loss: 0.0532 - dig1_loss: 0.1371 - dig2_loss: 0.1644 - dig3_loss: 0.0976 - dig4_loss: 0.0277 - nC_loss: 0.0147 - num_acc: 0.9837 - dig1_acc: 0.9599 - dig2_acc: 0.9495 - dig3_acc: 0.9702 - dig4_acc: 0.9915 - nC_acc: 0.9954 - val_loss: 0.6166 - val_num_loss: 0.0729 - val_dig1_loss: 0.1690 - val_dig2_loss: 0.2065 - val_dig3_loss: 0.1131 - val_dig4_loss: 0.0293 - val_nC_loss: 0.0259 - val_num_acc: 0.9776 - val_dig1_acc: 0.9530 - val_dig2_acc: 0.9375 - val_dig3_acc: 0.9679 - val_dig4_acc: 0.9911 - val_nC_acc: 0.9916\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.47821\n",
      "Epoch 14/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.3969 - num_loss: 0.0396 - dig1_loss: 0.1097 - dig2_loss: 0.1330 - dig3_loss: 0.0827 - dig4_loss: 0.0225 - nC_loss: 0.0095 - num_acc: 0.9876 - dig1_acc: 0.9683 - dig2_acc: 0.9592 - dig3_acc: 0.9742 - dig4_acc: 0.9928 - nC_acc: 0.9971 - val_loss: 0.5558 - val_num_loss: 0.0664 - val_dig1_loss: 0.1488 - val_dig2_loss: 0.1848 - val_dig3_loss: 0.1057 - val_dig4_loss: 0.0280 - val_nC_loss: 0.0220 - val_num_acc: 0.9794 - val_dig1_acc: 0.9592 - val_dig2_acc: 0.9470 - val_dig3_acc: 0.9694 - val_dig4_acc: 0.9925 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00014: loss improved from 0.47821 to 0.39689, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 15/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.3210 - num_loss: 0.0301 - dig1_loss: 0.0886 - dig2_loss: 0.1066 - dig3_loss: 0.0709 - dig4_loss: 0.0185 - nC_loss: 0.0064 - num_acc: 0.9907 - dig1_acc: 0.9741 - dig2_acc: 0.9666 - dig3_acc: 0.9780 - dig4_acc: 0.9943 - nC_acc: 0.9982 - val_loss: 0.5384 - val_num_loss: 0.0694 - val_dig1_loss: 0.1454 - val_dig2_loss: 0.1690 - val_dig3_loss: 0.1063 - val_dig4_loss: 0.0231 - val_nC_loss: 0.0251 - val_num_acc: 0.9807 - val_dig1_acc: 0.9615 - val_dig2_acc: 0.9556 - val_dig3_acc: 0.9717 - val_dig4_acc: 0.9945 - val_nC_acc: 0.9935\n",
      "\n",
      "Epoch 00015: loss improved from 0.39689 to 0.32105, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 16/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2977 - num_loss: 0.0281 - dig1_loss: 0.0826 - dig2_loss: 0.0981 - dig3_loss: 0.0669 - dig4_loss: 0.0164 - nC_loss: 0.0056 - num_acc: 0.9913 - dig1_acc: 0.9757 - dig2_acc: 0.9699 - dig3_acc: 0.9786 - dig4_acc: 0.9947 - nC_acc: 0.9982 - val_loss: 0.5679 - val_num_loss: 0.0752 - val_dig1_loss: 0.1528 - val_dig2_loss: 0.1814 - val_dig3_loss: 0.1074 - val_dig4_loss: 0.0227 - val_nC_loss: 0.0284 - val_num_acc: 0.9794 - val_dig1_acc: 0.9610 - val_dig2_acc: 0.9519 - val_dig3_acc: 0.9701 - val_dig4_acc: 0.9936 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00016: loss improved from 0.32105 to 0.29767, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 17/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.4587 - num_loss: 0.0551 - dig1_loss: 0.1361 - dig2_loss: 0.1437 - dig3_loss: 0.0833 - dig4_loss: 0.0224 - nC_loss: 0.0181 - num_acc: 0.9825 - dig1_acc: 0.9615 - dig2_acc: 0.9567 - dig3_acc: 0.9746 - dig4_acc: 0.9935 - nC_acc: 0.9941 - val_loss: 0.6066 - val_num_loss: 0.0775 - val_dig1_loss: 0.1558 - val_dig2_loss: 0.2070 - val_dig3_loss: 0.1155 - val_dig4_loss: 0.0258 - val_nC_loss: 0.0248 - val_num_acc: 0.9780 - val_dig1_acc: 0.9569 - val_dig2_acc: 0.9440 - val_dig3_acc: 0.9692 - val_dig4_acc: 0.9935 - val_nC_acc: 0.9929\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.29767\n",
      "Epoch 18/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.3296 - num_loss: 0.0334 - dig1_loss: 0.0957 - dig2_loss: 0.1071 - dig3_loss: 0.0681 - dig4_loss: 0.0168 - nC_loss: 0.0084 - num_acc: 0.9893 - dig1_acc: 0.9716 - dig2_acc: 0.9673 - dig3_acc: 0.9794 - dig4_acc: 0.9949 - nC_acc: 0.9973 - val_loss: 0.5556 - val_num_loss: 0.0694 - val_dig1_loss: 0.1579 - val_dig2_loss: 0.1771 - val_dig3_loss: 0.1002 - val_dig4_loss: 0.0245 - val_nC_loss: 0.0264 - val_num_acc: 0.9809 - val_dig1_acc: 0.9578 - val_dig2_acc: 0.9529 - val_dig3_acc: 0.9720 - val_dig4_acc: 0.9931 - val_nC_acc: 0.9939\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.29767\n",
      "Epoch 19/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2550 - num_loss: 0.0236 - dig1_loss: 0.0743 - dig2_loss: 0.0825 - dig3_loss: 0.0561 - dig4_loss: 0.0133 - nC_loss: 0.0053 - num_acc: 0.9926 - dig1_acc: 0.9787 - dig2_acc: 0.9751 - dig3_acc: 0.9824 - dig4_acc: 0.9957 - nC_acc: 0.9986 - val_loss: 0.5219 - val_num_loss: 0.0706 - val_dig1_loss: 0.1440 - val_dig2_loss: 0.1656 - val_dig3_loss: 0.0969 - val_dig4_loss: 0.0212 - val_nC_loss: 0.0237 - val_num_acc: 0.9808 - val_dig1_acc: 0.9625 - val_dig2_acc: 0.9559 - val_dig3_acc: 0.9728 - val_dig4_acc: 0.9943 - val_nC_acc: 0.9944\n",
      "\n",
      "Epoch 00019: loss improved from 0.29767 to 0.25499, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 20/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2259 - num_loss: 0.0205 - dig1_loss: 0.0644 - dig2_loss: 0.0750 - dig3_loss: 0.0502 - dig4_loss: 0.0121 - nC_loss: 0.0037 - num_acc: 0.9934 - dig1_acc: 0.9807 - dig2_acc: 0.9770 - dig3_acc: 0.9841 - dig4_acc: 0.9964 - nC_acc: 0.9990 - val_loss: 0.5485 - val_num_loss: 0.0753 - val_dig1_loss: 0.1439 - val_dig2_loss: 0.1723 - val_dig3_loss: 0.1047 - val_dig4_loss: 0.0249 - val_nC_loss: 0.0274 - val_num_acc: 0.9811 - val_dig1_acc: 0.9651 - val_dig2_acc: 0.9567 - val_dig3_acc: 0.9732 - val_dig4_acc: 0.9942 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00020: loss improved from 0.25499 to 0.22586, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 21/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2333 - num_loss: 0.0222 - dig1_loss: 0.0678 - dig2_loss: 0.0761 - dig3_loss: 0.0500 - dig4_loss: 0.0121 - nC_loss: 0.0049 - num_acc: 0.9928 - dig1_acc: 0.9800 - dig2_acc: 0.9766 - dig3_acc: 0.9840 - dig4_acc: 0.9963 - nC_acc: 0.9984 - val_loss: 0.5587 - val_num_loss: 0.0706 - val_dig1_loss: 0.1507 - val_dig2_loss: 0.1778 - val_dig3_loss: 0.1092 - val_dig4_loss: 0.0255 - val_nC_loss: 0.0250 - val_num_acc: 0.9814 - val_dig1_acc: 0.9629 - val_dig2_acc: 0.9558 - val_dig3_acc: 0.9734 - val_dig4_acc: 0.9937 - val_nC_acc: 0.9938\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.22586\n",
      "Epoch 22/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2215 - num_loss: 0.0211 - dig1_loss: 0.0678 - dig2_loss: 0.0708 - dig3_loss: 0.0474 - dig4_loss: 0.0100 - nC_loss: 0.0044 - num_acc: 0.9930 - dig1_acc: 0.9799 - dig2_acc: 0.9779 - dig3_acc: 0.9845 - dig4_acc: 0.9967 - nC_acc: 0.9985 - val_loss: 0.5403 - val_num_loss: 0.0718 - val_dig1_loss: 0.1446 - val_dig2_loss: 0.1736 - val_dig3_loss: 0.1014 - val_dig4_loss: 0.0226 - val_nC_loss: 0.0263 - val_num_acc: 0.9817 - val_dig1_acc: 0.9644 - val_dig2_acc: 0.9565 - val_dig3_acc: 0.9749 - val_dig4_acc: 0.9942 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00022: loss improved from 0.22586 to 0.22150, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 23/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2047 - num_loss: 0.0194 - dig1_loss: 0.0603 - dig2_loss: 0.0669 - dig3_loss: 0.0435 - dig4_loss: 0.0105 - nC_loss: 0.0042 - num_acc: 0.9939 - dig1_acc: 0.9823 - dig2_acc: 0.9798 - dig3_acc: 0.9857 - dig4_acc: 0.9968 - nC_acc: 0.9988 - val_loss: 0.5421 - val_num_loss: 0.0724 - val_dig1_loss: 0.1467 - val_dig2_loss: 0.1718 - val_dig3_loss: 0.1011 - val_dig4_loss: 0.0243 - val_nC_loss: 0.0259 - val_num_acc: 0.9818 - val_dig1_acc: 0.9644 - val_dig2_acc: 0.9577 - val_dig3_acc: 0.9745 - val_dig4_acc: 0.9940 - val_nC_acc: 0.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: loss improved from 0.22150 to 0.20470, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 24/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1762 - num_loss: 0.0157 - dig1_loss: 0.0529 - dig2_loss: 0.0577 - dig3_loss: 0.0379 - dig4_loss: 0.0090 - nC_loss: 0.0031 - num_acc: 0.9950 - dig1_acc: 0.9842 - dig2_acc: 0.9819 - dig3_acc: 0.9873 - dig4_acc: 0.9970 - nC_acc: 0.9989 - val_loss: 0.6103 - val_num_loss: 0.0835 - val_dig1_loss: 0.1681 - val_dig2_loss: 0.1944 - val_dig3_loss: 0.1090 - val_dig4_loss: 0.0256 - val_nC_loss: 0.0298 - val_num_acc: 0.9801 - val_dig1_acc: 0.9625 - val_dig2_acc: 0.9558 - val_dig3_acc: 0.9732 - val_dig4_acc: 0.9929 - val_nC_acc: 0.9939\n",
      "\n",
      "Epoch 00024: loss improved from 0.20470 to 0.17624, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 25/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1694 - num_loss: 0.0138 - dig1_loss: 0.0506 - dig2_loss: 0.0574 - dig3_loss: 0.0367 - dig4_loss: 0.0089 - nC_loss: 0.0020 - num_acc: 0.9953 - dig1_acc: 0.9848 - dig2_acc: 0.9820 - dig3_acc: 0.9874 - dig4_acc: 0.9971 - nC_acc: 0.9993 - val_loss: 0.5784 - val_num_loss: 0.0781 - val_dig1_loss: 0.1587 - val_dig2_loss: 0.1883 - val_dig3_loss: 0.1042 - val_dig4_loss: 0.0225 - val_nC_loss: 0.0266 - val_num_acc: 0.9805 - val_dig1_acc: 0.9616 - val_dig2_acc: 0.9548 - val_dig3_acc: 0.9748 - val_dig4_acc: 0.9950 - val_nC_acc: 0.9939\n",
      "\n",
      "Epoch 00025: loss improved from 0.17624 to 0.16937, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 26/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1592 - num_loss: 0.0145 - dig1_loss: 0.0471 - dig2_loss: 0.0515 - dig3_loss: 0.0361 - dig4_loss: 0.0074 - nC_loss: 0.0028 - num_acc: 0.9953 - dig1_acc: 0.9859 - dig2_acc: 0.9841 - dig3_acc: 0.9886 - dig4_acc: 0.9975 - nC_acc: 0.9992 - val_loss: 0.5918 - val_num_loss: 0.0803 - val_dig1_loss: 0.1628 - val_dig2_loss: 0.1923 - val_dig3_loss: 0.1030 - val_dig4_loss: 0.0244 - val_nC_loss: 0.0290 - val_num_acc: 0.9819 - val_dig1_acc: 0.9639 - val_dig2_acc: 0.9565 - val_dig3_acc: 0.9759 - val_dig4_acc: 0.9950 - val_nC_acc: 0.9940\n",
      "\n",
      "Epoch 00026: loss improved from 0.16937 to 0.15924, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 27/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1803 - num_loss: 0.0177 - dig1_loss: 0.0561 - dig2_loss: 0.0574 - dig3_loss: 0.0360 - dig4_loss: 0.0088 - nC_loss: 0.0044 - num_acc: 0.9943 - dig1_acc: 0.9829 - dig2_acc: 0.9817 - dig3_acc: 0.9879 - dig4_acc: 0.9972 - nC_acc: 0.9988 - val_loss: 0.5789 - val_num_loss: 0.0795 - val_dig1_loss: 0.1611 - val_dig2_loss: 0.1785 - val_dig3_loss: 0.1107 - val_dig4_loss: 0.0211 - val_nC_loss: 0.0279 - val_num_acc: 0.9807 - val_dig1_acc: 0.9628 - val_dig2_acc: 0.9577 - val_dig3_acc: 0.9741 - val_dig4_acc: 0.9947 - val_nC_acc: 0.9937\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.15924\n",
      "Epoch 28/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1591 - num_loss: 0.0138 - dig1_loss: 0.0508 - dig2_loss: 0.0518 - dig3_loss: 0.0322 - dig4_loss: 0.0078 - nC_loss: 0.0028 - num_acc: 0.9952 - dig1_acc: 0.9851 - dig2_acc: 0.9839 - dig3_acc: 0.9890 - dig4_acc: 0.9977 - nC_acc: 0.9991 - val_loss: 0.6487 - val_num_loss: 0.0952 - val_dig1_loss: 0.1609 - val_dig2_loss: 0.2063 - val_dig3_loss: 0.1290 - val_dig4_loss: 0.0299 - val_nC_loss: 0.0275 - val_num_acc: 0.9787 - val_dig1_acc: 0.9632 - val_dig2_acc: 0.9522 - val_dig3_acc: 0.9732 - val_dig4_acc: 0.9944 - val_nC_acc: 0.9939\n",
      "\n",
      "Epoch 00028: loss improved from 0.15924 to 0.15908, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 29/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1563 - num_loss: 0.0132 - dig1_loss: 0.0455 - dig2_loss: 0.0527 - dig3_loss: 0.0349 - dig4_loss: 0.0080 - nC_loss: 0.0020 - num_acc: 0.9957 - dig1_acc: 0.9865 - dig2_acc: 0.9835 - dig3_acc: 0.9885 - dig4_acc: 0.9974 - nC_acc: 0.9994 - val_loss: 0.5782 - val_num_loss: 0.0813 - val_dig1_loss: 0.1598 - val_dig2_loss: 0.1803 - val_dig3_loss: 0.1075 - val_dig4_loss: 0.0210 - val_nC_loss: 0.0284 - val_num_acc: 0.9825 - val_dig1_acc: 0.9647 - val_dig2_acc: 0.9577 - val_dig3_acc: 0.9750 - val_dig4_acc: 0.9950 - val_nC_acc: 0.9942\n",
      "\n",
      "Epoch 00029: loss improved from 0.15908 to 0.15635, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 30/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1494 - num_loss: 0.0133 - dig1_loss: 0.0454 - dig2_loss: 0.0496 - dig3_loss: 0.0308 - dig4_loss: 0.0077 - nC_loss: 0.0026 - num_acc: 0.9956 - dig1_acc: 0.9862 - dig2_acc: 0.9844 - dig3_acc: 0.9899 - dig4_acc: 0.9975 - nC_acc: 0.9991 - val_loss: 0.5985 - val_num_loss: 0.0839 - val_dig1_loss: 0.1614 - val_dig2_loss: 0.1825 - val_dig3_loss: 0.1122 - val_dig4_loss: 0.0304 - val_nC_loss: 0.0282 - val_num_acc: 0.9815 - val_dig1_acc: 0.9658 - val_dig2_acc: 0.9588 - val_dig3_acc: 0.9756 - val_dig4_acc: 0.9925 - val_nC_acc: 0.9943\n",
      "\n",
      "Epoch 00030: loss improved from 0.15635 to 0.14943, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 31/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1374 - num_loss: 0.0125 - dig1_loss: 0.0416 - dig2_loss: 0.0456 - dig3_loss: 0.0292 - dig4_loss: 0.0060 - nC_loss: 0.0025 - num_acc: 0.9960 - dig1_acc: 0.9878 - dig2_acc: 0.9860 - dig3_acc: 0.9901 - dig4_acc: 0.9981 - nC_acc: 0.9993 - val_loss: 0.6398 - val_num_loss: 0.0923 - val_dig1_loss: 0.1711 - val_dig2_loss: 0.2020 - val_dig3_loss: 0.1223 - val_dig4_loss: 0.0243 - val_nC_loss: 0.0277 - val_num_acc: 0.9803 - val_dig1_acc: 0.9638 - val_dig2_acc: 0.9571 - val_dig3_acc: 0.9749 - val_dig4_acc: 0.9950 - val_nC_acc: 0.9943\n",
      "\n",
      "Epoch 00031: loss improved from 0.14943 to 0.13740, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 32/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1616 - num_loss: 0.0164 - dig1_loss: 0.0484 - dig2_loss: 0.0522 - dig3_loss: 0.0329 - dig4_loss: 0.0071 - nC_loss: 0.0046 - num_acc: 0.9949 - dig1_acc: 0.9859 - dig2_acc: 0.9841 - dig3_acc: 0.9893 - dig4_acc: 0.9980 - nC_acc: 0.9987 - val_loss: 0.6432 - val_num_loss: 0.0919 - val_dig1_loss: 0.1808 - val_dig2_loss: 0.1998 - val_dig3_loss: 0.1148 - val_dig4_loss: 0.0249 - val_nC_loss: 0.0311 - val_num_acc: 0.9765 - val_dig1_acc: 0.9584 - val_dig2_acc: 0.9525 - val_dig3_acc: 0.9720 - val_dig4_acc: 0.9946 - val_nC_acc: 0.9925\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.13740\n",
      "Epoch 33/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1391 - num_loss: 0.0124 - dig1_loss: 0.0427 - dig2_loss: 0.0468 - dig3_loss: 0.0276 - dig4_loss: 0.0066 - nC_loss: 0.0030 - num_acc: 0.9960 - dig1_acc: 0.9872 - dig2_acc: 0.9855 - dig3_acc: 0.9909 - dig4_acc: 0.9978 - nC_acc: 0.9991 - val_loss: 0.5848 - val_num_loss: 0.0795 - val_dig1_loss: 0.1628 - val_dig2_loss: 0.1867 - val_dig3_loss: 0.1043 - val_dig4_loss: 0.0198 - val_nC_loss: 0.0317 - val_num_acc: 0.9831 - val_dig1_acc: 0.9647 - val_dig2_acc: 0.9589 - val_dig3_acc: 0.9757 - val_dig4_acc: 0.9959 - val_nC_acc: 0.9941\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.13740\n",
      "Epoch 34/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1235 - num_loss: 0.0117 - dig1_loss: 0.0370 - dig2_loss: 0.0401 - dig3_loss: 0.0263 - dig4_loss: 0.0066 - nC_loss: 0.0018 - num_acc: 0.9964 - dig1_acc: 0.9892 - dig2_acc: 0.9876 - dig3_acc: 0.9912 - dig4_acc: 0.9980 - nC_acc: 0.9995 - val_loss: 0.6029 - val_num_loss: 0.0790 - val_dig1_loss: 0.1700 - val_dig2_loss: 0.1923 - val_dig3_loss: 0.1100 - val_dig4_loss: 0.0222 - val_nC_loss: 0.0293 - val_num_acc: 0.9820 - val_dig1_acc: 0.9617 - val_dig2_acc: 0.9587 - val_dig3_acc: 0.9764 - val_dig4_acc: 0.9950 - val_nC_acc: 0.9942\n",
      "\n",
      "Epoch 00034: loss improved from 0.13740 to 0.12346, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1524 - num_loss: 0.0151 - dig1_loss: 0.0464 - dig2_loss: 0.0496 - dig3_loss: 0.0308 - dig4_loss: 0.0066 - nC_loss: 0.0039 - num_acc: 0.9956 - dig1_acc: 0.9866 - dig2_acc: 0.9849 - dig3_acc: 0.9904 - dig4_acc: 0.9981 - nC_acc: 0.9990 - val_loss: 0.5756 - val_num_loss: 0.0742 - val_dig1_loss: 0.1607 - val_dig2_loss: 0.1819 - val_dig3_loss: 0.1073 - val_dig4_loss: 0.0254 - val_nC_loss: 0.0261 - val_num_acc: 0.9820 - val_dig1_acc: 0.9631 - val_dig2_acc: 0.9569 - val_dig3_acc: 0.9738 - val_dig4_acc: 0.9939 - val_nC_acc: 0.9940\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.12346\n",
      "Epoch 36/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.1725 - num_loss: 0.0179 - dig1_loss: 0.0560 - dig2_loss: 0.0536 - dig3_loss: 0.0309 - dig4_loss: 0.0067 - nC_loss: 0.0073 - num_acc: 0.9948 - dig1_acc: 0.9836 - dig2_acc: 0.9839 - dig3_acc: 0.9903 - dig4_acc: 0.9981 - nC_acc: 0.9984 - val_loss: 0.5997 - val_num_loss: 0.0835 - val_dig1_loss: 0.1598 - val_dig2_loss: 0.1836 - val_dig3_loss: 0.1148 - val_dig4_loss: 0.0282 - val_nC_loss: 0.0297 - val_num_acc: 0.9805 - val_dig1_acc: 0.9603 - val_dig2_acc: 0.9550 - val_dig3_acc: 0.9735 - val_dig4_acc: 0.9939 - val_nC_acc: 0.9927\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.12346\n",
      "Epoch 37/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.3618 - num_loss: 0.0446 - dig1_loss: 0.1100 - dig2_loss: 0.1150 - dig3_loss: 0.0618 - dig4_loss: 0.0145 - nC_loss: 0.0159 - num_acc: 0.9860 - dig1_acc: 0.9679 - dig2_acc: 0.9657 - dig3_acc: 0.9815 - dig4_acc: 0.9960 - nC_acc: 0.9946 - val_loss: 0.6182 - val_num_loss: 0.0798 - val_dig1_loss: 0.1753 - val_dig2_loss: 0.2007 - val_dig3_loss: 0.1073 - val_dig4_loss: 0.0243 - val_nC_loss: 0.0307 - val_num_acc: 0.9784 - val_dig1_acc: 0.9573 - val_dig2_acc: 0.9479 - val_dig3_acc: 0.9731 - val_dig4_acc: 0.9943 - val_nC_acc: 0.9923\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.12346\n",
      "Epoch 38/50\n",
      "69076/69076 [==============================] - 85s 1ms/step - loss: 0.2573 - num_loss: 0.0290 - dig1_loss: 0.0803 - dig2_loss: 0.0809 - dig3_loss: 0.0467 - dig4_loss: 0.0113 - nC_loss: 0.0090 - num_acc: 0.9905 - dig1_acc: 0.9759 - dig2_acc: 0.9758 - dig3_acc: 0.9852 - dig4_acc: 0.9965 - nC_acc: 0.9969 - val_loss: 0.6002 - val_num_loss: 0.0797 - val_dig1_loss: 0.1602 - val_dig2_loss: 0.2004 - val_dig3_loss: 0.1060 - val_dig4_loss: 0.0254 - val_nC_loss: 0.0285 - val_num_acc: 0.9789 - val_dig1_acc: 0.9616 - val_dig2_acc: 0.9527 - val_dig3_acc: 0.9749 - val_dig4_acc: 0.9947 - val_nC_acc: 0.9925\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.12346\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 39/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.1111 - num_loss: 0.0100 - dig1_loss: 0.0349 - dig2_loss: 0.0377 - dig3_loss: 0.0220 - dig4_loss: 0.0043 - nC_loss: 0.0022 - num_acc: 0.9969 - dig1_acc: 0.9898 - dig2_acc: 0.9887 - dig3_acc: 0.9928 - dig4_acc: 0.9987 - nC_acc: 0.9994 - val_loss: 0.5460 - val_num_loss: 0.0763 - val_dig1_loss: 0.1440 - val_dig2_loss: 0.1767 - val_dig3_loss: 0.1012 - val_dig4_loss: 0.0220 - val_nC_loss: 0.0258 - val_num_acc: 0.9826 - val_dig1_acc: 0.9668 - val_dig2_acc: 0.9613 - val_dig3_acc: 0.9782 - val_dig4_acc: 0.9957 - val_nC_acc: 0.9937\n",
      "\n",
      "Epoch 00039: loss improved from 0.12346 to 0.11106, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 40/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0701 - num_loss: 0.0053 - dig1_loss: 0.0235 - dig2_loss: 0.0243 - dig3_loss: 0.0139 - dig4_loss: 0.0020 - nC_loss: 9.4457e-04 - num_acc: 0.9985 - dig1_acc: 0.9932 - dig2_acc: 0.9929 - dig3_acc: 0.9955 - dig4_acc: 0.9994 - nC_acc: 0.9998 - val_loss: 0.5726 - val_num_loss: 0.0823 - val_dig1_loss: 0.1499 - val_dig2_loss: 0.1828 - val_dig3_loss: 0.1059 - val_dig4_loss: 0.0240 - val_nC_loss: 0.0278 - val_num_acc: 0.9823 - val_dig1_acc: 0.9672 - val_dig2_acc: 0.9624 - val_dig3_acc: 0.9787 - val_dig4_acc: 0.9956 - val_nC_acc: 0.9938\n",
      "\n",
      "Epoch 00040: loss improved from 0.11106 to 0.07011, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 41/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0540 - num_loss: 0.0039 - dig1_loss: 0.0184 - dig2_loss: 0.0190 - dig3_loss: 0.0108 - dig4_loss: 0.0013 - nC_loss: 6.0603e-04 - num_acc: 0.9990 - dig1_acc: 0.9949 - dig2_acc: 0.9946 - dig3_acc: 0.9969 - dig4_acc: 0.9997 - nC_acc: 0.9999 - val_loss: 0.6037 - val_num_loss: 0.0874 - val_dig1_loss: 0.1577 - val_dig2_loss: 0.1926 - val_dig3_loss: 0.1116 - val_dig4_loss: 0.0251 - val_nC_loss: 0.0293 - val_num_acc: 0.9818 - val_dig1_acc: 0.9670 - val_dig2_acc: 0.9626 - val_dig3_acc: 0.9790 - val_dig4_acc: 0.9956 - val_nC_acc: 0.9935\n",
      "\n",
      "Epoch 00041: loss improved from 0.07011 to 0.05405, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 42/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0444 - num_loss: 0.0032 - dig1_loss: 0.0155 - dig2_loss: 0.0155 - dig3_loss: 0.0088 - dig4_loss: 9.4167e-04 - nC_loss: 4.3859e-04 - num_acc: 0.9993 - dig1_acc: 0.9958 - dig2_acc: 0.9957 - dig3_acc: 0.9976 - dig4_acc: 0.9998 - nC_acc: 1.0000 - val_loss: 0.6252 - val_num_loss: 0.0903 - val_dig1_loss: 0.1636 - val_dig2_loss: 0.1997 - val_dig3_loss: 0.1147 - val_dig4_loss: 0.0260 - val_nC_loss: 0.0310 - val_num_acc: 0.9822 - val_dig1_acc: 0.9672 - val_dig2_acc: 0.9628 - val_dig3_acc: 0.9790 - val_dig4_acc: 0.9955 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00042: loss improved from 0.05405 to 0.04442, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 43/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0375 - num_loss: 0.0027 - dig1_loss: 0.0131 - dig2_loss: 0.0131 - dig3_loss: 0.0074 - dig4_loss: 7.4394e-04 - nC_loss: 3.3407e-04 - num_acc: 0.9993 - dig1_acc: 0.9966 - dig2_acc: 0.9964 - dig3_acc: 0.9980 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.6511 - val_num_loss: 0.0946 - val_dig1_loss: 0.1703 - val_dig2_loss: 0.2073 - val_dig3_loss: 0.1189 - val_dig4_loss: 0.0278 - val_nC_loss: 0.0321 - val_num_acc: 0.9819 - val_dig1_acc: 0.9664 - val_dig2_acc: 0.9626 - val_dig3_acc: 0.9794 - val_dig4_acc: 0.9957 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00043: loss improved from 0.04442 to 0.03746, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 44/50\n",
      "69076/69076 [==============================] - 87s 1ms/step - loss: 0.0324 - num_loss: 0.0023 - dig1_loss: 0.0115 - dig2_loss: 0.0113 - dig3_loss: 0.0064 - dig4_loss: 5.8927e-04 - nC_loss: 2.6921e-04 - num_acc: 0.9994 - dig1_acc: 0.9971 - dig2_acc: 0.9970 - dig3_acc: 0.9982 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.6751 - val_num_loss: 0.0982 - val_dig1_loss: 0.1769 - val_dig2_loss: 0.2142 - val_dig3_loss: 0.1235 - val_dig4_loss: 0.0289 - val_nC_loss: 0.0334 - val_num_acc: 0.9821 - val_dig1_acc: 0.9665 - val_dig2_acc: 0.9621 - val_dig3_acc: 0.9793 - val_dig4_acc: 0.9956 - val_nC_acc: 0.9935\n",
      "\n",
      "Epoch 00044: loss improved from 0.03746 to 0.03236, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 45/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0284 - num_loss: 0.0021 - dig1_loss: 0.0101 - dig2_loss: 0.0099 - dig3_loss: 0.0055 - dig4_loss: 5.1290e-04 - nC_loss: 2.1353e-04 - num_acc: 0.9995 - dig1_acc: 0.9974 - dig2_acc: 0.9973 - dig3_acc: 0.9985 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.6987 - val_num_loss: 0.1024 - val_dig1_loss: 0.1831 - val_dig2_loss: 0.2214 - val_dig3_loss: 0.1269 - val_dig4_loss: 0.0301 - val_nC_loss: 0.0348 - val_num_acc: 0.9820 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9621 - val_dig3_acc: 0.9794 - val_dig4_acc: 0.9956 - val_nC_acc: 0.9934\n",
      "\n",
      "Epoch 00045: loss improved from 0.03236 to 0.02835, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 46/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0250 - num_loss: 0.0019 - dig1_loss: 0.0089 - dig2_loss: 0.0087 - dig3_loss: 0.0049 - dig4_loss: 4.2944e-04 - nC_loss: 1.5822e-04 - num_acc: 0.9995 - dig1_acc: 0.9977 - dig2_acc: 0.9977 - dig3_acc: 0.9987 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.7175 - val_num_loss: 0.1051 - val_dig1_loss: 0.1886 - val_dig2_loss: 0.2272 - val_dig3_loss: 0.1304 - val_dig4_loss: 0.0305 - val_nC_loss: 0.0357 - val_num_acc: 0.9821 - val_dig1_acc: 0.9668 - val_dig2_acc: 0.9620 - val_dig3_acc: 0.9794 - val_dig4_acc: 0.9955 - val_nC_acc: 0.9936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00046: loss improved from 0.02835 to 0.02496, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 47/50\n",
      "69076/69076 [==============================] - 87s 1ms/step - loss: 0.0220 - num_loss: 0.0017 - dig1_loss: 0.0078 - dig2_loss: 0.0077 - dig3_loss: 0.0043 - dig4_loss: 3.9173e-04 - nC_loss: 1.3032e-04 - num_acc: 0.9996 - dig1_acc: 0.9980 - dig2_acc: 0.9980 - dig3_acc: 0.9989 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.7405 - val_num_loss: 0.1084 - val_dig1_loss: 0.1952 - val_dig2_loss: 0.2344 - val_dig3_loss: 0.1339 - val_dig4_loss: 0.0316 - val_nC_loss: 0.0370 - val_num_acc: 0.9823 - val_dig1_acc: 0.9664 - val_dig2_acc: 0.9621 - val_dig3_acc: 0.9794 - val_dig4_acc: 0.9955 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00047: loss improved from 0.02496 to 0.02205, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 48/50\n",
      "69076/69076 [==============================] - 87s 1ms/step - loss: 0.0196 - num_loss: 0.0015 - dig1_loss: 0.0070 - dig2_loss: 0.0068 - dig3_loss: 0.0038 - dig4_loss: 3.2717e-04 - nC_loss: 1.1512e-04 - num_acc: 0.9997 - dig1_acc: 0.9982 - dig2_acc: 0.9983 - dig3_acc: 0.9990 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7630 - val_num_loss: 0.1119 - val_dig1_loss: 0.2019 - val_dig2_loss: 0.2404 - val_dig3_loss: 0.1378 - val_dig4_loss: 0.0327 - val_nC_loss: 0.0382 - val_num_acc: 0.9820 - val_dig1_acc: 0.9664 - val_dig2_acc: 0.9622 - val_dig3_acc: 0.9796 - val_dig4_acc: 0.9955 - val_nC_acc: 0.9935\n",
      "\n",
      "Epoch 00048: loss improved from 0.02205 to 0.01963, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 49/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0176 - num_loss: 0.0014 - dig1_loss: 0.0063 - dig2_loss: 0.0061 - dig3_loss: 0.0033 - dig4_loss: 3.0507e-04 - nC_loss: 1.0234e-04 - num_acc: 0.9997 - dig1_acc: 0.9985 - dig2_acc: 0.9984 - dig3_acc: 0.9992 - dig4_acc: 0.9999 - nC_acc: 1.0000 - val_loss: 0.7803 - val_num_loss: 0.1143 - val_dig1_loss: 0.2058 - val_dig2_loss: 0.2466 - val_dig3_loss: 0.1408 - val_dig4_loss: 0.0337 - val_nC_loss: 0.0391 - val_num_acc: 0.9820 - val_dig1_acc: 0.9665 - val_dig2_acc: 0.9623 - val_dig3_acc: 0.9793 - val_dig4_acc: 0.9955 - val_nC_acc: 0.9934\n",
      "\n",
      "Epoch 00049: loss improved from 0.01963 to 0.01756, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "Epoch 50/50\n",
      "69076/69076 [==============================] - 88s 1ms/step - loss: 0.0158 - num_loss: 0.0013 - dig1_loss: 0.0057 - dig2_loss: 0.0055 - dig3_loss: 0.0030 - dig4_loss: 2.3685e-04 - nC_loss: 9.5663e-05 - num_acc: 0.9997 - dig1_acc: 0.9987 - dig2_acc: 0.9987 - dig3_acc: 0.9993 - dig4_acc: 1.0000 - nC_acc: 1.0000 - val_loss: 0.7996 - val_num_loss: 0.1168 - val_dig1_loss: 0.2117 - val_dig2_loss: 0.2525 - val_dig3_loss: 0.1444 - val_dig4_loss: 0.0344 - val_nC_loss: 0.0398 - val_num_acc: 0.9821 - val_dig1_acc: 0.9666 - val_dig2_acc: 0.9623 - val_dig3_acc: 0.9792 - val_dig4_acc: 0.9954 - val_nC_acc: 0.9936\n",
      "\n",
      "Epoch 00050: loss improved from 0.01756 to 0.01580, saving model to saved_models/VGGPreTrained_classifier_corrected.hdf5\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "dict_keys(['val_loss', 'val_num_loss', 'val_dig1_loss', 'val_dig2_loss', 'val_dig3_loss', 'val_dig4_loss', 'val_nC_loss', 'val_num_acc', 'val_dig1_acc', 'val_dig2_acc', 'val_dig3_acc', 'val_dig4_acc', 'val_nC_acc', 'loss', 'num_loss', 'dig1_loss', 'dig2_loss', 'dig3_loss', 'dig4_loss', 'nC_loss', 'num_acc', 'dig1_acc', 'dig2_acc', 'dig3_acc', 'dig4_acc', 'nC_acc', 'lr'])\n",
      "CPU times: user 1h 4min 25s, sys: 16min 2s, total: 1h 20min 28s\n",
      "Wall time: 1h 11min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vggHistory = vggPreTrain.fit(x = X_train,\n",
    "                             y = list(y_train.T),\n",
    "                             batch_size = batch_size,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             shuffle = True,\n",
    "                             validation_data = (X_val, list(y_val.T)),\n",
    "                             callbacks= callback)\n",
    "\n",
    "print(vggHistory.history.keys())\n",
    "modName = 'vgg16_PreTrain_corrected'\n",
    "# list all data in history\n",
    "print(vggHistory.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg_pretrain_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train loss: 0.014020312673659113\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Train accuracy: [99.97538942613933, 99.88852857721929, 99.88708089640396, 99.93919740575598, 99.99855231918467, 99.99855231918467]\n",
      "Train sequence accuracy: 99.74955121894725\n",
      "Validation loss: 0.7995588414178265\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Validation accuracy: [98.21066651224739, 96.65875267820951, 96.2302391568707, 97.91533962591927, 99.5425328623545, 99.36302044125311]\n",
      "Validation sequence accuracy: 92.8716196652962\n",
      "Test loss: 1.6288448797922923\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Test accuracy: [96.75493647635084, 92.21643961426604, 91.71896525332926, 96.6630950558702, 99.58671360783713, 99.3418031532221]\n",
      "Test sequence accuracy: 84.62421552120006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [99.97538942613933,\n",
       "  99.88852857721929,\n",
       "  99.88708089640396,\n",
       "  99.93919740575598,\n",
       "  99.99855231918467,\n",
       "  99.99855231918467],\n",
       " 'test_acc': [96.75493647635084,\n",
       "  92.21643961426604,\n",
       "  91.71896525332926,\n",
       "  96.6630950558702,\n",
       "  99.58671360783713,\n",
       "  99.3418031532221],\n",
       " 'val_acc': [98.21066651224739,\n",
       "  96.65875267820951,\n",
       "  96.2302391568707,\n",
       "  97.91533962591927,\n",
       "  99.5425328623545,\n",
       "  99.36302044125311],\n",
       " 'train_seq_acc': 99.74955121894725,\n",
       " 'test_seq_acc': 84.62421552120006,\n",
       " 'val_seq_acc': 92.8716196652962,\n",
       " 'train_score': [0.014020312673659113,\n",
       "  0.0011900593736928655,\n",
       "  0.00510851295568146,\n",
       "  0.004846705962200736,\n",
       "  0.002579063866183819,\n",
       "  0.00021484057969230894,\n",
       "  8.113011016274738e-05,\n",
       "  0.9997538942613933,\n",
       "  0.9988852857721929,\n",
       "  0.9988708089640396,\n",
       "  0.9993919740575598,\n",
       "  0.9999855231918466,\n",
       "  0.9999855231918466],\n",
       " 'test_score': [1.6288448797922923,\n",
       "  0.22731382164296057,\n",
       "  0.524573706161919,\n",
       "  0.5707254456551292,\n",
       "  0.2350420507594548,\n",
       "  0.02908931626101544,\n",
       "  0.04210055153280704,\n",
       "  0.9675493647452611,\n",
       "  0.9221643961426603,\n",
       "  0.9171896525332925,\n",
       "  0.9666309505678256,\n",
       "  0.9958671360783713,\n",
       "  0.9934180315322211],\n",
       " 'val_score': [0.7995588414178265,\n",
       "  0.11675526536860126,\n",
       "  0.21170167259638392,\n",
       "  0.2525068464780433,\n",
       "  0.14444340134476946,\n",
       "  0.034361426703195495,\n",
       "  0.039790232811928894,\n",
       "  0.9821066651224738,\n",
       "  0.966587526782095,\n",
       "  0.9623023915687069,\n",
       "  0.9791533962626443,\n",
       "  0.995425328623545,\n",
       "  0.9936302044125311]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.model_evaluation_utils import evaluate_model_performance\n",
    "\n",
    "evaluate_model_performance(fitted_model=vggHistory, \n",
    "                           model_name = modName,\n",
    "                           data=data,\n",
    "                           model=vggPreTrain\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train loss: 0.0012191442427505605\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Train accuracy: [100.0, 99.99710463836932, 99.99710463836932, 100.0, 100.0, 100.0]\n",
      "Train sequence accuracy: 99.99420927673867\n",
      "Validation loss: 0.8632769504238671\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Validation accuracy: [98.65076148010886, 96.69928774103886, 95.89437720771325, 97.56789623023916, 99.35722971799179, 100.0]\n",
      "Validation sequence accuracy: 92.33887312525334\n",
      "Test loss: 1.9249597305217272\n",
      "number_of_digits digit1 digit2 digit3 digit4\n",
      "Test accuracy: [96.96157967243226, 91.51997550895454, 89.759681616409, 95.83652227154447, 99.44129802540947, 100.0]\n",
      "Test sequence accuracy: 81.93020052043471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_acc': [100.0,\n",
       "  99.99710463836932,\n",
       "  99.99710463836932,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0],\n",
       " 'test_acc': [96.96157967243226,\n",
       "  91.51997550895454,\n",
       "  89.759681616409,\n",
       "  95.83652227154447,\n",
       "  99.44129802540947,\n",
       "  100.0],\n",
       " 'val_acc': [98.65076148010886,\n",
       "  96.69928774103886,\n",
       "  95.89437720771325,\n",
       "  97.56789623023916,\n",
       "  99.35722971799179,\n",
       "  100.0],\n",
       " 'train_seq_acc': 99.99420927673867,\n",
       " 'test_seq_acc': 81.93020052043471,\n",
       " 'val_seq_acc': 92.33887312525334,\n",
       " 'train_score': [0.0012191442427505605,\n",
       "  9.542184659218849e-05,\n",
       "  0.00047577119569368494,\n",
       "  0.0003629728998552712,\n",
       "  0.00022080434270599865,\n",
       "  6.387599376335974e-05,\n",
       "  2.979689108205491e-07,\n",
       "  1.0,\n",
       "  0.9999710463836933,\n",
       "  0.9999710463836933,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'test_score': [1.9249597305217272,\n",
       "  0.22608713149070242,\n",
       "  0.6083131103722972,\n",
       "  0.7564571753749809,\n",
       "  0.2903091489847405,\n",
       "  0.04378623184903659,\n",
       "  6.951734232663811e-06,\n",
       "  0.9696157967243226,\n",
       "  0.9151997550712981,\n",
       "  0.89759681616409,\n",
       "  0.9583652226971974,\n",
       "  0.9944129802540946,\n",
       "  1.0],\n",
       " 'val_score': [0.8632769504238671,\n",
       "  0.0940574583885234,\n",
       "  0.2302493174947017,\n",
       "  0.30255114309782905,\n",
       "  0.19391753407335105,\n",
       "  0.04249996233630721,\n",
       "  1.541354273413108e-06,\n",
       "  0.9865076148010886,\n",
       "  0.9669928774103885,\n",
       "  0.958943772087487,\n",
       "  0.9756789623058431,\n",
       "  0.9935722971799178,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
